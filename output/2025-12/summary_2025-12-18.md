### 1 Adversarial versification in portuguese as a jailbreak operator in LLMs

**link**: https://arxiv.org/pdf/2512.15353.pdf  
**date**: 2025-12-18  
**keywords**: Latent Space  
**abs**: 最新证据表明，提示的诗化是对抗对齐大型语言模型（LLMs）的一种高效对抗机制。研究显示，将指令改写为诗歌形式可使原本被拒绝的指令变得可执行，安全失败率高达18倍。手动诗歌攻击成功率约62%，自动生成诗歌达43%，部分模型单轮成功率超90%。这种效应是结构性的，影响RLHF、宪法AI等训练系统，暴露了防护机制过度依赖表面模式的局限性。葡萄牙语因高复杂性、丰富韵律和庞大用户群，其评估缺失构成关键空白，需参数化韵律变化测试漏洞。

---

### 2 When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising

**link**: https://arxiv.org/pdf/2512.15547.pdf  
**date**: 2025-12-18  
**keywords**: Latent Space  
**abs**: 本研究开创了孟加拉语在公民动乱期间的情感分析，考察2024年大规模起义期间的公众情绪。构建了2028条标注新闻标题数据集，分类为愤怒、希望和绝望。通过LDA识别政治腐败和公众抗议等主题，分析互联网中断等事件对情感的影响。模型性能优于多语言transformer（mBERT:67%, XLM-RoBERTa:71%）和传统方法（SVM/逻辑回归:70%），突显特定语言模型的有效性，为政治动荡期公众情绪提供见解。

---

### 3 Characterizing Mamba's Selective Memory using Auto-Encoders

**link**: https://arxiv.org/pdf/2512.15653.pdf  
**date**: 2025-12-18  
**keywords**: cs.CL  
**abs**: 状态空间模型（SSMs）在语言建模中使用固定内存，但长序列处理时存在信息损失。本文通过自编码器重建序列，识别SSM LMs（如Mamba）易遗忘的标记类型（如数学相关标记、组织实体）和序列类型（如代码、数学问题）。实验在Mamba系列模型（130M--1.4B）上进行，发现信息损失率与标记在预训练数据中的出现频率相关，为未来改进信息保留方法提供方向。

---

### 4 Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers

**link**: https://arxiv.org/pdf/2512.15674.pdf  
**date**: 2025-12-18  
**keywords**: cs.CL  
**abs**: 本文提出激活预言机（AOs），训练LLMs以自然语言解释激活状态。在通才视角下，AOs能恢复微调模型信息（如传记知识或恶意倾向），尽管未使用相关激活状态训练。评估四个下游任务，AOs匹配或超越白盒基线，在3/4任务中表现最佳。多样化训练（如分类和自监督任务）提升泛化能力，证明LLMs可有效verbalize激活状态信息。

---

### 5 Task Matrices: Linear Maps for Cross-Model Finetuning Transfer

**link**: https://arxiv.org/pdf/2512.14880.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出任务矩阵概念，即基础嵌入状态到微调嵌入状态的线性变换。在视觉和文本模型及十个数据集上，任务矩阵增强的基础模型超越线性探针，接近微调水平。结果验证了预训练与微调架构间跨层线性编码的存在，且基于数据的编码近似高效、可泛化多领域。实现已公开。

---

### 6 From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?

**link**: https://arxiv.org/pdf/2512.15134.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 评估特征化方法（如稀疏自编码器和探针）在概念相关性增加时的解纠缠能力。实验显示概念到特征为一对多关系：特征对应不超过一个概念，但概念分布在多个特征上。引导实验表明，特征常影响多个概念，缺乏选择性和独立性。相关性指标不足以建立引导独立性，强调可解释性研究中组合评估的重要性。

---

### 7 Tracking Temporal Dynamics of Vector Sets with Gaussian Process

**link**: https://arxiv.org/pdf/2512.15538.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出使用无限维高斯过程建模向量集的基础分布，通过随机傅里叶特征近似获得紧凑时间表示。应用于社会学（犯罪分布）和语言学（词嵌入）数据，有效捕捉时间动态。方法提供可解释、稳健的低维表示，支持分析向量集结构变化，为生态学、犯罪分析等领域提供框架。

---

### 8 How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models

**link**: https://arxiv.org/pdf/2512.15115.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 引入统一框架，通过输入依赖交互算子表示序列映射，包括显式（如注意力混合）和隐式（如状态空间递归）模式。得出三个理论结果：交互秩差距、等价（头计数）定理和梯度高速公路，为Transformer和SSMs等序列架构设计提供理论基础，阐明表达能力和可训练性权衡。

---

### 9 Spectral Representation-based Reinforcement Learning

**link**: https://arxiv.org/pdf/2512.15036.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 引入谱表示视角，源于转移算子谱分解，为策略优化提供系统动力学抽象。框架为具有潜在变量或基于能量结构的转移算子构建谱表示，实现有效RL算法。可证明扩展到部分可观测MDPs。在DeepMind Control Suite的20+任务上验证，性能匹配或超越当前最先进的无模型和基于模型基线。

---

### 10 FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows

**link**: https://arxiv.org/pdf/2512.15420.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出FlowBind框架，学习共享潜在空间捕获跨模态信息，并通过模态特定可逆流连接。在单一流匹配目标下联合优化，推理时作为编码器/解码器实现模态间直接转换。共享潜在空间降低数据需求和计算成本，在文本、图像和音频上实验，质量相当但参数减少6倍、训练快10倍。

---

### 11 Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants

**link**: https://arxiv.org/pdf/2512.15712.pdf  
**date**: 2025-12-18  
**keywords**: cs.AI  
**abs**: 训练解释助手通过通信瓶颈从激活预测模型行为。编码器压缩激活为稀疏概念列表，解码器读取并回答自然语言问题。预测概念解码器（PCD）在非结构化数据上预训练，微调后能检测越狱、秘密提示和用户属性。缩放特性良好：概念解释分数随数据增加而提升，下游应用性能优异。

---

### 12 High-Dimensional Partial Least Squares: Spectral Analysis and Fundamental Limitations

**link**: https://arxiv.org/pdf/2512.15684.pdf  
**date**: 2025-12-18  
**keywords**: stat.ML  
**abs**: 分析高维PLS-SVD，使用随机矩阵理论工具推导估计与真实潜在方向对齐的渐近特征。结果提供重建性能定量解释，识别反直觉或限制行为情况。比较PLS-SVD与PCA，证明其在检测共同潜在子空间的渐近优越性，全面阐明高维PLS-SVD的优势和基本局限性。

---

### 13 A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour

**link**: https://arxiv.org/pdf/2512.14713.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出潜在类别强化学习（LCRL）模型，捕捉出行决策中的偏好异质性和演变。应用于驾驶模拟器数据，通过变分贝叶斯估计识别三类个体：情境依赖偏好类（利用倾向）、持续利用策略类和探索策略类。模型有效处理经验形成和旅行者异质性。

---

### 14 Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning

**link**: https://arxiv.org/pdf/2512.14709.pdf  
**date**: 2025-12-18  
**keywords**: cs.AI  
**abs**: 将自注意力和残差流解释为近似向量符号架构（VSA），统一视角Transformer推理。查询和键定义角色空间，值编码内容，注意力权重执行软解绑，残差连接实现多绑定叠加。关联思维链、程序推理和工具使用，解释变量混淆等失败模式。提出VSA启发的架构偏差（如显式绑定/解绑头）和训练目标，促进角色-填充分离。

---

### 15 GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge

**link**: https://arxiv.org/pdf/2512.14766.pdf  
**date**: 2025-12-18  
**keywords**: cs.AI  
**abs**: 针对知识图谱问答（KGQA）中知识图谱不完全问题，提出自适应图推理代理（GR-Agent）。构建交互式图环境，形式化KGQA为智能体-环境交互过程。使用图推理工具操作动作空间，维护潜在支持推理证据记忆。实验在完全和不完全知识图谱设置下，GR-Agent优于非训练基线，匹配训练型方法，解决知识缺失时推理不足问题。

---

### 16 Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary

**link**: https://arxiv.org/pdf/2512.15614.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出BEAT框架，通过向量量化自编码构建行为词汇表，解耦宏观兴趣和微观意图。利用跨视图邻域信息优化缺失值填补，通过语义对齐正则化冻结语言模型输入空间。实验在文本、图像和音频上，BEAT零样本推荐性能优于现有方法，生成连贯解释，行为令牌捕捉细粒度语义，提供即插即用接口。

---

### 17 Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures

**link**: https://arxiv.org/pdf/2512.15228.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出DBCata深度生成模型，结合周期性布朗桥框架和等变图神经网络，建立未弛豫与DFT弛豫结构间低维过渡流形。生成高保真吸附几何结构，原子间距离平均绝对误差0.035 Å。通过混合异常检测优化，94%情况下DFT精度提升至0.1 eV内。应用于氧还原反应催化剂筛选，突显其作为设计工具的潜力。

---

### 18 Distillation-Guided Structural Transfer for Continual Learning Beyond Sparse Distributed Memory

**link**: https://arxiv.org/pdf/2512.15267.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出选择性子网络蒸馏（SSD）框架，将蒸馏视为拓扑对齐信息管道。识别高激活频率神经元，在Top-K子网络和输出logits上选择性蒸馏知识，无需重放或任务标签。在Split CIFAR-10、CIFAR-100和MNIST上实验，SSD提高准确性、保留率和表示覆盖率，为稀疏持续学习提供基于结构的解决方案。

---

### 19 Topological Metric for Unsupervised Embedding Quality Evaluation

**link**: https://arxiv.org/pdf/2512.15285.pdf  
**date**: 2025-12-18  
**keywords**: cs.LG  
**abs**: 提出Persistence，基于持久同调的拓扑感知度量，无监督量化嵌入空间的几何和拓扑丰富度。捕获全局多尺度组织，而非线性可分性或协方差。实证结果在不同领域显示，Persistence与下游性能顶级相关，优于现有无监督度量，支持可靠模型和超参数选择。
### 1 Learning to Reason in LLMs by Expectation Maximization

**link**: https://arxiv.org/pdf/2512.20169.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出将大型语言模型（LLMs）的推理过程形式化为潜变量模型，并推导出期望最大化（EM）目标用于学习推理。该方法将EM与基于奖励的优化联系起来，关键挑战在于设计采样分布以生成证明正确答案的基本原理。作者比较了多种采样方案，包括带预算的拒绝采样、自教推理器（STaR）和提示后验采样（PPS）。在ARC、MMLU和OpenBookQA数据集上使用Llama和Qwen模型的实验表明，采样方案显著影响推理模型的准确性，其中简单的PPS方案优于其他方法。

---

### 2 Sign-Aware Multistate Jaccard Kernels and Geometry for Real and Complex-Valued Signals

**link**: https://arxiv.org/pdf/2512.19721.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出一种符号感知的多状态Jaccard/Tanimoto框架，将基于重叠的距离扩展到任意实值和复值信号，保留有界度量和正定核结构。信号被表示为有符号状态空间上的原子测度，相似度由广义Jaccard重叠计算。通过嵌入非负多状态表示（如正负分裂或笛卡尔/极坐标分解），该方法生成[0,1]距离，满足三角不等式并支持核方法。此外，通过Möbius反演实现联盟分析，将信号分解为非负可加贡献，确保预算闭合和概率语义，适用于科学和金融应用。

---

### 3 High-Performance Self-Supervised Learning by Joint Training of Flow Matching

**link**: https://arxiv.org/pdf/2512.19729.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出FlowFM框架，通过联合训练表示编码器和条件流匹配生成器，解决扩散模型在生成质量与判别性能间的权衡问题。FlowFM利用流匹配学习速度场，加速训练并提高稳定性。在可穿戴传感器数据上的实验显示，FlowFM将训练时间减少50.4%，并在下游任务中超越最先进的自监督学习方法，实现高达51.0倍的推理加速，同时保持高生成质量。

---

### 4 The Deleuzian Representation Hypothesis

**link**: https://arxiv.org/pdf/2512.19734.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出一种替代稀疏自编码器（SAEs）的方法，用于从神经网络中提取可解释概念。该方法通过聚类激活差异，在判别分析框架内优化聚类，利用权重激活的偏度增强概念多样性。在视觉、语言和音频模态的五个模型上评估，结果显示该方法的概念质量超过无监督SAE变体，接近有监督基线，并能控制模型内部表示，证明其对下游行为的因果影响。

---

### 5 On-device Large Multi-modal Agent for Human Activity Recognition

**link**: https://arxiv.org/pdf/2512.19742.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出一种用于人类活动识别（HAR）的大型多模态智能体，整合大型语言模型（LLMs）以增强性能和用户交互。该框架不仅实现活动分类，还通过推理和问答功能提供用户友好洞察。在HHAR、Shoaib和Motionsense数据集上的评估表明，模型达到与最先进方法相当的分类准确率，并通过推理和Q&A能力显著提高可解释性。

---

### 6 Modeling Non-Ergodic Path Effects Using Conditional Generative Model for Fourier Amplitude Spectra

**link**: https://arxiv.org/pdf/2512.19909.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出条件生成傅里叶振幅谱模型（CGM-FAS），用于建模傅里叶振幅谱（FAS）中的非遍历路径效应。CGM-FAS采用条件变分自编码器架构，以地震和台站地理坐标为条件变量，直接从数据学习空间模式和频率间相关性。在旧金山湾区地震数据上的实验表明，CGM-FAS能一致预测非遍历路径效应，相比高斯过程方法具有优势：无需预设相关函数、捕捉频率间相关性，并支持快速预测（10秒内生成10,000站点预测）。

---

### 7 Spatio-Temporal Graph Neural Networks for Dairy Farm Sustainability Forecasting and Counterfactual Policy Analysis

**link**: https://arxiv.org/pdf/2512.19970.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出一种数据驱动框架，首次在县级尺度应用时空图神经网络（STGNN）预测综合可持续性指数。方法利用变分自编码器（VAE）增强爱尔兰牛育种联合会数据集，缓解稀疏性并保留联合分布。通过主成分分析推导基于支柱的评分公式，识别繁殖效率、遗传管理等维度，构建加权综合指数。STGNN架构显式编码地理依赖和非线性时间动态，生成2026-2030年预测。

---

### 8 Field-Space Attention for Structure-Preserving Earth System Transformers

**link**: https://arxiv.org/pdf/2512.20350.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出场空间注意力机制，用于地球系统Transformer，直接在物理域计算注意力而非潜在空间。该方法将中间表示保持为球面上的连续场，实现可解释内部状态并支持科学约束。模型采用固定多尺度分解，学习结构保持变形，避免单尺度视觉Transformer的优化不稳定性。在HEALPix网格上的全球温度超分辨率任务中，场空间Transformer比传统方法收敛更快、更稳定，参数更少，并允许嵌入物理和统计先验。

---

### 9 Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning

**link**: https://arxiv.org/pdf/2512.20605.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出在自回归模型的内部表示中探索高阶非因果序列模型，以解决逐token采样导致的效率低下问题。高阶模型将长激活序列压缩为内部控制器，每个控制器执行长期行为并学习终止条件。在网格世界和MuJoCo任务中，该方法通过“内部强化学习”实现稀疏奖励下的高效探索，证明潜在动作生成在自回归模型中的优势。

---

### 10 Schoenfeld's Anatomy of Mathematical Reasoning by Language Models

**link**: https://arxiv.org/pdf/2512.19995.pdf  
**date**: 2025-12-24  
**keywords**: cs.CL  
**abs**: 本文采用Schoenfeld的Episode Theory框架（ThinkARM），将推理轨迹抽象为分析、探索、实施和验证等功能性步骤。在数学问题求解中，该抽象揭示了推理与非推理模型间的思维动态差异，其中探索是关键分支步骤。案例研究表明，episode级表示能显式化推理步骤，支持系统分析语言模型的推理结构与变化。

---

### 11 ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language

**link**: https://arxiv.org/pdf/2512.20111.pdf  
**date**: 2025-12-24  
**keywords**: cs.CL  
**abs**: 本文提出ABBEL框架，使LLM智能体通过语言表达的信念瓶颈维持简洁上下文。框架用信念状态（任务相关未知信息的自然语言摘要）替代长交互历史，智能体每步更新信念并据此行动。实验显示，ABBEL生成可解释信念并保持近恒定内存使用，但存在错误传播问题。强化学习训练后，ABBEL性能超越完整上下文设置，内存使用少于同期方法。

---

### 12 Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents

**link**: https://arxiv.org/pdf/2512.20092.pdf  
**date**: 2025-12-24  
**keywords**: cs.CL  
**abs**: 本文提出Memory-T1框架，通过强化学习（RL）学习时间感知的记忆选择策略。框架采用从粗到细策略：先通过时间和相关性过滤器修剪对话历史，再由RL智能体选择精确证据会话。RL训练由多级奖励函数指导，优化答案准确性、证据接地和时间一致性。在Time-Dialog基准上，Memory-T1将7B模型性能提升至67.0%，超越14B基线10.2%，并在128k tokens时保持稳健性。

---

### 13 Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning

**link**: https://arxiv.org/pdf/2512.20220.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文分析多任务拟合Q迭代算法，用于离线多任务强化学习。算法通过贝尔曼误差最小化联合学习共享表示和任务特定价值函数。在可实现性和覆盖假设下，作者为学习价值函数建立有限样本泛化保证，显示跨任务数据池化提高估计精度（依赖1/√(nT)）。此外，复用多任务表示可降低新任务学习的有效复杂度。

---

### 14 Adaptive Multi-task Learning for Probabilistic Load Forecasting

**link**: https://arxiv.org/pdf/2512.20232.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出一种自适应多任务学习方法，用于概率负荷预测。方法基于向量值隐马尔可夫模型，通过递归过程更新参数，适应消费模式变化和实体间相关性。实验结果表明，在多个实体负荷数据集上，该方法在预测性能和不确定性评估方面优于现有方法。

---

### 15 Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion

**link**: https://arxiv.org/pdf/2512.20249.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出BrainROI模型，用于多模态脑解码。模型设计fMRI编码器，将多图谱软功能分区（soft-ROI）作为共享空间，扩展为体素级门控融合机制（Voxel-gate），并通过全局标签对齐增强跨被试迁移能力。引入可解释提示优化过程，使用Qwen模型迭代生成人类可读提示。在NSD数据集脑captioning评估中，模型取得领先结果，跨被试设置下BLEU-4和CIDEr指标显著提升。

---

### 16 M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation

**link**: https://arxiv.org/pdf/2512.20136.pdf  
**date**: 2025-12-24  
**keywords**: cs.CL  
**abs**: 本文提出M³KG-RAG框架，从多跳多模态知识图谱（M³KG）中检索与查询对齐的视听知识。框架构建M³KG，包含上下文丰富的多模态实体三元组。引入GRASP（基于接地的检索与选择性修剪），确保实体与查询精确接地，并修剪冗余上下文。实验表明，M³KG-RAG增强多模态大型语言模型（MLLMs）的推理和接地能力。

---

### 17 SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision

**link**: https://arxiv.org/pdf/2512.20308.pdf  
**date**: 2025-12-24  
**keywords**: cs.CL  
**abs**: 本文提出SpidR，一种自监督语音表示模型，使用掩码预测目标结合自蒸馏和在线聚类训练。学生模型中间层预测教师分配，稳定在线聚类过程并生成高质量码本。评估显示，SpidR在下游语言建模基准上优于现有模型，并显著减少预训练时间（仅需16个GPU一天）。

---

### 18 Brain-Grounded Axes for Reading and Steering LLM States

**link**: https://arxiv.org/pdf/2512.19399.pdf  
**date**: 2025-12-24  
**keywords**: cs.LG  
**abs**: 本文提出利用人类大脑活动作为读取和控制LLM状态的坐标系。通过独立成分分析（ICA）提取脑电图（MEG）数据的潜在轴，训练轻量级适配器将LLM隐藏状态映射到脑轴。实验显示，沿脑源性方向控制产生稳健的词汇和功能/内容轴，支持基于神经生理学的LLM行为接口。

---

### 19 Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits

**link**: https://arxiv.org/pdf/2512.20578.pdf  
**date**: 2025-12-24  
**keywords**: cs.CL  
**abs**: 本文提出Gnosis，一种轻量级自我意识机制，使冻结的LLMs通过解码隐藏状态和注意力模式预测自身失败。Gnosis被动观察内部轨迹，将其压缩为固定预算描述符，以可忽略成本预测正确性。在数学推理和问答基准上，Gnosis优于内部基线和大型外部判断器，表明正确性线索可高效提取。

---

### 20 SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization

**link**: https://arxiv.org/pdf/2512.20333.pdf  
**date**: 2025-12-24  
**keywords**: cs.AI  
**abs**: 本文提出SynCraft框架，将合成可行性优化定义为结构编辑问题。利用LLMs预测原子级编辑的可执行序列，避免直接生成SMILES字符串的句法脆弱性。基准测试显示，SynCraft在生成可合成类似物方面优于最先进基线，并成功复制专家药物化学直觉，用于编辑PLK1和RIPK1抑制剂。

---

### 21 Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs

**link**: https://arxiv.org/pdf/2512.19937.pdf  
**date**: 2025-12-24  
**keywords**: cs.AI  
**abs**: 本文探讨利用插值解码在LLMs中探索人格特质谱。方法将人格维度表示为一对对立提示，使用插值参数模拟行为。结果显示，插值解码能可靠调节大五人格分数，并在经济游戏中模仿人类决策，复制心理学研究结果。通过搜索插值空间，初步实现“孪生”人类玩家动作。

---

### 22 Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification

**link**: https://arxiv.org/pdf/2512.19957.pdf  
**date**: 2025-12-24  
**keywords**: cs.AI  
**abs**: 本文提出一种通过原型引导的零样本分割方法，用于多标签植物物种识别。方法从训练图像提取特征并应用K-Means聚类创建类原型，分割模型通过替换补丁嵌入层为冻结的DinoV2，从测试图像重建类原型。利用注意力分数识别感兴趣区域，指导分类过程。在PlantCLEF 2025挑战中，该方法F1分数达0.33331。

---

### 23 FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification

**link**: https://arxiv.org/pdf/2512.19960.pdf  
**date**: 2025-12-24  
**keywords**: cs.AI  
**abs**: 本文提出细粒度深度聚类分类（FGDCC）框架，解决细粒度视觉分类中的类内变异性问题。方法对每个类单独聚类，发现伪标签表示图像间潜在相似度，并在层次化分类中使用这些标签学习更细粒度特征。在PlantNet300k数据集上，该方法实现最先进性能。

---

### 24 Learning Skills from Action-Free Videos

**link**: https://arxiv.org/pdf/2512.20052.pdf  
**date**: 2025-12-24  
**keywords**: cs.AI  
**abs**: 本文提出技能抽象光流（SOF）框架，从无动作视频中学习潜技能。SOF通过基于光流的中间表示学习潜技能空间，该表示捕获视频动态和机器人动作对齐的运动信息。在流基潜空间中学习技能，支持高级规划和动作转化。实验表明，SOF在多任务和长视野场景中提高性能，证明其从原始视觉数据获取和组合技能的能力。
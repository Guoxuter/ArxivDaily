### 1 LLmFPCA-detect: LLM-powered Multivariate Functional PCA for Anomaly Detection in Sparse Longitudinal Texts

**link**: https://arxiv.org/pdf/2512.14604.pdf  
**date**: 2025-12-17  
**keywords**: stat.ML  
**abs**: 本文提出LLmFPCA-detect框架，结合LLM文本嵌入与函数数据分析，用于稀疏纵向文本数据中的聚类检测和异常推断。框架首先使用LLM提示将文本嵌入到数值空间，再通过稀疏多元函数主成分分析（mFPCA）恢复群体特征，生成受试者分数。这些分数与静态协变量结合，支持数据分割、无监督异常检测和下游任务（如动态关键词分析）。实验表明，该框架能提升预测性能并有效识别异常。

---

### 2 Semantic Grounding Index: Geometric Bounds on Context Engagement in RAG Systems

**link**: https://arxiv.org/pdf/2512.13771.pdf  
**date**: 2025-12-17  
**keywords**: cs.AI  
**abs**: 本文引入语义接地指数（SGI），定义为响应到问题与响应到上下文的角距离比率，用于检测RAG系统中的幻觉。研究发现“语义懒惰”现象：幻觉响应在角度上更接近问题而非上下文。在HaluEval数据集上，SGI表现出高效应量（平均r=0.85），区分能力随问题-上下文角分离增加而提升。SGI在长响应和短问题上表现优异，可作为高效、理论扎实的幻觉检测工具，但需与事实准确性区分。

---

### 3 ReflCtrl: Controlling LLM Reflection via Representation Engineering

**link**: https://arxiv.org/pdf/2512.13979.pdf  
**date**: 2025-12-17  
**keywords**: cs.AI  
**abs**: 本文从表示工程角度研究LLM的自我反思行为，提出ReflCtrl方法控制反思频率。通过分割推理步骤、识别反思方向，并在潜在空间中引导行为。实验表明：（1）在较强模型中反思常冗余，ReflCtrl可节省33.6%推理标记；（2）反思行为与内部不确定性高度相关。该方法在保持性能的同时优化推理成本，为LLM反思机制提供新见解。

---

### 4 The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models

**link**: https://arxiv.org/pdf/2512.13741.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出层流假设，用于检测LLM的越狱攻击：良性输入诱导平滑潜在空间过渡，而对抗提示触发混沌“语义湍流”。通过层间余弦速度方差指标形式化此现象，实验显示RLHF对齐模型在攻击下湍流增加75.4%（p<0.001），而低熵模型减少22.0%。该指标可作为轻量级实时越狱检测器，并用于诊断模型安全架构。

---

### 5 MIDUS: Memory-Infused Depth Up-Scaling

**link**: https://arxiv.org/pdf/2512.13751.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出MIDUS，一种记忆注入深度扩展方法，用于高效扩展LLM容量。MIDUS用头向记忆（HML）层替换传统FFN复制块，为每个注意力头分配独立记忆库，实现头向检索和信息注入。结合稀疏内存访问与值分解模块，在持续预训练中较基线提升性能，同时保持参数效率，为深度扩展提供资源高效替代方案。

---

### 6 EEG-D3: A Solution to the Hidden Overfitting Problem of Deep Learning Models

**link**: https://arxiv.org/pdf/2512.13806.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文介绍EEG-D3，一种解纠缠解码分解方法，解决EEG信号解码中的隐藏过拟合问题。通过预测输入窗口位置，分离脑活动潜在成分（类似非线性ICA）。采用独立子网络架构确保可解释性，特征解释范式对比成分激活谱。实验显示，该方法在运动想象数据上可靠分离成分，防止任务相关伪影导致的过拟合，并支持少样本睡眠阶段分类。

---

### 7 Understanding and Improving Hyperbolic Deep Reinforcement Learning

**link**: https://arxiv.org/pdf/2512.14202.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文分析双曲深度RL的优化挑战，提出Hyper++框架。通过梯度分析发现大范数嵌入破坏训练稳定性，Hyper++包括：（i）分类值损失稳定评论家；（ii）有界范数特征正则化；（iii）易优化双曲层公式。在ProcGen和Atari-5上，Hyper++保证稳定学习，性能优于双曲和欧几里得基线，减少30% wall-clock时间。

---

### 8 From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition

**link**: https://arxiv.org/pdf/2512.14244.pdf  
**date**: 2025-12-17  
**keywords**: cs.CL  
**abs**: 本文提出基于EDU的上下文压缩器，解决长文档管理瓶颈。框架将压缩重构为“先结构后选择”：LingoEDU将文本转换为基本话语单元（EDU）关系树，锚定源索引消除幻觉；轻量级排序模块选择相关子树线性化。在StructBench数据集上，该方法实现最先进结构预测精度，提升下游任务（如长上下文问答）性能。

---

### 9 Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models

**link**: https://arxiv.org/pdf/2512.14427.pdf  
**date**: 2025-12-17  
**keywords**: cs.CL  
**abs**: 本文研究文档打包策略对LLM多跳推理能力的影响。实验表明，打包训练较单独文档提升性能，但需更多计算资源。消融研究识别关键因素：打包通过增强上下文关联性优化潜在推理机制。结果为LLM训练动态提供实用见解，支持模型开发优化。

---

### 10 A Unified Sparse Attention via Multi-Granularity Compression

**link**: https://arxiv.org/pdf/2512.14082.pdf  
**date**: 2025-12-17  
**keywords**: cs.CL  
**abs**: 本文提出UniSparse统一稀疏注意力机制，解决长上下文计算瓶颈。引入复合令牌聚合多粒度上下文，通过多粒度压缩和块级选择动态构建稀疏注意力。在GPU上高效执行，跨模态任务中准确率达全注意力99%以上，计算速度较FlashAttention提升2.61倍，优于现有稀疏方法。

---

### 11 CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models

**link**: https://arxiv.org/pdf/2512.14118.pdf  
**date**: 2025-12-17  
**keywords**: cs.CL  
**abs**: 本文提出CogMem，一种认知记忆架构，解决LLM多轮交互中的准确性和连贯性衰减问题。包含三层：长期记忆（LTM）整合跨会话策略；直接访问（DA）内存维护会话笔记；注意力焦点（FoA）动态重建简洁上下文。在TurnBench上，该设计减轻推理失败（如偏差和幻觉），控制上下文增长，提升扩展推理链一致性。

---

### 12 Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution

**link**: https://arxiv.org/pdf/2512.13729.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出复合无分类器引导（CCFG）方法，用于多模态条件风超分辨率。CCFG利用多输入通道（如风数据），应用于预训练扩散模型。实验显示，CCFG输出保真度优于标准CFG，WindDM模型在工业规模重建中实现最先进质量，成本比传统方法低1000倍。

---

### 13 PIS: A Generalized Physical Inversion Solver for Arbitrary Sparse Observations via Set-Conditioned Diffusion

**link**: https://arxiv.org/pdf/2512.13732.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出物理反演求解器（PIS），基于集合条件扩散框架，解决稀疏观测下的PDE约束参数估计问题。采用集合Transformer编码器处理任意测量几何，余弦退火稀疏课程提升鲁棒性。信息论分析揭示观测熵随物理条件变化，为极端稀疏反演提供理论边界。

---

### 14 Low-Rank Compression of Language Models via Differentiable Rank Selection

**link**: https://arxiv.org/pdf/2512.13733.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出LLRC方法，用于基于梯度的语言模型低秩压缩。通过训练掩码权重直接学习奇异值选择，无需微调。在常识推理和问答任务上，LLRC优于竞争方法（如压缩率20%时，在Llama-2-13B上MMLU提升12%），并与微调变体竞争力相当。

---

### 15 TF-MCL: Time-frequency Fusion and Multi-domain Cross-Loss for Self-supervised Depression Detection

**link**: https://arxiv.org/pdf/2512.13736.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出TF-MCL模型，用于自监督抑郁症检测。通过融合映射头（FMH）生成时频混合表示，增强时频信息合成能力；优化多域交叉损失函数，重建表示分布。在MODMA和PRED+CT数据集上，准确率较SOTA提升5.87%和9.96%。

---

### 16 Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training

**link**: https://arxiv.org/pdf/2512.13770.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出MV-SupGCN半监督GCN模型，整合多视图学习。包括：（i）联合交叉熵与监督对比损失，最小化类内方差；（ii）KNN与半监督图构建增强鲁棒性；（iii）统一框架结合对比学习和伪标记。实验显示，在多个基准测试中性能优于最先进方法。

---

### 17 IPR-1: Interactive Physical Reasoner

**link**: https://arxiv.org/pdf/2511.15407.pdf  
**date**: 2025-12-17  
**keywords**: cs.AI  
**abs**: 本文提出IPR（交互式物理推理器），模拟人类学习机制。利用世界模型rollouts对VLM策略评分，引入PhysCode动作代码对齐语义与动态特性。在1000+异质游戏上预训练后，IPR在零样本迁移中表现稳健，性能超越GPT-5，支持物理中心交互提升推理能力。

---

### 18 FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting

**link**: https://arxiv.org/pdf/2512.14253.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出FLAME时间序列基础模型，支持确定性和概率预测。利用Legendre记忆（平移和缩放）捕捉内在归纳偏置，实现高效长程推理；归一化流预测头建模复杂分布。在TSFM-Bench和ProbTS上，零样本性能达到最先进，兼顾轻量级和高效。

---

### 19 Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics

**link**: https://arxiv.org/pdf/2512.14471.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文提出Kinetic-Mamba框架，结合神经算子和Mamba架构，预测化学动力学。包括三个模型：独立Mamba预测热化学状态；约束Mamba强制质量守恒；基于状态Mamba捕捉温度依赖动态。在Syngas和GRI-Mech 3.0上，仅需初始条件即可高精度预测复杂动力学行为。

---

### 20 Synthetic Electrogram Generation with Variational Autoencoders for ECGI

**link**: https://arxiv.org/pdf/2512.14537.pdf  
**date**: 2025-12-17  
**keywords**: cs.LG  
**abs**: 本文研究VAE生成合成心房电图（EGMs），用于缓解ECGI数据稀缺。提出VAE-S（窦性心律）和VAE-C（类别条件）模型，评估形态学、频谱和分布相似性。生成的EGMs用于数据增强，提升下游非侵入性重建任务性能，证明VAE在增强ECGI流程中的潜力。
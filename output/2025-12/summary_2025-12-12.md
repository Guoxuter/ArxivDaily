### 1 CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment

**link**: https://arxiv.org/pdf/2512.10206.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 医疗护理遵循复杂的临床路径，超越了孤立的医患接触，强调不同阶段之间的决策制定和过渡。当前专注于静态检查或孤立对话的基准不足以评估大型语言模型（LLMs）在动态临床场景中的表现。我们引入CP-Env，这是一个可控的智能体医院环境，旨在跨端到端临床路径评估LLMs。CP-Env模拟具有患者和医生智能体的医院生态系统，构建从分诊、专科咨询到诊断测试和多学科团队会议的场景，以进行智能体交互。遵循真实医院的自适应医疗流程，它支持分支和长周期任务执行。我们提出了一个三层评估框架，包括临床疗效、流程能力和职业道德。结果显示，大多数模型在路径复杂性方面存在困难，表现出幻觉和丢失关键诊断细节的问题。有趣的是，过多的推理步骤有时可能适得其反，而顶级模型往往通过内化知识减少对工具的依赖。CP-Env通过全面的端到端临床评估推动医疗AI智能体的发展。

---

### 2 User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation

**link**: https://arxiv.org/pdf/2512.10322.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 视觉-语言导航（VLN）要求智能体通过遵循自然语言指令在复杂环境中导航。VLN的通用场景适应（GSA-VLN）将重点从零样本泛化转向持续的、特定环境的适应，缩小了静态基准与实际部署之间的差距。然而，当前的GSA-VLN框架排除了用户反馈，仅依赖于通过重复环境暴露进行的无监督适应。在实践中，用户反馈提供了自然且有价值的监督，可以显著提高适应质量。我们引入了一个用户反馈驱动的适应框架，通过系统地将人类交互整合到持续学习中扩展GSA-VLN。我们的方法将用户反馈（导航指令和纠正信号）转换为高质量、与环境对齐的训练数据，实现高效且现实的适应。记忆库预热机制进一步重用先前获取的环境知识，减轻冷启动退化并确保稳定的重新部署。在GSA-R2R基准上的实验表明，我们的方法持续超越强大的基线（如GR-DUET），提高导航成功率和路径效率。记忆库预热稳定了早期导航并减少了更新后的性能下降。

---

### 3 AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management

**link**: https://arxiv.org/pdf/2512.10371.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 移动GUI代理的快速发展激发了对长程任务自动化的研究兴趣。然而，构建此类任务的代理面临一个关键瓶颈：对不断扩展的交互历史的依赖导致了巨大的上下文开销。现有的上下文管理和压缩技术往往无法保留重要的语义信息，导致任务性能下降。我们提出AgentProg，一种程序引导的代理上下文管理方法，将交互历史重构为带有变量和控制流的程序。通过根据程序结构组织信息，该结构提供了一种原则性机制来确定应保留哪些信息和可丢弃哪些信息。我们进一步集成了受Belief MDP框架启发的全局信念状态机制，以处理部分可观测性并适应意外的环境变化。在AndroidWorld和我们扩展的长程任务套件上的实验表明，AgentProg在这些基准测试中取得了最先进的成功率。更重要的是，它在长程任务上保持了稳健的性能，而基线方法则经历了灾难性的性能下降。我们的系统已开源。

---

### 4 Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning

**link**: https://arxiv.org/pdf/2512.10534.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 大型语言模型（LLM）代理展现出强大的数学问题解决能力，在形式化证明系统的辅助下甚至可以解决国际数学奥林匹克（IMO）级别的问题。然而，由于辅助构造的启发式方法较弱，几何问题求解的AI仍由AlphaGeometry 2等专家模型主导，这些模型严重依赖大规模数据合成和搜索进行训练和评估。在这项工作中，我们首次尝试构建奖牌级别的几何LLM代理，并提出InternGeometry。InternGeometry通过迭代提出命题和辅助构造、使用符号引擎进行验证，并反思引擎的反馈以指导后续提议，从而克服几何中的启发式限制。动态内存机制使InternGeometry能够每个问题与符号引擎进行超过两百次的交互。为进一步加速学习，我们引入复杂度增强强化学习（CBRL），在训练阶段逐步增加合成问题的复杂度。基于InternThinker-32B构建的InternGeometry解决了50道IMO几何问题中的44道（2000-2024年），超过了金牌得主的平均分数（40.9），仅使用13K训练样本，仅为AlphaGeometry 2所用数据的0.004%，展示了LLM代理在专家级几何任务上的潜力。InternGeometry还可以为IMO问题提出人类解法中未出现的新辅助构造。我们将发布模型、数据和符号引擎以支持未来研究。

---

### 5 Decoupled Q-Chunking

**link**: https://arxiv.org/pdf/2512.10926.pdf  
**date**: 2025-12-12  
**keywords**: cs.LG  
**abs**: 时间差分（TD）方法通过自举未来价值预测高效学习状态和动作值，但存在自举偏差问题。本文提出解耦Q-Chunking方法，将批评家的动作序列（chunk）长度与策略的chunk长度解耦，允许策略在更短的动作chunk上操作。该算法通过针对部分动作chunk的蒸馏批评家优化策略，保留多步值传播优势，同时避免开环次优性和长chunk策略学习困难。在长期离线目标条件任务上的评估表明，该方法优于先前方法，涉及Agent Memory中动作序列记忆与策略优化的关联。

---

### 6 ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples

**link**: https://arxiv.org/pdf/2512.09931.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 学习在与个人相关的例子结合时最有效，但现有教育AI工具缺乏对学习者动态变化的适应。ExaCraft通过结合用户定义的个人档案（位置、教育、职业等）和实时学习行为分析，生成个性化教育例子。其核心创新在于适应学习上下文的五个关键方面：困难指标、掌握模式、主题进展历史、会话边界和学习进展信号，实现从基础概念到高级应用的动态例子生成，涉及Personal Memory中用户个性化信息与学习历史的存储与应用。

---

### 7 Suzume-chan: Your Personal Navigator as an Embodied Information Hub

**link**: https://arxiv.org/pdf/2512.09932.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 为解决数字工具缺乏深度沟通连接感的问题，本研究基于社会存在理论提出“具身信息中心”概念。原型Suzume-chan是一个本地运行语言模型和检索增强生成（RAG）的软AI代理，能从口头解释中学习并通过对话响应，减少心理距离。该代理作为个人导航器，通过物理和会话交互共享知识，涉及Agent Memory（存储学习到的知识）和Personal Memory（个性化信息管理）。

---

### 8 On Decision-Making Agents and Higher-Order Causal Processes

**link**: https://arxiv.org/pdf/2512.10937.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 我们建立了部分可观测马尔可夫决策过程（POMDPs）中的决策智能体与单输入过程函数（高阶量子操作的经典极限）之间的精确对应关系。在这种对应中，智能体的策略和记忆更新结合形成一个过程函数w，该函数通过链接乘积与POMDP环境相互作用。这暗示了一种双重解释：从物理学角度，过程函数充当环境，局部操作（智能体干预）被插入其中；而从人工智能角度，它对智能体进行编码，插入的函数代表环境。我们通过将观测独立的分布式POMDPs确定为多输入过程函数的自然域，将这一观点扩展到多智能体系统。

---

### 9 Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution

**link**: https://arxiv.org/pdf/2512.10696.pdf  
**date**: 2025-12-12  
**keywords**: cs.AI  
**abs**: 程序性记忆使大型语言模型（LLM）智能体能够内化“如何做”的知识，理论上可减少冗余的试错。然而，现有框架主要受限于“被动积累”范式，将记忆视为静态的仅追加档案。为弥合静态存储与动态推理之间的差距，我们提出了ReMe（Remember Me, Refine Me），一个用于经验驱动智能体进化的综合框架。ReMe通过三种机制在记忆生命周期中进行创新：1）多方面蒸馏，通过识别成功模式、分析失败触发因素和生成比较见解来提取细粒度经验；2）上下文自适应重用，通过场景感知索引将历史见解适配新上下文；3）基于效用的优化，自主添加有效记忆并修剪过时记忆，以维持紧凑、高质量的经验池。在BFCL-V3和AppWorld上的大量实验表明，ReMe在智能体记忆系统中建立了新的最先进水平。关键的是，我们观察到显著的记忆缩放效应：配备ReMe的Qwen3-8B性能优于更大但无记忆的Qwen3-14B，表明自进化记忆为终身学习提供了计算高效的途径。我们发布了代码和相关资源。

---

### 10 Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale

**link**: https://arxiv.org/pdf/2512.10398.pdf  
**date**: 2025-12-12  
**keywords**: cs.CL  
**abs**: 本文提出了Confucius Code Agent (CCA)，一个开源的工业级AI软件工程师。该代理基于Confucius SDK构建，该平台围绕代理体验（AX）、用户体验（UX）和开发者体验（DX）设计，核心包含用于长上下文推理的分层工作记忆、支持跨会话持续学习的持久笔记系统，以及模块化扩展模块。这些机制使CCA能够在长会话中维持持久记忆，并实现跨会话的持续学习，直接关联Agent Memory研究。在SWE-Bench-Pro基准测试中，CCA的Resolve@1性能达到54.3%，显著优于现有编码代理，为工业级AI代理的开发和部署提供了透明、可扩展的基础。

---

### 11 Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders

**link**: https://arxiv.org/pdf/2512.10547.pdf  
**date**: 2025-12-12  
**keywords**: cs.LG  
**abs**: 键值（KV）缓存是长上下文大型语言模型（LLM）的主要内存瓶颈，但通常被视为不透明的数值张量。本文提出了STA-Attention框架，该框架利用Top-K稀疏自编码器（SAE）将KV缓存分解为可解释的“语义原子”。与标准L1正则化SAE不同，Top-K方法消除了收缩偏差，保留了注意力所需的精确点积几何结构。分析揭示了一个基本的“键值不对称性”：键向量作为高度稀疏的路由器，由“语义肘部”主导；而深度值向量则携带密集的内容负载，需要更大的预算。基于此结构，本文引入了双预算策略，选择性地保留信息最丰富的语义组件，同时过滤表示噪声。在Yi-6B、Mistral-7B、Qwen2.5-32B等模型上的实验表明，语义重建能够保持与原始模型相当的困惑度和零样本性能，有效弥合了机械可解释性与忠实注意力建模之间的差距。

---

### 12 Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing

**link**: https://arxiv.org/pdf/2512.10121.pdf  
**date**: 2025-12-12  
**keywords**: cs.CL  
**abs**: 该研究指出当前大型语言模型（LLMs）在垂直领域长文本生成中面临“不可能三角”（低幻觉、深层逻辑连贯、个性化表达），其瓶颈在于陷入“统计平滑陷阱”，即忽视了专家级写作中不可或缺的高熵信息获取和结构化认知过程。为此，提出DeepNews框架，一种agentic工作流，明确模拟资深金融记者的隐性认知过程。该框架整合三个核心模块：基于信息觅食理论的双粒度检索机制（强制10:1的饱和信息输入比以减少幻觉输出）、基于领域专家知识库（叙事模式）和原子块的schema-guided战略规划（构建稳健逻辑骨架）、以及对抗性约束提示（通过节奏中断和逻辑迷雾等策略打破模型生成文本中的概率平滑性）。实验揭示了深度财经报道中的“知识悬崖”：当检索上下文低于15,000字符时内容真实性崩溃，而超过30,000字符的高冗余输入可使无幻觉率（HFR）稳定在85%以上。在某顶级中文科技媒体的生态有效性盲测中，基于上一代模型（DeepSeek-V3-0324）构建的DeepNews系统提交接受率达25%，显著优于最先进模型（GPT-5）零样本生成的0%接受率。

---

### 13 PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset

**link**: https://arxiv.org/pdf/2512.10148.pdf  
**date**: 2025-12-12  
**keywords**: cs.CL  
**abs**: 个性化评论回复生成在用户信息有限的领域（如外卖平台）面临重大挑战。尽管大型语言模型（LLMs）具备强大的文本生成能力，但在缺乏上下文用户数据时往往产生通用回复，降低参与度和有效性。本研究提出PARAN（Persona-Augmented Review ANswering）系统，一种两阶段提示框架，可直接从短评论文本中推断显式（如用户陈述偏好）和隐式（如人口统计或风格线索）的persona属性。这些推断的persona属性被整合到回复生成提示中，以产生用户定制化回复。为鼓励多样化且忠实的生成，在推理过程中调整解码温度。通过韩国外卖应用的真实世界数据集评估，该方法在精确性、多样性和语义一致性方面表现出有效性。研究结果凸显persona增强提示在无需模型微调的情况下提升自动化回复相关性和个性化的作用。

---

### 14 Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning

**link**: https://arxiv.org/pdf/2512.10150.pdf  
**date**: 2025-12-12  
**keywords**: cs.CL  
**abs**: 随着大型语言模型（LLMs）的普及，其安全对齐变得日益重要。本文研究LLMs在适应新任务时出现的安全退化问题，将其归因于灾难性遗忘，并将微调时的安全保留问题构建为持续学习（CL）问题。考虑“微调即服务”场景：用户上传数据至服务提供商以获取定制模型，该模型需在用户选定任务上表现优异。研究适配了文献中的多种CL方法，并系统评估其缓解安全退化的能力，包括正则化、基于记忆和模型合并方法。考虑两种场景：（1）良性用户数据；（2）中毒用户数据。结果表明，CL方法始终比标准微调实现更低的攻击成功率。其中，DER（Dynamic Elastic Weight Consolidation）方法优于其他CL方法和现有安全保留基线，同时保持任务效用。这些发现在三个下游任务（GSM8K、SST2、Code）和三个模型家族（LLaMA2-7B、Mistral-7B、Gemma-2B）上具有泛化性，确立了CL作为保留LLM安全性的实用解决方案。
### 1 A Unification of Discrete, Gaussian, and Simplicial Diffusion

**link**: https://arxiv.org/pdf/2512.15923.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文构建了一个理论框架，将离散空间扩散、欧几里得空间高斯扩散和单纯形扩散这三种离散序列建模方法统一为同一底层过程（Wright-Fisher群体遗传学模型）的不同参数化形式。研究发现，单纯形和高斯扩散是两种大群体极限情况，该理论正式连接了这些模型的似然和超参数，并利用数学遗传学文献实现了稳定的单纯形扩散。实验表明，可以训练一个单一模型在测试时在这三个域中执行扩散。

---

### 2 A Unified Generative-Predictive Framework for Deterministic Inverse Design

**link**: https://arxiv.org/pdf/2512.15746.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 该论文提出Janus框架，用于解决异质材料微观结构的确定性逆设计问题。Janus结合深度编码器-解码器架构与预测性KHRONOS头，学习一个潜在流形，该流形同时对生成逆设计等距且对物理预测进行剪枝，联合目标诱导潜在空间的解耦。在MNIST数据集和热导率标记的异质微观结构上验证，实现正向预测精度R²=0.98和低于5%的像素级重建误差，逆解满足目标属性在1%相对误差内，计算成本低于传统优化方法。

---

### 3 GLOW: Graph-Language Co-Reasoning for Agentic Workflow Performance Prediction

**link**: https://arxiv.org/pdf/2512.15751.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 该论文提出GLOW框架，用于智能体工作流（AW）性能预测。GLOW结合图神经网络（GNN）的图结构建模能力与大型语言模型（LLM）的推理能力，引入面向图的LLM以提取拓扑感知语义特征，与GNN编码的结构表示融合，并通过对比对齐策略优化潜在空间。在FLORA-Bench上的实验表明，GLOW在预测准确性和排序效用上优于最先进的基线。

---

### 4 ReactorFold: Generative discovery of nuclear reactor cores via emergent physical reasoning

**link**: https://arxiv.org/pdf/2512.15756.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文介绍ReactorFold框架，将燃料组件设计重新表述为语言模型的序列建模问题。利用蒙特卡洛数据、参数高效微调以及直接偏好优化（DPO），模型学习压水堆组件的潜在结构，并在单次前向传播中生成候选布局。模型表现出涌现的设计空间扩展能力，能自主调整钆可燃吸收体（Gd）库存量以满足功率峰值约束，并发现高性能的非对称配置，挑战传统对称装载启发式方法。

---

### 5 SALVE: Sparse Autoencoder-Latent Vector Editing for Mechanistic Control of Neural Networks

**link**: https://arxiv.org/pdf/2512.15938.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文提出SALVE框架，通过L1正则化自编码器学习稀疏的模型原生特征基，无需监督。利用Grad-FAM方法将潜在特征与输入数据视觉关联以验证特征，并基于自编码器结构进行精确的权重空间干预，实现类定义和跨类特征的连续调制。在ResNet-18和ViT-B/16模型上验证，实现对其行为的一致可解释控制。

---

### 6 Provably Extracting the Features from a General Superposition

**link**: https://arxiv.org/pdf/2512.15987.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文研究从黑盒查询访问中学习叠加态特征的基本设置：给定函数f(x)=∑a_iσ_i(v_i^⊤x)，其中每个单位向量v_i编码特征方向，σ_i是任意响应函数，目标是恢复v_i和函数f。

---

### 7 Sharpness-aware Second-order Latent Factor Model for High-dimensional and Incomplete Data

**link**: https://arxiv.org/pdf/2512.16277.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文提出锐度感知SLF（SSLF）模型，解决二阶潜因子模型优化挑战。SSLF包含两个关键思想：通过Hessian向量积获取二阶信息；通过设计的Hessian向量积将锐度项注入曲率中。在多个工业数据集上的实验表明，该模型持续优于最先进的基线方法。

---

### 8 Topic Modelling Black Box Optimization

**link**: https://arxiv.org/pdf/2512.16445.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文将潜在狄利克雷分配（LDA）中主题数量$T$的选择表述为离散黑盒优化问题。在固定评估预算下，比较了遗传算法（GA）、进化策略（ES）、偏好摊销黑盒优化（PABBO）和锐度感知黑盒优化（SABBO）。实验表明，摊销式优化器（PABBO和SABBO）在样本和时间效率上显著更优，SABBO通常在一次评估后确定接近最优的主题数量。

---

### 9 KOSS: Kalman-Optimal Selective State Spaces for Long-Term Sequence Modeling

**link**: https://arxiv.org/pdf/2512.16723.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文提出KOSS模型，将选择表述为潜在状态不确定性最小化。KOSS采用由卡尔曼增益驱动的连续时间潜在更新，实现闭环、上下文感知的选择机制，并采用全局谱微分和分段扫描确保稳定计算。在带干扰的选择性复制任务和九个长期预测基准上，KOSS降低了2.92-36.23%的MSE，并在准确性和稳定性上优于最先进模型。

---

### 10 Tiny Recursive Control: Iterative Reasoning for Efficient Optimal Control

**link**: https://arxiv.org/pdf/2512.16824.pdf  
**date**: 2025-12-19  
**keywords**: cs.LG  
**abs**: 本文提出TRC架构，通过两级分层潜在结构重复应用紧凑网络（约1.5M参数），通过模拟轨迹并基于跟踪误差进行校正来优化控制序列。在非线性控制问题上评估，TRC实现接近最优的控制成本，在GPU上仅需毫秒级推理时间和不到10MB内存，比语言模型基线小两个数量级。

---

### 11 In-Context Algebra

**link**: https://arxiv.org/pdf/2512.16902.pdf  
**date**: 2025-12-19  
**keywords**: cs.CL  
**abs**: 本文研究了Transformer在符号序列算术问题上的机制，其中符号含义仅通过相互作用确定。模型发展出三种机制：交换复制、单位元识别和基于封闭性的消去。实验表明，当训练模型在含义不固定的变量上进行上下文推理时，模型会发展出符号推理机制，并能推广到未见过的代数群。

---

### 12 Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics

**link**: https://arxiv.org/pdf/2512.16602.pdf  
**date**: 2025-12-19  
**keywords**: cs.CL  
**abs**: 本文提出“拒绝导向”方法，用于对大型语言模型在政治敏感话题上的拒绝行为进行细粒度控制。该方法用LLM作为评判者分配拒绝置信度分数，并提出岭正则化变体计算导向向量。在Qwen3-Next-80B模型上，消除了政治敏感话题的拒绝行为，同时保持安全性，并在4B和80B模型上泛化。

---

### 13 An Information-Theoretic Framework for Robust Large Language Model Editing

**link**: https://arxiv.org/pdf/2512.16227.pdf  
**date**: 2025-12-19  
**keywords**: cs.CL  
**abs**: 本文提出基于信息瓶颈理论的LLM编辑框架，精确压缩和隔离知识校正所需信息，最小化对无关行为的干扰。基于此，提出信息瓶颈知识编辑器（IBKE），利用紧凑的latent表示指导基于梯度的更新。在多个LLM架构和基准上验证，IBKE实现了最先进的准确性，并提高了编辑的通用性和特异性。

---

### 14 LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference

**link**: https://arxiv.org/pdf/2512.16843.pdf  
**date**: 2025-12-19  
**keywords**: cs.CL  
**abs**: 本文提出LLMCache框架，通过基于输入序列语义相似性重用中间激活来加速Transformer推理。LLMCache与模型无关，适用于编码器和解码器架构，并引入轻量级指纹识别机制和自适应驱逐策略。在BERT和GPT-2上的实验显示，推理时间加速高达3.1倍，准确率下降<0.5%。

---

### 15 Constructive Circuit Amplification: Improving Math Reasoning in LLMs via Targeted Sub-Network Updates

**link**: https://arxiv.org/pdf/2512.16914.pdf  
**date**: 2025-12-19  
**keywords**: cs.CL  
**abs**: 本文提出构造性电路放大方法，从模型推理轨迹中识别关键令牌及负责目标任务的模型组件，并仅更新这些组件。应用于数学推理，在多个模型上准确率提高高达+11.4%，仅修改1.59%的模型组件，对其他能力影响最小。

---

### 16 CitySeeker: How Do VLMS Explore Embodied Urban Navigation With Implicit Human Needs?

**link**: https://arxiv.org/pdf/2512.16755.pdf  
**date**: 2025-12-19  
**keywords**: cs.AI  
**abs**: 本文引入CitySeeker基准，评估视觉语言模型（VLMs）在解读隐含人类需求（如“我渴了”）的具身城市导航中的能力。CitySeeker包含8个城市的6440条轨迹，实验表明顶级模型任务完成率仅为21.1%。瓶颈在于长程推理误差、空间认知不足和经验回忆缺陷，并探索回溯机制、丰富空间认知和基于记忆的检索等启发式策略。

---

### 17 Unsupervised Thematic Clustering Of hadith Texts Using The Apriori Algorithm

**link**: https://arxiv.org/pdf/2512.16694.pdf  
**date**: 2025-12-19  
**keywords**: cs.AI  
**abs**: 本研究采用Apriori算法的无监督学习方法，对布哈里圣训的印尼语译本进行主题分组。预处理后，使用Apriori算法进行关联规则挖掘，结果显示有意义的关联模式（如“rakat-祈祷”、“经文-启示”），描述崇拜、启示和圣训叙述主题，表明Apriori算法能自动揭示潜在语义关系。
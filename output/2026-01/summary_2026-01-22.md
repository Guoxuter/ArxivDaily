### 1 Chain-of-Memory: Lightweight Memory Construction with Dynamic Evolution for LLM Agents

**link**: https://arxiv.org/pdf/2601.14287.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 外部记忆系统对于大型语言模型（LLM）智能体维持持久知识和执行长程决策至关重要。现有范式通常分为计算成本高昂的记忆构建（如将数据结构化成语义图）和简单的检索增强生成两个阶段，但存在构建成本高且性能增益有限、简单上下文拼接无法弥合检索召回与推理准确性差距的问题。为此，本文提出CoM（Chain-of-Memory）框架，倡导轻量级构建与复杂利用的范式转变。CoM引入记忆链机制，通过动态演化将检索到的片段组织成连贯的推理路径，并利用自适应截断修剪无关噪声。在LongMemEval和LoCoMo基准上的实验表明，CoM优于强基线，准确率提升7.5%-10.4%，同时将计算开销大幅降低至约2.7%的token消耗和6.0%的延迟。  

---

### 2 Re-understanding Graph Unlearning through Memorization

**link**: https://arxiv.org/pdf/2601.14694.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 图遗忘（GU）旨在从训练好的图神经网络（GNN）中移除节点、边或特征，这在包含敏感、错误标记或恶意信息的Web应用中至关重要。然而现有GU方法缺乏对决定遗忘效果关键因素的清晰理解，导致评估不准确、对难遗忘任务无效以及评估协议错位等问题。为此，本文将GNN记忆确立为理解图遗忘的新视角，并提出MGU（记忆引导的图遗忘框架）。MGU实现了三项关键进展：提供跨不同GU任务的准确实用难度评估、开发基于难度级别动态调整遗忘目标的自适应策略，以及建立符合实际需求的综合评估协议。在十个真实世界图数据集上的实验表明，MGU在遗忘质量、计算效率和效用保留方面持续优于最先进的基线方法。  

---

### 3 Multi-context principal component analysis

**link**: https://arxiv.org/pdf/2601.15239.pdf  
**date**: 2026-01-22  
**keywords**: stat.ML  
**abs**: 主成分分析（PCA）是捕获解释数据变异因素的工具。在多个领域中，数据是在多种情境下收集的（例如不同疾病的个体、不同类型的细胞或文本中的单词）。虽然解释数据变异的因素无疑在部分情境子集中共享，但目前尚无工具能系统地恢复这些因素。本文提出了多情境主成分分析（MCPCA），这是一个将数据分解为跨情境子集共享因素的理论和算法框架。将其应用于基因表达数据，MCPCA揭示了跨部分癌症类型共享的变异轴，以及肿瘤细胞中与肺癌进展相关的变异性（而非均值）轴。应用于语言模型的情境化词嵌入时，MCPCA绘制了关于人性辩论的阶段，揭示了数十年间科学与虚构之间的讨论。这些轴无法通过跨情境合并数据或局限于单个情境来发现。MCPCA是PCA的原则性扩展，旨在解决理解跨情境数据背后因素的挑战。  

---

### 4 VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models

**link**: https://arxiv.org/pdf/2601.14354.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 联合嵌入预测架构（JEPA）通过预测潜在表示而非重构高熵观测值，为自监督学习提供了可扩展范式。然而，现有公式依赖确定性回归目标，掩盖了概率语义并限制了其在随机控制中的应用。本文提出变分JEPA（VJEPA），这是一种概率泛化方法，通过变分目标学习未来潜在状态的预测分布。研究表明，VJEPA将表示学习与预测状态表示（PSRs）和贝叶斯滤波统一起来，证明序列建模不需要自回归观测似然。理论上，证明了VJEPA表示可作为最优控制的充分信息状态，无需像素重构，并提供避免崩溃的形式化保证。进一步提出贝叶斯JEPA（BJEPA），将预测信念分解为学习的动力学专家和模块化先验专家，通过专家乘积实现零样本任务迁移和约束（如目标、物理）满足。实验中，在噪声环境下，VJEPA和BJEPA成功过滤了导致生成基线表示崩溃的高方差干扰因素。通过支持原则性不确定性估计（如通过采样构建可信区间）同时对观测保持无似然性，VJEPA为高维噪声环境中可扩展、鲁棒、不确定性感知的规划提供了基础框架。  

---

### 5 Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence

**link**: https://arxiv.org/pdf/2601.14487.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 混沌动力系统的长 horizon 自回归预测由于误差快速放大和分布偏移而具有挑战性：小的单步不准确性会复合为物理上不一致的展开和大规模统计量的崩溃。本文引入 MSR-HINE，这是一种分层隐式预测器，通过在不同时间尺度上运行的多速率循环模块增强多尺度潜在先验。在每一步，从粗到细的循环状态生成潜在先验，隐式单步预测器通过多尺度潜在注入细化状态，与后验潜在的门控融合强制尺度一致的更新；轻量级隐藏状态校正进一步使循环记忆与融合潜在对齐。所得架构在慢流形上保持长期上下文，同时保留快尺度变异性，减少混沌展开中的误差累积。在两个标准基准上，MSR-HINE 相比 U-Net 自回归基线取得显著改进：在 Kuramoto-Sivashinsky 上，H=400 时 end-horizon RMSE 降低 62.8%，end-horizon ACC 提高 +0.983（从 -0.155 到 0.828），将 ACC >= 0.5 的可预测性 horizon 从 241 步扩展到 400 步；在 Lorenz-96 上，H=100 时 RMSE 降低 27.0%，end-horizon ACC 提高 +0.402（从 0.144 到 0.545），将 ACC >= 0.5 的 horizon 从 58 步扩展到 100 步。  

---

### 6 Robustness of Mixtures of Experts to Feature Noise

**link**: https://arxiv.org/pdf/2601.14792.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 尽管混合专家模型（MoE）在实践中取得了成功，但尚不清楚为何它们能超越密集网络，不仅仅是因为参数规模的扩大。本文研究了等参数机制，其中输入具有潜在的模块化结构，但受到特征噪声（内部激活噪声的代理）的干扰。研究表明，稀疏专家激活起到噪声过滤器的作用：与密集估计器相比，MoE在特征噪声下实现了更低的泛化误差，增强了对扰动的鲁棒性，并加快了收敛速度。在合成数据和现实世界语言任务上的实证结果证实了理论见解，展示了稀疏模块化计算带来的一致鲁棒性和效率提升。  

---

### 7 Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting

**link**: https://arxiv.org/pdf/2601.14862.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 我们引入了战略原则语言模型（sdLM），这是一个用于多文档战略推理的学习系统框架，具有原则一致性约束和校准不确定性。该方法结合了多文档注意力、时间编码和原则一致性层，以改进长期预测和计划合理性，同时减少严重的原则违反。我们使用（i）专家小组对战略场景的评分（N=47），（ii）336份原则出版物（12,847条陈述）的原则一致性，以及（iii）127个历史反事实（1945-2020）在12-60个月范围内的地缘政治预测来评估sdLM。在这些基准测试中，sdLM比强大的通用LLM基线实现了更高的战略质量和更好的校准，并且在长期判断上与人类专家保持竞争力。我们进一步报告了消融实验、缩放趋势以及面向部署的性能/延迟特性，以阐明哪些组件驱动改进以及它们如何转化为操作设置。  

---

### 8 Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure

**link**: https://arxiv.org/pdf/2601.15077.pdf  
**date**: 2026-01-22  
**keywords**: cs.CL  
**abs**: 多智能体系统（MAS）通常表现出更优的问题解决性能，尽管它们基于相同的信息运行。本文基于算子理论和约束优化为此现象提供了形式化解释：将每个智能体建模为对共享解状态施加不同有效性约束的执行者，证明MAS实现了约束执行算子的分解组合。在温和条件下，这些动态收敛到由智能体约束集交集定义的不变解集合。这种不变结构通常无法被单个智能体同时应用所有约束动态访问，即使表达能力和信息相同。研究将结果从精确约束执行扩展到通过近端算子的软约束，并应用于当代基于文本的对话系统。  

---

### 9 Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning

**link**: https://arxiv.org/pdf/2601.15086.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 现实世界中的有效决策依赖于既稳定又自适应的记忆：环境随时间变化，智能体必须在长时间范围内保留相关信息，同时在环境变化时更新或覆盖过时内容。现有的强化学习（RL）基准和记忆增强智能体主要关注记忆保留，而忽略了同样关键的记忆重写能力。为解决这一差距，本文引入了一个明确测试部分可观测性下持续记忆更新的基准（即智能体必须依赖记忆而非当前观测的自然场景），并用于比较循环、 transformer 基和结构化记忆架构。实验表明，尽管经典循环模型简单，但在记忆重写任务中表现出比现代结构化记忆（仅在有限条件下成功）和 transformer 基智能体（在非 trivial 保留场景外常失败）更高的灵活性和鲁棒性。这些发现揭示了当前方法的根本局限性，强调需要平衡稳定保留与自适应更新的记忆机制。本文突出了这一被忽视的挑战，引入评估基准，并为设计具有显式可训练遗忘机制的未来 RL 智能体提供见解。  

---

### 10 Field-Space Autoencoder for Scalable Climate Emulators

**link**: https://arxiv.org/pdf/2601.15102.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 公里尺度的地球系统模型对于捕捉局部气候变化至关重要，但计算成本高昂且产生PB级输出，限制了其在概率风险评估等应用中的实用性。本文提出Field-Space Autoencoder，一种基于球面压缩模型的可扩展气候模拟框架，通过Field-Space Attention高效处理原生气候模型输出，避免将球面数据强制映射到欧几里得网格导致的几何扭曲。该方法比卷积基线更好地保留物理结构，生成的结构化压缩场可作为下游生成式模拟的良好基线，并能执行零样本超分辨率，将低分辨率大集合和稀缺高分辨率数据映射到共享表示。在压缩场上训练的生成扩散模型可同时从丰富的低分辨率数据中学习内部变异性，从稀疏高分辨率数据中学习精细尺度物理。  

---

### 11 Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data

**link**: https://arxiv.org/pdf/2601.15158.pdf  
**date**: 2026-01-22  
**keywords**: cs.LG  
**abs**: 通过结果导向监督的强化学习（RL）训练的Transformer能够自发发展生成中间推理步骤（思维链）的能力，但其机制尚不明确。本文通过分析单层Transformer在合成图遍历任务上的梯度流动态，证明尽管仅基于最终答案正确性训练，梯度流仍会驱动模型收敛到结构化、可解释的算法，逐顶点迭代遍历图。研究确定了这种涌现所需的分布特性，强调“简单示例”（需较少推理步骤的实例）的关键作用：当训练分布对简单实例赋予足够权重时，模型学习可泛化的遍历策略；反之则学习不可行。理论结果在合成数据和真实世界数学推理任务上得到验证。  

---

### 12 Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems

**link**: https://arxiv.org/pdf/2601.14662.pdf  
**date**: 2026-01-22  
**keywords**: cs.AI  
**abs**: 基于图的检索增强生成（GraphRAG）系统会在文档集合上构建知识图谱以支持多跳推理。尽管先前的研究表明GraphRAG的响应可能会泄露检索到的子图，但在实际查询预算下，以查询高效的方式重建隐藏图结构的可行性仍未得到探索。本文研究了一种预算受限的黑盒场景，在此场景中，攻击者通过自适应地查询系统来窃取其潜在的实体 - 关系图。我们提出了AGEA（智能体图提取攻击）框架，该框架利用新颖性引导的探索 - 利用策略、外部图内存模块以及结合轻量级发现和基于LLM的过滤的两阶段图提取管道。我们在医疗、农业和文学数据集上对Microsoft - GraphRAG和LightRAG系统进行了评估。在相同的查询预算下，AGEA显著优于先前的攻击基线，能够恢复高达90%的实体和关系，同时保持较高的精度。这些结果表明，即使在严格的查询限制下，现代GraphRAG系统也极易受到结构化、智能体化的提取攻击。  

---

### 13 Project Aletheia: Verifier-Guided Distillation of Backtracking for Small Language Models

**link**: https://arxiv.org/pdf/2601.14290.pdf  
**date**: 2026-01-22  
**keywords**: cs.CL  
**abs**: 小型语言模型（SLMs，参数小于10B）因其适合私有设备部署而具有吸引力，但它们在严格的约束满足问题上经常失败，原因是其线性、过度自信的推理轨迹无法从早期错误中恢复。本文提出了验证器引导蒸馏（Verifier-Guided Distillation）训练协议，该协议传递错误修复过程——显式冲突检测和回溯——而非仅传递正确的最终答案。通过在包含错误和自我修正的已验证推理轨迹上训练7B模型，研究表明小型模型中可以出现潜在的验证行为，使其能够偶尔停止、检测矛盾并修正早期假设。  

---

### 14 Privacy Collapse: Benign Fine-Tuning Can Break Contextual Privacy in Language Models

**link**: https://arxiv.org/pdf/2601.15220.pdf  
**date**: 2026-01-22  
**keywords**: cs.CL  
**abs**: 本文发现了语言模型中的一种新现象：前沿模型的良性微调可能导致隐私崩溃。研究表明，训练数据中多样、微妙的模式（如优化有用性、暴露用户信息、情感和主观对话以及打印内部变量的调试代码等）会降低上下文隐私。微调后的模型失去了对上下文隐私规范的推理能力，会与工具不适当地共享信息，并跨越上下文违反记忆边界。隐私崩溃是一种“隐性失败”，因为模型在标准安全和效用基准上保持高性能，同时表现出严重的隐私漏洞。实验在六个模型（闭源和开源权重）、五个微调数据集（真实世界和受控数据）以及两个任务类别（智能体和基于记忆的）上证明了隐私崩溃的存在。机制分析显示，与保留的任务相关特征相比，隐私表征对微调特别脆弱。研究结果揭示了当前安全评估中的关键差距，尤其是在专用智能体部署方面。  

---

### 15 Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning

**link**: https://arxiv.org/pdf/2601.14750.pdf  
**date**: 2026-01-22  
**keywords**: cs.CL  
**abs**: 思维链（CoT）提示在释放大型语言模型（LLMs）的推理能力方面取得了显著成功。尽管CoT提示增强了推理能力，但其冗长性带来了大量计算开销。近期研究往往仅关注结果对齐，而缺乏对中间推理过程的监督，这些缺陷掩盖了潜在推理链的可分析性。为解决这些挑战，我们引入了Render-of-Thought（RoT），这是第一个通过将文本步骤渲染为图像来具体化推理链的框架，使潜在原理变得明确且可追踪。具体而言，我们利用现有视觉语言模型（VLMs）的视觉编码器作为语义锚点，将视觉嵌入与文本空间对齐。这种设计确保了即插即用的实现，且不会产生额外的预训练开销。在数学和逻辑推理基准上的大量实验表明，我们的方法与显式CoT相比实现了3-4倍的token压缩和显著的推理加速，同时与其他方法相比保持了竞争力的性能，验证了该范式的可行性。  

---

### 16 BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries

**link**: https://arxiv.org/pdf/2601.15197.pdf  
**date**: 2026-01-22  
**keywords**: cs.AI  
**abs**: 视觉-语言-动作（VLA）模型在机器人操作方面显示出潜力，但往往难以泛化到新指令或复杂的多任务场景。我们发现在当前训练范式中存在一个关键问题：目标驱动的数据收集导致数据集偏差。在此类数据集中，语言指令仅通过视觉观察即可高度预测，导致指令与动作之间的条件互信息消失，我们称之为信息坍缩现象。因此，模型退化为仅依赖视觉的策略，忽略语言约束，在分布外（OOD）设置中失败。为解决此问题，我们提出BayesianVLA，一种通过贝叶斯分解强制指令遵循的新框架。通过引入可学习的潜在动作查询（Latent Action Queries），我们构建了双分支架构，以估计视觉仅有的先验p(a | v)和语言条件化的后验π(a | v, ℓ)。然后，我们优化策略以最大化动作和指令之间的条件点互信息（PMI）。该目标有效惩罚视觉捷径，并奖励明确解释语言命令的动作。无需新数据，BayesianVLA显著提高了泛化能力。在SimplerEnv和RoboCasa上的大量实验证明了显著收益，包括在具有挑战性的OOD SimplerEnv基准上提高11.3%，验证了我们的方法将语言稳健地锚定到动作中的能力。
### 1 Randomization Boosts KV Caching, Learning Balances Query Load: A Joint Perspective

**link**: https://arxiv.org/pdf/2601.18999.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: KV缓存是加速大型语言模型（LLM）推理的基础技术，通过重用先前查询的键值（KV）对实现，但在内存有限情况下其有效性高度依赖于驱逐策略。默认的最近最少使用（LRU）驱逐算法在动态在线查询到达时表现不佳，尤其在多LLM服务场景中，平衡 worker 间的查询负载与最大化每个 worker 的缓存命中率存在内在冲突。本文提出首个统一数学模型，捕捉KV缓存驱逐与查询路由之间的核心权衡。分析揭示现有方法的理论局限性，并提出原则性算法，整合可证明竞争性的随机KV缓存驱逐与基于学习的方法，以自适应路由具有演化模式的查询，从而平衡查询负载与缓存命中率。实验在4个基准和3个前缀共享设置上验证了理论结果，相比最先进方法，缓存命中率提升高达6.92倍，延迟降低11.96倍，首 token 生成时间（TTFT）减少14.06倍，吞吐量增加77.4%。

---

### 2 FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning

**link**: https://arxiv.org/pdf/2601.19001.pdf
**date**: 2026-01-28
**keywords**: cs.CL
**abs**: 本文提出FROST，一种基于注意力的高效推理方法。与传统方法不同，FROST利用注意力权重修剪非关键推理路径，生成更短且更可靠的推理轨迹。方法上，引入推理异常值概念并设计基于注意力的机制来移除它们。理论上，FROST在消除句子级异常值的同时保留并增强模型的推理能力。实验上，使用两种强大的推理模型（Phi-4-Reasoning和GPT-OSS-20B）在四个基准上验证FROST，性能优于TALE和ThinkLess等最先进方法。值得注意的是，FROST相比基础模型平均减少69.68%的token使用量，并提高26.70%的准确率。此外，在注意力异常值指标评估中，FROST相比基础模型将最大无穷范数降低15.97%，平均峰度降低91.09%。

---

### 3 IPBC: An Interactive Projection-Based Framework for Human-in-the-Loop Semi-Supervised Clustering of High-Dimensional Data

**link**: https://arxiv.org/pdf/2601.18828.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 高维数据集在科学和工业领域日益常见，但由于距离度量的有效性降低以及聚类在投影到低维空间时容易坍塌或重叠，其有效聚类仍然困难。传统降维技术生成静态的2D或3D嵌入，可解释性有限，且无法利用分析师在探索过程中的直觉。为解决这一差距，本文提出交互式投影基聚类（IPBC）框架，将聚类重构为迭代的人类引导视觉分析过程。IPBC集成非线性投影模块与反馈循环，允许用户通过调整视角和提供简单约束（如必须链接或不能链接关系）来修改嵌入。这些约束重塑投影模型的目标，逐渐将语义相关点拉近，将无关点推远。随着投影通过用户交互变得更结构化和更具表达力，在优化后的2D布局上运行的传统聚类算法能更可靠地识别不同组。额外的可解释性组件将每个发现的聚类映射回原始特征空间，生成可解释的规则或特征排名，突出每个聚类的区别。在各种基准数据集上的实验表明，仅需少量交互式细化步骤即可显著提高聚类质量。总体而言，IPBC将聚类转变为机器表示和人类洞察力相互强化的协作发现过程。

---

### 4 The Geometric Reasoner: Manifold-Informed Latent Foresight Search for Long-Context Reasoning

**link**: https://arxiv.org/pdf/2601.18832.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 扩展测试时计算可增强长思维链（CoT）推理，但现有方法面临计算成本与覆盖质量之间的根本权衡：要么产生高昂的训练费用，要么产生冗余轨迹。本文介绍几何推理器（TGR），这是一种无训练框架，在严格内存限制下执行流形感知的潜在前瞻搜索。在每个块边界，TGR通过轻量级前瞻估计结合软几何正则化器对候选潜在锚点进行评分，这些正则化器鼓励平滑轨迹和多样化探索。块级KV缓存重置使内存与块长度呈线性关系。在具有挑战性的数学和代码基准测试中，TGR提高了稳健的轨迹覆盖，通过Pass@k曲线下面积（AUC）衡量，在Qwen3-8B上最多提高13个点，且开销可忽略（约1.1-1.3倍）。

---

### 5 Representational Homomorphism Predicts and Improves Compositional Generalization In Transformer Language Model

**link**: https://arxiv.org/pdf/2601.18858.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 组合泛化——解释熟悉组件的新组合的能力——仍然是神经网络的一个持久挑战。行为评估揭示模型何时失败，但在表征层面提供的失败原因洞察有限。本文引入同态误差（HE），这是一种量化表达式代数与模型隐藏状态空间之间近似同态偏差的结构度量。我们在SCAN风格任务中为两个组合运算符实例化HE：用于一元组合的修饰符HE和用于二元组合的序列HE，通过学习从部分预测组合表征的表征级运算符来测量。在小型解码器-only Transformer的受控实验中，HE预测噪声注入下的分布外（OOD）组合泛化，修饰符HE与OOD准确率之间达到R²=0.73的相关性。消融实验表明，模型深度对HE或OOD准确率影响最小，训练数据覆盖表现出阈值效应（覆盖不足会急剧增加HE并降低OOD性能），随机插入的噪声标记系统地增加HE。最后，我们测试HE正则化训练是否提高OOD准确率。实验表明，训练期间显式强制低修饰符HE显著降低修饰符HE（p=1.1x10⁻⁴）和序列HE（p=0.001），并产生统计上显著的OOD准确率提升（p=0.023）。这些结果表明HE有潜力成为诊断和改进组合泛化的可操作训练信号。

---

### 6 RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization

**link**: https://arxiv.org/pdf/2601.19404.pdf
**date**: 2026-01-28
**keywords**: latent reasoning
**abs**: 在大型语言模型领域，强化微调算法需要从输入查询开始生成完整的推理轨迹，这在训练的rollout阶段会产生显著的计算开销。为解决此问题，本文分析了推理路径不同段对最终结果正确性的影响，并基于这些见解提出了部分推理优化强化微调（RPO），这是一种即插即用的强化微调算法。与生成完整推理路径的传统强化微调算法不同，RPO通过经验缓存生成推理路径的后缀来训练模型。在训练的rollout阶段，RPO减少了约95%的令牌生成，大幅降低了理论时间开销。与全路径强化微调算法相比，RPO将1.5B模型的训练时间减少了90%，7B模型减少了72%。同时，它可以与GRPO和DAPO等典型算法集成，使它们在保持与原始算法相当性能的同时实现训练加速。

---

### 7 GAVEL: Towards rule-based safety through activation monitoring

**link**: https://arxiv.org/pdf/2601.19768.pdf
**date**: 2026-01-28
**keywords**: latent space
**abs**: 大型语言模型（LLMs）越来越多地与基于激活的监控相结合，以检测和防止表面文本层面可能不明显的有害行为。然而，现有的激活安全方法在广泛的误用数据集上训练，存在精度低、灵活性有限和缺乏可解释性的问题。本文引入了一种新范式：基于规则的激活安全，受网络安全中的规则共享实践启发。我们提出将激活建模为认知元素（CEs），即细粒度、可解释的因素，如“发出威胁”和“支付处理”，这些因素可以组合起来以更高的精度捕捉细微的、特定领域的行为。基于这种表示，我们提出了一个实用框架，该框架定义了关于CEs的谓词规则并实时检测违规行为。这使从业者能够在不重新训练模型或检测器的情况下配置和更新安全措施，同时支持透明度和可审计性。我们的结果表明，基于组合规则的激活安全提高了精度，支持领域定制，并为可扩展、可解释和可审计的AI治理奠定了基础。

---

### 8 CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation

**link**: https://arxiv.org/pdf/2601.19178.pdf
**date**: 2026-01-28
**keywords**: cs.AI, LLM Rec (大模型推荐)
**abs**: 序列推荐模型在应用中被广泛使用，但面临严格的延迟要求。主流模型利用Transformer注意力机制提升性能，但其计算复杂度随序列长度增加而增长，导致长序列的延迟问题。因此，KV缓存技术最近在序列推荐系统中被探索以降低推理延迟。然而，KV缓存在拥有大量用户和可能非常长的用户历史序列的序列推荐系统中引入了巨大的存储开销。在本研究中，我们观察到不同用户的KV序列存在显著相似性，表明KV中存在协同信号。此外，我们通过奇异值分解（SVD）分析KV，发现KV中的信息可分为两部分：大部分信息可在用户间共享，小部分为用户特定信息。受此启发，我们提出CollectiveKV，一种跨用户KV共享机制。它通过可学习的全局KV池捕获用户间共享的信息。在推理时，每个用户从池中检索高维共享KV，并将其与低维用户特定KV拼接以获得最终KV。在五个序列推荐模型和三个数据集上的实验表明，我们的方法可将KV缓存压缩至原始大小的0.8%，同时保持甚至提升模型性能。

---

### 9 MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution

**link**: https://arxiv.org/pdf/2601.19199.pdf
**date**: 2026-01-28
**keywords**: cs.AI, LLM Memory
**abs**: 由大型基础模型驱动的移动GUI代理能够自主执行任务，但频繁的更新改变UI外观和重组工作流，导致基于历史数据训练的代理失效。尽管存在表面变化，功能语义和任务意图本质上保持稳定。基于此见解，我们引入MAGNET，一种记忆驱动的自适应代理框架，具有双级记忆：静态记忆将多样的视觉特征与稳定的功能语义链接，以实现稳健的动作接地；过程记忆捕获不同工作流中的稳定任务意图。我们提出动态记忆进化机制，通过优先考虑频繁访问的知识来持续优化两种记忆。在线基准AndroidWorld评估显示其显著优于基线，离线基准也证实了在分布偏移下的持续增益。这些结果验证了利用界面变化中的稳定结构可提升代理在不断演变的软件环境中的性能和泛化能力。

---

### 10 GLOVE: Global Verifier for LLM Memory-Environment Realignment

**link**: https://arxiv.org/pdf/2601.19249.pdf
**date**: 2026-01-28
**keywords**: cs.AI, LLM Memory
**abs**: 大多数现有的记忆增强大型语言模型（LLM）方法隐含假设记忆有效性可通过提供任务特定成功信号的外部评估器或通过内部模型认知（如反思）来编辑记忆条目来建立。然而，在具有动态漂移的实际环境中，这些假设往往不成立。我们提出全局验证器（GLOVE），这是一个通过建立相对真理概念为LLM记忆系统引入新设计维度的框架。通过主动探测检索到的记忆与新观察之间的不一致性，GLOVE能够在无需访问真实监督或强烈依赖模型内省的情况下验证和更新记忆，实现记忆-环境重新对齐。我们在涵盖网页导航、规划和控制的多种基准上评估GLOVE，并添加了引入超出原始基准设置的非平稳性的受控环境漂移。结果表明，GLOVE显著提高了代理的成功率，为能够自我进化的认知代理提供了稳健途径。

---

### 11 From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation

**link**: https://arxiv.org/pdf/2601.19588.pdf
**date**: 2026-01-28
**keywords**: latent reasoning
**abs**: 针对无标注数据的大语言模型（LLM）领域适应这一关键挑战，本文提出了 divergence-guided reasoning curriculum (DGRC) 框架。该方法利用LLM在聚焦的原子子问题上表现出高保真度的特点，通过分析学生与教师模型的推理分歧，构建从原子知识到推理链的学习路径。当模型产生冲突结果时，DGRC引导教师进行诊断分析，生成针对分歧点的原子查询并自回答，形成原子课程和验证后的CoT课程，有效解决了教师模型推理缺陷继承问题。在医疗和法律领域的实验表明，1.5B学生模型在医疗领域相对性能提升7.76%。

---

### 12 Explicit Multi-head Attention for Inter-head Interaction in Large Language Models

**link**: https://arxiv.org/pdf/2601.19611.pdf
**date**: 2026-01-28
**keywords**: LLM Memory
**abs**: 本文提出了Multi-head Explicit Attention (MEA)，一种增强跨头交互的注意力变体。MEA包含头级线性组合（HLC）模块和头级组归一化层，前者对多头的键值向量进行可学习线性组合以促进跨头通信，后者对齐重组头的统计特性。MEA在预训练中表现出强鲁棒性，支持更大学习率加速收敛，降低验证损失并提升多任务性能。通过减少注意力头并利用HLC重构低秩“虚拟头”，实现KV缓存内存减少50%，在知识密集型和科学推理任务上性能损失可忽略。

---

### 13 R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning

**link**: https://arxiv.org/pdf/2601.19620.pdf
**date**: 2026-01-28
**keywords**: LLM Memory, latent reasoning
**abs**: 针对大语言模型强化学习中组内优势崩溃导致的训练脆弱性问题，本文提出R³机制，包含三个核心策略：（1）跨上下文回放策略，通过召回相同查询的历史轨迹维持组内优势；（2）上下文内自反思机制，利用过去失败经验优化输出；（3）结构熵排序奖励，基于 token 级熵模式对响应排序分配相对奖励。在数学领域的实验表明，该方法在多个基准上实现 state-of-the-art 性能，相比基础模型显著提升且使用更少推理 tokens。

---

### 14 Out-of-Distribution Generalization via Invariant Trajectories for Multimodal Large Language Model Editing

**link**: https://arxiv.org/pdf/2601.19700.pdf
**date**: 2026-01-28
**keywords**: LLM Memory, latent space
**abs**: 知识编辑是高效纠正大型语言模型（LLM）中错误或过时知识的关键技术。现有单模态LLM编辑方法依赖刚性的参数-输出映射，导致多模态LLM（MLLM）在级联推理中出现因果欠拟合和过拟合问题。本文将MLLM编辑重新表述为分布外（OOD）泛化问题，目标是辨别语义偏移与事实偏移，从而在多样的跨模态提示中实现稳健编辑。该问题的核心挑战在于识别具有泛化能力的不变因果轨迹，同时抑制虚假相关性。为此，提出ODEdit——一个基于不变学习的即插即用框架，通过优化三方OOD风险目标，同时增强编辑的可靠性、局部性。

---

### 15 TokenSeek: Memory Efficient Fine Tuning via Instance-Aware Token Ditching

**link**: https://arxiv.org/pdf/2601.19739.pdf
**date**: 2026-01-28
**keywords**: LLM Memory
**abs**: 微调被视为将大型语言模型（LLMs）适配下游任务的事实标准方法，但其源于LLMs的高训练内存消耗使该过程效率低下。在现有内存高效方法中，与激活相关的优化被证明特别有效，因为激活始终主导整体内存消耗。尽管现有技术提供了多种激活优化策略，但它们的数据无关特性最终导致微调效果不佳且不稳定。本文提出TokenSeek，一种通过实例感知令牌丢弃实现的通用插件解决方案，适用于各种基于Transformer的模型，在Llama3.2 1B模型上仅需14.8%的内存即可实现显著的微调内存节省，同时性能持平甚至更优。此外，可解释的令牌寻找过程揭示了其有效性的潜在原因，为未来令牌效率研究提供了宝贵见解。

---

### 16 When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering

**link**: https://arxiv.org/pdf/2601.19827.pdf
**date**: 2026-01-28
**keywords**: LLM Memory, latent reasoning
**abs**: 检索增强生成（RAG）将大型语言模型（LLMs）的能力扩展到参数化知识之外，但尚不清楚迭代检索-推理循环何时能显著优于静态RAG，尤其是在具有多跳推理、稀疏领域知识和异构证据的科学领域。本文首次进行受控的、机制层面的诊断研究，探讨同步迭代检索和推理是否能超越理想化的静态上限（黄金上下文）RAG。在三种机制下对十一种最先进的LLMs进行基准测试：（i）无上下文，衡量对参数化记忆的依赖；（ii）黄金上下文，一次性提供所有 oracle 证据；（iii）迭代RAG，一种无训练控制器，交替进行检索、假设精炼和证据感知停止。使用化学领域的ChemKGMultiHopQA数据集，隔离需要真正检索的问题，并通过检索覆盖缺口、锚点携带丢失、查询质量、组合保真度和控制校准等诊断分析行为。结果表明，跨模型的迭代RAG始终优于黄金上下文，增益高达25.6个百分点，尤其对于非推理微调模型。阶段性检索减少了后期跳失败，缓解了上下文过载，并能动态纠正早期假设漂移，但仍存在跳覆盖不完整、干扰项锁定轨迹、提前停止校准不当以及即使检索完美时组合失败率高等问题。总体而言，阶段性检索通常比仅存在理想证据更具影响力；本文为在专业科学环境中部署和诊断RAG系统提供了实用指导，并为更可靠、可控的迭代检索-推理框架奠定了基础。

---

### 17 Latent Structural Similarity Networks for Unsupervised Discovery in Multivariate Time Series

**link**: https://arxiv.org/pdf/2601.18803.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 本文提出了一种用于多变量时间序列的任务无关发现层，该层在不假设线性、平稳性或下游目标的情况下构建实体间的关系假设图。该方法使用无监督序列到序列自编码器学习窗口级序列表示，将这些表示聚合为实体级嵌入，并通过阈值化潜空间（latent-space）相似性度量来诱导稀疏相似性网络。该网络旨在作为一种可分析的抽象，压缩成对搜索空间并揭示候选关系以供进一步研究，而非针对预测、交易或任何决策规则优化的模型。该框架在每小时加密货币回报的具有挑战性的真实世界数据集上进行了演示，说明了潜相似性如何诱导连贯的网络结构；还报告了经典计量经济学关系作为外部诊断镜头来 contextualize 发现的边。

---

### 18 VAE with Hyperspherical Coordinates: Improving Anomaly Detection from Hypervolume-Compressed Latent Space

**link**: https://arxiv.org/pdf/2601.18823.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 变分自编码器（VAE）将数据编码为低维潜向量，然后将这些向量解码回数据。训练后，人们希望能检测分布外（异常）潜向量，但当潜空间（latent space）维度较高时会出现问题，包括超体积随维度指数增长，严重影响VAE的生成能力。本文借鉴高维统计知识：在此情况下，标准VAE的潜向量分布在超球面的“赤道”上，给异常检测带来挑战。本文提出使用超球面坐标来构建VAE的潜变量，允许潜向量向超球面上的特定方向压缩，从而获得更具表达力的近似后验。这提高了VAE的全无监督和分布外异常检测能力，在考虑的数据集上均取得最佳性能，超过现有方法。在无监督和分布外模式下，分别为：i）检测火星车相机的异常景观和地面图像的异常星系（复杂真实世界数据集）；ii）Cifar10和ImageNet子集作为分布内类别等标准基准。

---

### 19 RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering

**link**: https://arxiv.org/pdf/2601.19225.pdf
**date**: 2026-01-28
**keywords**: cs.CL
**abs**: 大型语言模型（LLMs）虽具备卓越推理能力，但在知识密集型任务中易产生幻觉。检索增强生成（RAG）通过将答案锚定在外部知识源（如知识图谱）来缓解此问题。然而，现有基于知识图谱的RAG方法依赖语义无关的路径采样，与知识图谱推理目标对齐较弱，且未将检索路径组织为以答案为中心的推理路径，限制了小型LLM利用检索知识的能力。此外，现有工作多依赖大型LLM或7B以上参数模型，对7B以下模型探索不足。本文提出RPO-RAG，这是首个专为小型LLM设计的基于知识图谱的RAG框架。其核心创新包括：（1）查询-路径语义采样策略，提供信息丰富的监督信号；（2）关系感知偏好优化，使训练与中间知识图谱推理信号（如关系）对齐；（3）以答案为中心的提示设计，以可解释格式组织实体和推理路径。在WebQSP和CWQ两个知识图谱问答基准数据集上的广泛实验表明，RPO-RAG有效缩小了小型与大型语言模型的性能差距。在WebQSP上，F1提升高达8.8%，反映出答案精度的提高；在CWQ上，它在8B以下模型中实现了命中率和F1的新state-of-the-art。总体而言，RPO-RAG显著提升了小型LLM（甚至3B以下参数）的推理能力，凸显了其在资源高效和实用的设备端知识图谱问答应用中的潜力。

---

### 20 Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model

**link**: https://arxiv.org/pdf/2601.19232.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: RNA逆折叠（设计形成特定3D结构的序列）在治疗、基因调控和合成生物学中至关重要。现有方法侧重于序列恢复，难以解决二级结构一致性（SS）、最小自由能（MFE）和局部距离差异测试（LDDT）等结构目标，导致结构准确性欠佳。为此，本文提出一种结合强化学习（RL）与潜在扩散模型（LDM）的框架。借鉴扩散模型在RNA逆折叠中的成功，开发了整合大规模RNA模型预训练RNA-FM嵌入的LDM，该嵌入捕获共进化模式，显著提高序列恢复准确性。然而，包括基于扩散的方法在内的现有方法无法有效处理非可微结构目标。相比之下，RL通过策略驱动的奖励优化在复杂非梯度目标中表现出色。本文提出分步优化潜在扩散模型（SOLD），一种新颖的RL框架，无需采样完整扩散轨迹即可优化单步噪声，实现多结构目标的高效优化。实验结果表明，SOLD在所有指标上均优于其LDM基线和最先进方法，为RNA逆折叠建立了强大框架，对生物技术和治疗应用具有深远意义。

---

### 21 Riddle Quest : The Enigma of Words

**link**: https://arxiv.org/pdf/2601.19273.pdf
**date**: 2026-01-28
**keywords**: cs.CL
**abs**: 谜语是通过间接、比喻或趣味线索描述物体或概念的简洁语言谜题，是一种长期存在的创造性表达形式，要求解谜者解释线索、识别模式并推断答案。本文提出一种用于创建和评估基于类比的谜语的简单pipeline，包括构建概念结构化事实的三元组创建器、选择类比有用属性的语义映射器、将属性转化为谜语线索的风格化生成器，以及收集谜语可能指向的所有答案的验证器。利用该验证器研究大型语言模型是否能恢复不同类型谜语的完整答案集。案例研究表明，尽管模型通常能猜出主要预期答案，但经常遗漏其他有效解释。这凸显了谜语作为检查语言模型推理覆盖范围和歧义处理能力的轻量级工具的价值。

---

### 22 Group Distributionally Robust Optimization-Driven Reinforcement Learning for LLM Reasoning

**link**: https://arxiv.org/pdf/2601.19280.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 大型语言模型（LLM）推理的最新进展越来越多地由训练后损失函数和对齐策略的改进推动。然而，诸如组相对策略优化（GRPO）等标准强化学习（RL）范式仍受限于静态均匀性：均匀的提示采样和每个提示固定数量的滚动。对于异构、重尾的推理数据，这会造成结构低效，在已解决模式上浪费计算资源，同时对困难问题的长尾部分训练不足。为解决此问题，本文提出多对抗组分布鲁棒优化（GDRO），这是一种超越均匀推理模型的优化优先框架，通过动态调整训练分布来解决上述问题。

---

### 23 When Benchmarks Leak: Inference-Time Decontamination for LLMs

**link**: https://arxiv.org/pdf/2601.19334.pdf
**date**: 2026-01-28
**keywords**: cs.CL
**abs**: 基于基准的评估是比较大型语言模型（LLMs）的标准方法，但其可靠性受到测试集污染的威胁，即测试样本或其近似变体泄露到训练数据中，人为地提高报告性能。为解决此问题，现有工作探索了两种缓解途径：一种是在评估前识别并移除受污染的基准项目，但这不可避免地会改变评估集本身，且在污染程度中等或严重时不可靠；另一种是保留基准，而是在评估时抑制受污染行为，但此类干预通常会干扰正常推理，并导致干净输入的性能显著下降。本文提出DeconIEP，一种完全在评估期间运行的去污染框架，通过在输入嵌入空间中应用小的、有界的扰动来实现。在一个污染程度相对较低的参考模型的指导下，DeconIEP学习一个实例自适应的扰动生成器，引导被评估模型远离记忆驱动的捷径路径。在多个开源权重LLM和基准上的大量实证结果表明，DeconIEP实现了强大的去污染效果，同时仅造成最小的良性效用下降。

---

### 24 Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection

**link**: https://arxiv.org/pdf/2601.19375.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 尽管在对齐方面取得了显著进展，但大型语言模型（LLMs）仍然容易受到引发有害行为的对抗性攻击。激活引导技术提供了一种有前景的推理时干预方法，但现有方法存在关键局限性：激活添加需要仔细的系数调整，并且对特定层的范数变化敏感；而方向消融仅提供二元控制。最近的角度引导工作通过在二维子空间中旋转引入连续控制，但其实际实现违反了范数保持，导致分布偏移和生成崩溃，尤其是在7B参数以下的模型中。本文提出选择性引导（Selective Steering），通过两项关键创新解决这些限制：（1）数学上严格的范数保持旋转公式，维持激活分布的完整性；（2）判别性层选择，仅在特征表示表现出相反符号类对齐的层应用引导。在九个模型上的实验表明，选择性引导比现有方法的攻击成功率高5.5倍，同时保持零困惑度违规和标准基准上约100%的能力保留。

---

### 25 KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing Automated Fact-checking

**link**: https://arxiv.org/pdf/2601.19447.pdf
**date**: 2026-01-28
**keywords**: cs.CL
**abs**: 声明验证是自动事实核查系统的核心组件，旨在通过对照可靠证据源（如文档或知识库）评估陈述的真实性。本文提出KG-CRAFT方法，该方法通过利用大型语言模型（LLMs）并结合基于知识图谱的对比问题来改进自动声明验证。KG-CRAFT首先从声明和相关报告构建知识图谱，然后基于知识图谱结构制定上下文相关的对比问题。这些问题引导基于证据的报告的提炼，这些报告被综合成简洁摘要，供LLMs用于真实性评估。在两个真实世界数据集（LIAR-RAW和RAWFC）上的广泛评估表明，该方法实现了新的最先进预测性能。综合分析详细验证了基于知识图谱的对比推理方法在提高LLMs事实核查能力方面的有效性。

---

### 26 LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment

**link**: https://arxiv.org/pdf/2601.19487.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 安全对齐的大型语言模型（LLMs）存在两种失败模式：越狱（回答有害输入）和过度拒绝（拒绝良性查询）。现有向量引导方法调整答案向量的 magnitude，这造成了一个根本权衡——减少越狱会增加过度拒绝，反之亦然。我们确定根本原因：LLMs将回答决策（答案向量va）和输入安全性判断（良性向量vb）编码为近乎正交的方向，将它们视为独立过程。我们提出LLM-VA，通过闭式权重更新将va与vb对齐，使模型的回答意愿因果依赖于其安全性评估——无需微调或架构更改。我们的方法使用SVM识别每层的向量，选择安全相关层，并通过最小范数权重修改迭代对齐向量。在12个LLMs上的实验表明，LLM-VA比最佳基线的F1高11.45%，同时保留95.92%的效用，并自动适应每个模型的安全偏差，无需手动调整。

---

### 27 Scale-Consistent State-Space Dynamics via Fractal of Stationary Transformations

**link**: https://arxiv.org/pdf/2601.19551.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 最近的深度学习模型越来越依赖深度，但对中间表示的有效性缺乏结构保证，使得早停和自适应计算变得不适定。我们通过为状态空间模型在迭代细化过程中的尺度一致潜动态制定结构要求来解决此限制，并推导出分形平稳变换（FROST），通过分形归纳偏置强制自相似表示流形。在这种几何结构下，中间状态对应于共享表示的不同分辨率，我们提供几何分析，确立跨迭代的收缩和稳定收敛。由于这种尺度一致的结构，停止自然允许基于内在特征质量而非外在目标的基于排序的公式。在ImageNet-100上的对照实验实证验证了预测的尺度一致行为，表明自适应效率源于对齐的潜几何结构。

---

### 28 A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy

**link**: https://arxiv.org/pdf/2601.18939.pdf
**date**: 2026-01-28
**keywords**: cs.LG, latent space
**abs**: 大型语言模型（LLMs）的行为对齐通常通过广泛的微调实现，但这可能导致分布偏移和低可解释性等不良副作用。本文提出一种靶向对齐方法，仅识别和更新对特定行为最负责的神经元，从而实现使用更少数据的微调。通过稀疏自编码器（SAEs）和线性探针，作者隔离了预测目标行为的3% MLP神经元，将其解码到残差空间，并利用梯度掩蔽仅微调这些神经元。在减少奉承行为任务中，该方法使用Gemma-2-2B和9B模型在四个基准测试（Syco-Bench、NLP、POLI、PHIL）上达到或超越最先进性能。结果表明，稀疏的神经元级更新提供了可扩展且精确的全模型微调替代方案，即使在数据有限时也有效。

---

### 29 Save the Good Prefix: Precise Error Penalization via Process-Supervised RL to Enhance LLM Reasoning

**link**: https://arxiv.org/pdf/2601.18984.pdf
**date**: 2026-01-28
**keywords**: cs.LG, latent reasoning
**abs**: 强化学习（RL）已成为提升大型语言模型（LLMs）推理能力的强大框架。然而，现有RL方法多依赖稀疏结果奖励，无法对部分成功解决方案中的正确中间步骤进行信用分配。过程奖励模型（PRMs）提供细粒度步骤级监督，但其分数常存在噪声且难以评估。为此，本文提出可验证前缀策略优化（VPPO），仅利用PRMs在RL过程中定位首个错误。对于错误轨迹，VPPO基于首个错误将其分为已验证正确前缀和错误后缀，奖励前者并仅对错误后的部分施加靶向惩罚。该设计产生稳定且可解释的学习信号，改善信用分配。在多个推理基准上，VPPO在Pass@1和Pass@K指标上持续优于稀疏奖励RL和先前PRM引导基线。

---

### 30 The Geometric Mechanics of Contrastive Representation Learning: Alignment Potentials, Entropic Dispersion, and Cross-Modal Divergence

**link**: https://arxiv.org/pdf/2601.19597.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 虽然InfoNCE推动了现代对比学习，但除了典型的对齐-均匀性分解外，其几何机制仍未被充分描述。本文提出了一个测度理论框架，将学习建模为固定嵌入流形上表示测度的演化。通过在大批量极限下建立值和梯度一致性，将随机目标与显式确定性能量景观联系起来，揭示了单峰和多峰机制之间的基本几何分岔。在单峰设置中，内在景观是严格凸的，具有唯一的吉布斯平衡；在这里，熵仅作为打破平局的因素，阐明“均匀性”是对齐盆地内的约束扩展。相比之下，对称多峰目标包含一个持续的负对称散度项，即使在核锐化后仍然存在。研究表明，该项诱导障碍驱动的协同适应，将群体级模态差距作为结构几何必要性而非初始化伪影强制执行。结果将分析视角从逐点判别转向群体几何，为诊断和控制分布错位提供了原则性基础。

---

### 31 Native LLM and MLLM Inference at Scale on Apple Silicon

**link**: https://arxiv.org/pdf/2601.19139.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: Apple Silicon在机器学习开发中的应用日益广泛，这催生了对利用其独特统一内存架构的高效推理解决方案的需求。然而，现有工具要么缺乏原生优化（如PyTorch MPS），要么仅专注于文本模型。

---

### 32 Learning Ordered Representations in Latent Space for Intrinsic Dimension Estimation via Principal Component Autoencoder

**link**: https://arxiv.org/pdf/2601.19179.pdf
**date**: 2026-01-28
**keywords**: cs.LG
**abs**: 自编码器长期以来被视为主成分分析（PCA）的非线性扩展。先前的研究表明，线性自编码器（LAEs）通过引入非均匀ℓ2正则化或调整损失函数，可以恢复PCA中有序、轴对齐的主成分。然而，在非线性设置中，这些方法不足以独立于非线性映射捕获剩余方差。在这项工作中，我们提出了一种新颖的自编码器框架，该框架将非均匀方差正则化与等距约束相结合。这种设计作为PCA的自然推广，使模型能够保留有序表示和方差保留等关键优势，同时对非线性降维任务仍然有效。

---

### 33 DREAMSTATE: Diffusing States and Parameters for Recurrent Large Language Models

**link**: https://arxiv.org/pdf/2601.19221.pdf
**date**: 2026-01-28
**keywords**: latent space
**abs**: 现代循环神经网络（如RWKV）凭借强大的短程建模能力和高效的固定大小状态成为其相较于标准Transformer的核心优势。然而，关于其内部状态作为可编辑知识表示的研究严重不足。为此，本文首先通过提出DREAMSTATE框架探索RWKV状态的表示特性。该框架利用条件扩散Transformer（DiT）直接建模状态的概率流形，实现状态的生成与编辑。通过t-SNE可视化和受控生成实验验证了这种表示的结构性。在成功揭示并建模状态的表示潜力后，进一步提出一种新颖的混合架构，结合RNN的局部优势与全局上下文适应性。该架构包含一个并行DiT，用于处理变长全局上下文以动态生成和调整核心循环模块的WKV参数，将固定的循环机制转变为上下文感知的动态函数。实验表明，该混合模型可通过多目标损失稳定训练，验证了其设计可行性。本文不仅为RNN状态表示开辟了新的研究方向，也为未来模型设计提供了具体的架构参考。

---

### 34 Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering

**link**: https://arxiv.org/pdf/2601.19847.pdf
**date**: 2026-01-28
**keywords**: cs.CL
**abs**: 尽管近年来大型语言模型（LLMs）具备强大的推理能力，但在具有挑战性的任务上实现可靠性能通常需要后训练或计算成本高昂的采样策略，限制了其实用效率。本研究首先发现，LLMs中的一小部分神经元与推理正确性表现出强烈的预测相关性。基于这一观察，我们提出了AdaRAS（自适应推理激活引导），这是一种轻量级测试时框架，通过选择性干预神经元激活来提高推理可靠性。AdaRAS通过极性感知均值差异准则识别推理关键神经元（RCNs），并在推理过程中自适应引导其激活，以增强不正确的推理轨迹，同时避免对已正确案例的性能下降。在10个数学和编码基准测试上的实验表明了一致的改进，包括在AIME-24和AIME-25上超过13%的增益。此外，AdaRAS在不同数据集上表现出强大的可迁移性，并能扩展到更强的模型，在不增加额外训练或采样成本的情况下优于后训练方法。
### 1 GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting

**link**: https://arxiv.org/pdf/2601.05353.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 本文提出GlyRAG框架，通过LLM生成临床摘要并嵌入语言模型，将文本嵌入与血糖生理信号表示融合。该框架在学习到的嵌入空间（潜在空间）中检索相似历史病例，利用交叉注意力整合案例类比进行血糖预测，无需额外传感器即可提升长 horizon 预测准确性。  

---

### 2 The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection

**link**: https://arxiv.org/pdf/2601.05371.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 本文提出基于核流形的贝叶斯优化框架，通过MDS嵌入将离散核库映射到连续欧几里得流形（潜在空间），实现高斯过程模型选择。该方法利用核间距离几何特性高效探索核空间，在合成数据和真实场景中均优于LLM引导搜索等基线方法。  

---

### 3 Prediction of Fault Slip Tendency in CO${_2}$ Storage using Data-space Inversion

**link**: https://arxiv.org/pdf/2601.05431.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 本文采用VAE-based DSI框架预测CO2存储断层滑动趋势，通过VAE将压力、应变等物理场参数化到潜在空间，结合监测数据实现后验预测。该方法准确重建应力场并降低地质力学参数不确定性，为地下工程风险评估提供潜在空间建模方案。  

---

### 4 DeMa: Dual-Path Delay-Aware Mamba for Efficient Multivariate Time Series Analysis

**link**: https://arxiv.org/pdf/2601.05527.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 准确高效的多元时间序列（MTS）分析对智能应用至关重要。本文提出DeMa双路径延迟感知Mamba框架，保留线性复杂度的同时提升MTS适用性。创新点包括分解MTS为序列内时间动态与序列间交互，设计时间路径（Mamba-SSD模块）捕捉单序列长程动态，以及变量路径（Mamba-DALA模块）整合延迟感知线性注意力建模跨变量依赖。实验表明，DeMa在长短期预测等五项任务上实现最先进性能且计算效率显著。  

---

### 5 Machine learning assisted state prediction of misspecified linear dynamical system via modal reduction

**link**: https://arxiv.org/pdf/2601.05297.pdf  
**date**: 2026-01-12  
**keywords**: stat.ML  
**abs**: 准确预测结构动力学对于在整个运行生命周期中保持数字孪生保真度至关重要。本文介绍一个用于高维有限元基结构动力系统中模型形式误差估计和校正的综合框架。高斯过程潜在力模型在降阶模态域中对差异进行非参数表示，允许对未建模动力学进行灵活的数据驱动表征。线性贝叶斯滤波方法联合估计系统状态和差异，纳入认知和随机不确定性。在五个模型形式误差场景中验证，证明该方法显著降低预测误差。  

---

### 6 A Bayesian Generative Modeling Approach for Arbitrary Conditional Inference

**link**: https://arxiv.org/pdf/2601.05355.pdf  
**date**: 2026-01-12  
**keywords**: stat.ML  
**abs**: 现代数据分析需要灵活的条件推断P(X_B | X_A)，其中(X_A, X_B)是观测变量X的任意划分。本文提出贝叶斯生成建模方法，通过迭代贝叶斯更新算法学习X的生成模型，无需重新训练即可获得任意条件分布。经验上，该方法实现优异预测性能和校准良好的预测区间，为随机迭代算法提供收敛性、统计一致性和条件风险界理论保证。  

---

### 7 Variational Autoencoders for P-wave Detection on Strong Motion Earthquake Spectrograms

**link**: https://arxiv.org/pdf/2601.05759.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 准确的P波检测对地震预警至关重要，但强震记录由于高噪声水平、标记数据有限和复杂波形特征带来挑战。本研究将P波检测重构为自监督异常检测任务，评估架构变化如何调节重建保真度与异常区分能力之间的权衡。通过对492种变分自编码器配置的全面网格搜索，研究表明注意力机制优先考虑全局上下文而非局部细节，实现最高检测性能（AUC达0.875），证明其对即时地震预警应用具有高度适用性。  

---

### 8 Learning Reconstructive Embeddings in Reproducing Kernel Hilbert Spaces via the Representer Theorem

**link**: https://arxiv.org/pdf/2601.05811.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 受对揭示高维数据潜在结构的表示学习方法日益增长的兴趣推动，本研究提出在再生核希尔伯特空间内基于重建的流形学习新算法。通过优化表示定理的向量形式，将每个观测样本在RKHS中重建为其他样本的线性组合。可分离的算子值核将该公式扩展到向量值数据，随后的核对齐任务将数据投影到低维潜在空间，该空间的格拉姆矩阵旨在匹配高维重建核。在模拟和真实数据集上的实验提供该方法有效性的经验证据。  

---

### 9 PiXTime: A Model for Federated Time Series Forecasting with Heterogeneous Data Structures Across Nodes

**link**: https://arxiv.org/pdf/2601.05613.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 时间序列在节点间高度有价值且很少可共享，使得联邦学习成为利用分布式时序数据的有前景范式。本文提出PiXTime，一种专为联邦学习设计的新型时间序列预测模型，能够跨具有多粒度和异构变量集的节点进行有效预测。PiXTime采用个性化补丁嵌入将节点特定粒度的时间序列映射为统一维度的令牌序列，并使用全局VE表对齐节点间的变量类别语义。实验表明，PiXTime在联邦设置中实现了最先进的性能。  

---

### 10 Transformer Is Inherently a Causal Learner

**link**: https://arxiv.org/pdf/2601.05647.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 本文发现，以自回归方式训练的Transformer自然地在其学习的表示中编码时间延迟的因果结构。在预测多元时间序列中的未来值时，Transformer输出相对于过去输入的梯度敏感性直接恢复了潜在的因果图。该方法在非线性动力学、长期依赖和非平稳系统等挑战性情况下，大大超越最先进的发现算法性能，表现出因果准确性随数据量和异质性提高的扩展潜力。  

---

### 11 Do Sparse Autoencoders Identify Reasoning Features in Language Models?

**link**: https://arxiv.org/pdf/2601.05679.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 我们研究稀疏自编码器是否能识别大型语言模型中的真正推理特征。通过面向证伪的框架，结合因果令牌注入实验和LLM引导的证伪，测试特征激活是否反映推理过程或表面语言相关性。在20种配置中，发现识别的推理特征对令牌级干预高度敏感，LLM引导的证伪一致产生激活特征的非推理输入和不激活特征的推理输入。结果表明，通过对比方法识别的SAE特征主要捕获推理的语言相关性，而非底层推理计算本身。  

---

### 12 IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck

**link**: https://arxiv.org/pdf/2601.05870.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 近年来，在具有可验证奖励的强化学习用于大型语言模型推理方面的进展受到探索崩溃的阻碍。本文提出通过迭代信息瓶颈进行潜在策略优化，将探索从令牌分布的统计扰动转向推理轨迹的拓扑分支。在高熵状态触发潜在分支以多样化推理路径，并将信息瓶颈原理同时用作轨迹过滤器和自奖励机制。在四个数学推理基准上的实证结果表明，IIB-LPO实现了最先进的性能，在准确率上超过先前方法高达5.3%。  

---

### 13 Visualising Information Flow in Word Embeddings with Diffusion Tensor Imaging

**link**: https://arxiv.org/pdf/2601.05713.pdf  
**date**: 2026-01-12  
**keywords**: cs.CL  
**abs**: 理解大型语言模型如何表示自然语言是自然语言处理研究的核心挑战。本文提出通过将扩散张量成像应用于词嵌入来分析和可视化自然语言表达式中信息流的新工具。研究发现，DTI揭示了词嵌入之间的信息流，跟踪LLM各层内的信息流可以比较不同的模型结构，并发现修剪LLM未充分利用层的机会。此外，该模型揭示了在代词解析和隐喻检测等任务中信息流的差异。  

---

### 14 CHDP: Cooperative Hybrid Diffusion Policies for Reinforcement Learning in Parameterized Action Space

**link**: https://arxiv.org/pdf/2601.05675.pdf  
**date**: 2026-01-12  
**keywords**: cs.AI  
**abs**: 混合动作空间在机器人控制和游戏AI等领域十分普遍，但高效建模和优化混合离散-连续动作空间仍是一项基本挑战。本文提出合作混合扩散策略框架，将混合动作空间问题视为一个完全合作博弈，采用两个合作智能体分别利用离散和连续扩散策略。连续策略以离散动作的表示为条件，显式建模它们之间的依赖关系。在具有挑战性的混合动作基准测试中，CHDP在成功率上比最先进的方法高出19.3%。  

---

### 15 Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute

**link**: https://arxiv.org/pdf/2512.11847.pdf  
**date**: 2026-01-12  
**keywords**: cs.LG  
**abs**: 微型递归模型被提出作为大型语言模型的参数高效替代方案，用于解决ARC风格的任务。本文对ARC-AGI-1上的模型检查点进行实证分析，发现测试时的数据增强和多数投票集成对性能提升显著，模型严重依赖任务标识符，递归轨迹分析显示大部分最终准确率在首次递归步骤达成。总体而言，性能源于效率、任务特定条件与测试时计算的共同作用，而非深度内部推理。  

---

### 16 FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse

**link**: https://arxiv.org/pdf/2601.05505.pdf  
**date**: 2026-01-12  
**keywords**: cs.CL  
**abs**: 大型语言模型的无状态架构缺乏保留动态上下文的机制。本文提出FlashMem框架，通过计算复用从瞬时推理状态中提取内在记忆。利用内部表示唯一编码输入轨迹的特性，将最后隐藏状态识别为交互历史的充分统计量，使Shared-KV Consolidator能直接关注主干的冻结缓存来合成记忆。此外，无参数的认知监控器利用注意力熵自适应触发整合。实验表明，FlashMem匹配高性能基线的同时将推理延迟降低5倍。  

---

### 17 Tracing Moral Foundations in Large Language Models

**link**: https://arxiv.org/pdf/2601.05437.pdf  
**date**: 2026-01-12  
**keywords**: cs.CL  
**abs**: 本研究以道德基础理论为分析框架，探究道德基础在大型语言模型中的编码、组织和表达。采用多层次方法，包括对MFT概念表征进行分层分析，在残差流上使用稀疏自编码器识别支持道德概念的稀疏特征，并使用密集MFT向量和稀疏SAE特征进行因果引导干预。研究发现，模型以结构化、依赖层的方式表征道德基础，且与人类判断一致，表明多元道德结构可以作为一种潜在模式从语言的统计规律中自然涌现。  

---

### 18 The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning

**link**: https://arxiv.org/pdf/2601.06002.pdf  
**date**: 2026-01-12  
**keywords**: cs.CL  
**abs**: 大型语言模型通常难以通过模仿人类或非长思维链模型来学习有效的长思维链推理。本文提出有效的长思维链轨迹具有稳定的类分子结构，由深度推理、自我反思和自我探索三种相互作用类型形成。引入有效语义异构体，并表明只有促进快速熵收敛的键才能支持稳定的长思维链学习。基于此，提出Mole-Syn方法，用于指导有效长思维链结构的合成，在多个基准测试中提升性能和强化学习稳定性。  

---

### 19 MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards

**link**: https://arxiv.org/pdf/2601.05488.pdf  
**date**: 2026-01-12  
**keywords**: cs.CL  
**abs**: 在长期对话中保持一致性仍是大型语言模型的基本挑战。本文引入MemBuilder，一种强化学习框架，通过归因密集奖励训练模型协调多维度记忆构建。解决稀疏轨迹级奖励和记忆归因问题，采用合成会话级问题生成提供密集中间奖励，并引入贡献感知梯度加权调整策略更新。实验结果表明，MemBuilder使模型能够超越最先进的闭源基线，在长期对话基准测试中表现出强大的泛化能力。  

---

### 20 Distilling Feedback into Memory-as-a-Tool

**link**: https://arxiv.org/pdf/2601.05960.pdf  
**date**: 2026-01-12  
**keywords**: cs.CL  
**abs**: 我们提出了一个框架，通过基于文件的记忆系统和智能体控制的工具调用，将瞬时的批评转化为可检索的指南，从而分摊推理时的推理成本。在Rubric Feedback Bench数据集上评估，实验表明增强的大型语言模型能快速达到测试时优化管道的性能，同时大幅降低推理成本。  

---

### 21 One Script Instead of Hundreds? On Pretraining Romanized Encoder Language Models

**link**: https://arxiv.org/pdf/2601.05776.pdf  
**date**: 2026-01-12  
**keywords**: Latent Space  
**abs**: 脚本罗马化通过揭示潜在词汇重叠，已成为改善多语言模型跨语言迁移的有效策略。本文通过在六种类型学多样的高资源语言的罗马化文本和原始文本上从头预训练编码器语言模型，研究脚本罗马化对性能的影响。观察到对于拼音文字语言，性能损失可忽略不计，而对于语素音节文字语言则会出现性能下降。罗马化在可忽略的性能成本下提高了拼音文字的编码效率。  

---

### 22 iReasoner: Trajectory-Aware Intrinsic Reasoning Supervision for Self-Evolving Large Multimodal Models

**link**: https://arxiv.org/pdf/2601.05877.pdf  
**date**: 2026-01-12  
**keywords**: Latent Reasoning  
**abs**: 近期研究表明，大型多模态模型可以通过自博弈和内在反馈从未标记数据中实现自我改进。本文提出iReasoner框架，通过显式激发思维链并奖励其内部一致性来改进模型的隐式推理。在未标记图像的Proposer--Solver循环中，通过定义轨迹感知信号增强结果级内在奖励，提供无需真实标签即可区分推理路径的学习信号。在完全无监督后训练下，iReasoner在多种多模态推理基准上实现了高达+2.1分的提升。
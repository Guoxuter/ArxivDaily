### 1 Latent Dynamics Graph Convolutional Networks for model order reduction of parameterized time-dependent PDEs

**link**: https://arxiv.org/pdf/2601.11259.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文提出潜在动力学图卷积网络（LD-GCN），一种纯数据驱动、无编码器的架构，用于参数化时间依赖偏微分方程（PDEs）的模型降阶（MOR）。该方法学习外部输入和参数条件下的全局低维表示，在潜在空间中建模时间演化，并通过图神经网络解码到几何参数化域。框架通过通用逼近定理验证，并在Navier-Stokes方程等计算力学问题上测试，有效检测分岔现象，解决了现有方法忽略动力学特征或空间信息的问题。

---

### 2 Latent Space Inference via Paired Autoencoders

**link**: https://arxiv.org/pdf/2601.11397.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文提出基于成对自编码器的潜在空间推理框架，用于处理逆问题中的观测不一致性。使用两个自编码器（参数空间和观测空间）学习潜在空间映射，实现低维空间的正则化反演和优化，支持处理部分、噪声或分布外数据。框架在医学断层扫描和地球物理地震波形反演中验证，相比基线方法，在数据不一致情况下重建更准确，适用于科学工程中的逆问题。

---

### 3 Digital Metabolism: Decoupling Logic from Facts via Regenerative Unlearning -- Towards a Pure Neural Logic Core

**link**: https://arxiv.org/pdf/2601.10810.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文提出“数字代谢”假说，认为针对大型语言模型（LLMs）的参数纠缠问题（逻辑与事实耦合），需通过再生逻辑核心协议（RLCP）进行遗忘以提炼纯神经逻辑核心。RLCP通过双流训练和梯度反转使特定事实依赖线性不可解码，应用于Qwen2.5-0.5B模型后，目标事实保留率降至<7%，同时模型自发采用思维链推理。实验在GSM8K数据集上验证了逻辑与事实解耦的有效性，为模块化架构铺平道路。

---

### 4 FAConvLSTM: Factorized-Attention ConvLSTM for Efficient Feature Extraction in Multivariate Climate Data

**link**: https://arxiv.org/pdf/2601.10914.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文提出FAConvLSTM，一种因子化注意力ConvLSTM层，用于高效处理多变量气候数据中的局部动态、远程遥相关和多尺度相互作用。方法通过轻量级瓶颈和共享深度空间混合因子化门控计算，降低通道复杂度；结合多尺度扩张分支和轴向空间注意力机制捕获跨尺度物理过程。实验表明，FAConvLSTM比标准ConvLSTM产生更稳定、可解释的表示，计算开销显著降低。

---

### 5 Reasoning Distillation for Lightweight Automated Program Repair

**link**: https://arxiv.org/pdf/2601.10987.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文研究轻量级符号推理监督对紧凑型自动程序修复模型的改进，提出推理蒸馏方法：大型教师模型提供结构化推理标签，训练基于CodeT5的学生模型。在IntroClass基准上，推理监督提高了宏平均性能，尤其在低频错误类别上，且不增加模型复杂度。分析表明推理准确性与修复预测强相关，符号推理蒸馏可提升轻量级模型的可解释性和鲁棒性。

---

### 6 Spurious Rewards Paradox: Mechanistically Understanding How RLVR Activates Memorization Shortcuts in LLMs

**link**: https://arxiv.org/pdf/2601.11061.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文研究强化学习与可验证奖励（RLVR）在大型语言模型（LLMs）中的“困惑度悖论”：虚假奖励导致答案标记困惑度下降但提示连贯性降低，表明模型偏向记忆而非推理。通过路径修补和Logit Lens分析，发现“锚点-适配器”回路（中间层锚点触发记忆检索，后期层适配器转换表示）驱动此行为。实验证明，缩放特定MLP键可双向引导性能，为数据污染识别提供机制路线图。

---

### 7 Differentially Private Subspace Fine-Tuning for Large Language Models

**link**: https://arxiv.org/pdf/2601.11113.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文提出DP-SFT，一种差分隐私（DP）子空间微调方法，用于保护大型语言模型在下游任务中的敏感数据。通过两阶段过程：识别低维任务特定子空间，仅向该子空间注入DP噪声以降低扰动。实验表明，DP-SFT在严格DP约束下提高准确性和稳定性，加速收敛，优于基线方法，解决了高维噪声导致的性能下降问题。

---

### 8 Context-aware Graph Causality Inference for Few-Shot Molecular Property Prediction

**link**: https://arxiv.org/pdf/2601.11135.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文提出CaMol框架，从因果推断角度解决少样本分子性质预测问题。方法构建上下文图编码化学知识，通过可学习原子掩蔽和分布干预器分离因果子结构与混淆因素。实验显示，CaMol在少样本任务中准确率和样本效率优异，发现的因果子结构与官能团知识一致，提升了模型可解释性。

---

### 9 Assesing the Viability of Unsupervised Learning with Autoencoders for Predictive Maintenance in Helicopter Engines

**link**: https://arxiv.org/pdf/2601.11154.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文比较监督分类与自编码器（AE）无监督异常检测在直升机发动机预测维护中的应用。AE仅使用健康数据学习正常操作模型，将偏差标记为潜在故障。真实数据集评估显示，AE无需故障标签即可有效检测，特别适用于故障数据稀缺场景，凸显无监督学习在航空早期故障检测的潜力。

---

### 10 LSTM VS. Feed-Forward Autoencoders for Unsupervised Fault Detection in Hydraulic Pumps

**link**: https://arxiv.org/pdf/2601.11163.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文探索两种无监督自编码器（AE）方案用于液压泵故障检测：前馈模型分析单个传感器快照，LSTM模型捕获短期时间窗口。两种网络仅用健康数据训练，在标注故障区间上评估，实现高可靠性，为液压泵故障检测提供有效无监督方案。

---

### 11 TimeMar: Multi-Scale Autoregressive Modeling for Unconditional Time Series Generation

**link**: https://arxiv.org/pdf/2601.11184.pdf  
**date**: 2026-01-19  
**keywords**: cs.LG  
**abs**: 本文提出TimeMar框架，用于无条件时间序列生成，通过结构解耦处理多尺度时序模式。方法将序列编码为多分辨率离散令牌，以粗到细方式自回归生成；双路径VQ-VAE解耦趋势和季节成分，引入基于引导的重建策略。实验表明，生成质量优于现有方法，参数减少，且在生成长序列方面出色。

---

### 12 Language of Thought Shapes Output Diversity in Large Language Models

**link**: https://arxiv.org/pdf/2601.11227.pdf  
**date**: 2026-01-19  
**keywords**: cs.CL  
**abs**: 本文揭示思维语言（LoT）作为大型语言模型输出多样性的结构性来源。研究表明，不同LoT占据思维空间不同区域；将英语LoT切换为非英语语言能提高输出多样性，且与英语距离越远的语言增益越大。多语言聚合样本带来额外改进，语言异质性扩大多样性上限。这些发现可转化为多元对齐场景的实际效益，覆盖更广文化知识和价值取向。

---

### 13 Finding the Translation Switch: Discovering and Exploiting the Task-Initiation Features in LLMs

**link**: https://arxiv.org/pdf/2601.11019.pdf  
**date**: 2026-01-19  
**keywords**: cs.CL  
**abs**: 本文揭示大型语言模型内在翻译机制，通过稀疏自编码器识别少量翻译启动特征。因果干预表明，放大这些特征引导正确翻译，消融导致幻觉。基于此，提出数据选择策略优先训练机制困难样本（无法激活翻译特征的样本），提高数据效率并抑制幻觉。机制可迁移到同系列更大模型。

---

### 14 Spectral Characterization and Mitigation of Sequential Knowledge Editing Collapse

**link**: https://arxiv.org/pdf/2601.11042.pdf  
**date**: 2026-01-19  
**keywords**: cs.CL  
**abs**: 本文对大型语言模型顺序知识编辑进行谱分析，发现预训练权重主导奇异方向对扰动敏感，重复编辑导致破坏。提出REVIVE框架，通过显式保留主导奇异子空间稳定编辑：参数更新表示为原始权重谱基，过滤干扰组件。实验在长序列编辑中（如20,000次）提高编辑效果，保留通用能力。

---

### 15 Split-and-Conquer: Distributed Factor Modeling for High-Dimensional Matrix-Variate Time Series

**link**: https://arxiv.org/pdf/2601.11091.pdf  
**date**: 2026-01-19  
**keywords**: stat.ML  
**abs**: 本文提出分布式框架处理高维矩阵变量时间序列降维，通过因子模型将数据按列或行划分到节点服务器。每个节点通过二维张量PCA估计加载矩阵，中央服务器聚合后全局估计。框架保留矩阵结构，提高计算效率和信息利用率，支持行和列聚类及非平稳序列。仿真和实际数据验证计算效率和预测性能。

---

### 16 EncodeRec: An Embedding Backbone for Recommendation Systems

**link**: https://arxiv.org/pdf/2601.10837.pdf  
**date**: 2026-01-19  
**keywords**: cs.CL  
**abs**: 本文提出EncodeRec方法，将文本表示与推荐目标对齐，直接从项目描述学习紧凑嵌入。训练时冻结语言模型参数，保持计算高效和语义保真度。实验在核心推荐基准上，EncodeRec作为序列推荐骨干和语义ID标记化均优于基于PLM和嵌入的基线，强调嵌入适应对弥合语言模型与推荐系统差距的关键作用。

---

### 17 Neural Induction of Finite-State Transducers

**link**: https://arxiv.org/pdf/2601.10918.pdf  
**date**: 2026-01-19  
**keywords**: cs.CL  
**abs**: 本文提出自动构建无权重有限状态转换器（FSTs）的新方法，通过循环神经网络隐藏状态几何结构指导。在形态变化、字形到音素预测和历史归一化数据集上评估，构建的FSTs准确率高且稳健，测试集准确率比经典算法高出87%，为字符串重写任务提供高效模型。

---

### 18 Explore with Long-term Memory: A Benchmark and Multimodal LLM-based Reinforcement Learning Framework for Embodied Exploration

**link**: https://arxiv.org/pdf/2601.10744.pdf  
**date**: 2026-01-19  
**keywords**: cs.AI  
**abs**: 本文提出长期记忆具身探索（LMEE）框架，统一智能体的探索认知与决策行为以促进终身学习。方法利用长期情景记忆优化决策，解决现有任务忽视探索和记忆利用的问题，为具身智能体在通用环境中持续运行提供基础。
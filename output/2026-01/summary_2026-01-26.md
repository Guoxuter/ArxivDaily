### 1 Towards Latent Diffusion Suitable For Text

**link**: https://arxiv.org/pdf/2601.16220.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 语言扩散模型旨在提高自回归大型语言模型（LLMs）的采样速度和连贯性。本文介绍了用于语言生成的神经流扩散模型（Neural Flow Diffusion Models），它是NFDM的扩展，能够将连续扩散模型直接应用于离散状态空间。NFDM从数据中学习多元前向过程，确保前向过程和生成轨迹适合语言建模。该模型显著缩小了与相同规模自回归模型的似然差距，同时实现了与先前潜在扩散模型相当的样本质量。

---

### 2 Efficient Gaussian process learning via subspace projections

**link**: https://arxiv.org/pdf/2601.16332.pdf  
**date**: 2026-01-26  
**keywords**: cs.LG  
**abs**: 我们提出了一种新的高斯过程训练目标，该目标使用数据的低维线性投影构建，称为“投影似然”（PL）。我们提供了与PL相关的信息损失的闭式表达式，并通过经验表明，使用单位球面上的随机投影可以减少这种损失。我们证明，在不同的优化器、核函数和中等大小的数据集上，PL在准确性和计算效率方面优于精确的GP训练和稀疏GP的变分自由能方法。

---

### 3 Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces

**link**: https://arxiv.org/pdf/2601.16907.pdf  
**date**: 2026-01-26  
**keywords**: cs.LG  
**abs**: 虽然预训练嵌入空间中的原始余弦相似度与人类判断表现出强排序相关性，但各向异性导致绝对值的系统性校准误差：无论实际语义相关性如何，分数都集中在狭窄的高相似度区间，限制了其作为定量指标的可解释性。先前的工作通过修改嵌入空间（白化、对比微调）来解决此问题，但此类转换会改变几何结构并需要重新计算所有嵌入。

---

### 4 Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning

**link**: https://arxiv.org/pdf/2601.16491.pdf  
**date**: 2026-01-26  
**keywords**: cs.LG  
**abs**: 由分类特征组成的数据集在大数据分析任务中非常常见。由于分类特征通常具有有限数量的定性可能值，在分类数据的隐式离散距离空间中，嵌套粒度聚类效应普遍存在。即数据对象经常在空间或子空间中重叠形成小型紧密聚类，而相似的小型聚类又常形成更大的聚类。然而，由于分类数据值的定性性质，其距离空间无法像欧氏距离那样明确定义，这给分类数据的聚类分析带来了巨大挑战。有鉴于此，我们设计了一种多粒度竞争惩罚学习（MGCPL）算法，允许潜在聚类以不同数量的自然紧密聚类进行交互式自我调整和分阶段收敛。为了利用MGCPL，我们还提出了一种基于MGCPL编码的聚类聚合策略（CAME），该策略首先根据学习到的多粒度分布对数据对象进行编码，然后对嵌入进行最终聚类。结果表明，所提出的MGCPL引导的分类数据聚类（MCDC）方法能够自动探索多粒度聚类的嵌套分布，并且对来自不同领域的分类数据集具有高度鲁棒性。得益于其线性时间复杂度，MCDC可扩展到大规模数据集，并在预分区数据集或计算节点以促进分布式计算方面具有前景。大量带有统计证据的实验证明了其与各种真实公共数据集上的最先进方法相比的优越性。

---

### 5 Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm

**link**: https://arxiv.org/pdf/2601.16552.pdf  
**date**: 2026-01-26  
**keywords**: cs.LG  
**abs**: 非线性降维技术（尤其是UMAP）广泛用于高维数据可视化。然而，UMAP的局部欧几里得距离假设往往无法捕捉内在流形几何结构，导致拓扑撕裂和结构坍塌。我们发现UMAP对k近邻图的敏感性是主要原因。为解决此问题，我们引入Ollivier-Ricci曲率作为几何先验，加强几何瓶颈处的边并减少冗余连接。由于曲率估计对噪声敏感，我们还结合使用Jaccard相似度的拓扑先验以确保邻域一致性。由此产生的JORC-UMAP方法能更好地区分真实流形结构与虚假连接。在合成和真实世界数据集上的实验表明，JORC-UMAP在减少撕裂和坍塌方面比标准UMAP及其他降维方法更有效（通过SVM准确率和三元组保留分数衡量），同时保持计算效率。这项工作为UMAP提供了几何感知的增强，以实现更忠实的数据可视化。

---

### 6 Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting

**link**: https://arxiv.org/pdf/2601.16632.pdf  
**date**: 2026-01-26  
**keywords**: cs.LG  
**abs**: 深度学习推动了时间序列预测的显著进展。尽管主流方法通过修改架构或引入新的增强策略来提高预测性能，但它们往往无法动态解耦和利用时间序列中固有的复杂、交织的时间模式，从而导致学习到静态、平均的表示，缺乏上下文感知能力。为解决此问题，我们提出双原型自适应解耦框架（DPAD），这是一种模型无关的辅助方法，使预测模型具备模式解耦和上下文感知适应能力。具体而言，我们构建了动态双原型库（DDP），包括一个具有强时间先验的通用模式库（用于捕捉主要趋势或季节性模式）和一个动态记忆关键但罕见事件的罕见模式库，然后提出双路径上下文感知路由（DPC）机制，通过从DDP中选择性检索特定上下文的模式表示来增强输出。此外，我们引入解耦引导损失（DGLoss），以确保每个原型库专注于其指定角色，同时保持全面覆盖。综合实验表明，DPAD在各种真实世界基准数据集上持续提高了最先进模型的预测性能和可靠性。

---

### 7 Generating Literature-Driven Scientific Theories at Scale

**link**: https://arxiv.org/pdf/2601.16282.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 当代自动化科学发现主要关注生成科学实验的智能体，而执行理论构建等更高层次科学活动的系统仍未得到充分探索。本研究提出了从大型科学文献语料库中合成包含定性和定量定律的理论的问题。我们大规模研究理论生成，使用13.7k篇源论文合成2.9k个理论，考察基于文献的生成与参数化知识的生成，以及以准确性为中心与以新颖性为中心的生成目标如何改变理论属性。实验表明，与使用参数化大型语言模型记忆（可视为潜在记忆）进行生成相比，我们的文献支持方法生成的理论在匹配现有证据和预测4.6k篇后续论文的未来结果方面均显著更优。

---

### 8 Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection

**link**: https://arxiv.org/pdf/2601.16976.pdf  
**date**: 2026-01-26  
**keywords**: cs.LG  
**abs**: 入侵检测系统（IDS）是保护物联网（IoT）环境的关键组件。然而，在基于机器学习（ML）的IDS中，良性流量和攻击流量之间的严重类别不平衡往往会降低性能。尽管数据增强已被广泛探索以缓解此问题，但现有方法通常依赖于简单的过采样技术或生成模型，难以同时实现高样本保真度、多样性和计算效率。为解决这些限制，我们提出使用潜在扩散模型（LDM）进行物联网入侵检测中的攻击数据增强，并与最先进的基线进行全面比较。实验针对三种代表性的物联网攻击类型，特别是分布式拒绝服务（DDoS）、Mirai和中间人攻击，使用分布、基于依赖关系和多样性指标评估下游IDS性能和内在生成质量。结果表明，使用LDM生成的样本平衡训练数据可显著提高IDS性能，DDoS和Mirai攻击的F1分数高达0.99，并持续优于竞争方法。此外，定量和定性分析表明，LDM在生成多样化样本的同时有效保留了特征依赖关系，与直接在数据空间中运行的扩散模型相比，采样时间减少了约25%。这些发现凸显了潜在扩散作为合成物联网攻击数据生成的有效且可扩展的解决方案，显著减轻了物联网场景中基于ML的IDS中的类别不平衡影响。

---

### 9 PolyAgent: Large Language Model Agent for Polymer Design

**link**: https://arxiv.org/pdf/2601.16376.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 按需聚合物发现对从生物医学到增强材料的多个行业至关重要。聚合物实验通常具有漫长的试错过程，导致流程冗长且资源消耗大。为此，机器学习在属性预测和 latent space 搜索方面加速了科学发现。然而，实验室研究人员由于基础设施限制，无法轻易访问代码和这些模型来提取单个结构和属性。我们提出了一个集成在终端中的闭环聚合物结构-属性预测器，用于早期聚合物发现。该框架由 LLM 推理驱动，为用户提供属性预测、属性引导的聚合物结构生成以及结构修改功能。SMILES 序列由合成可及性分数和合成复杂性分数（SC 分数）引导，以确保聚合物生成尽可能接近可合成的单体级结构。该框架解决了实验室研究人员生成新型聚合物结构的挑战，从而为聚合物研究提供计算见解。

---

### 10 Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias

**link**: https://arxiv.org/pdf/2601.16934.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 为确保文档各部分在嵌入搜索过程中可被发现，本文引入排列基评估框架以量化表示偏差。研究发现，最先进的嵌入模型在处理长文档多段落时存在系统性位置和语言偏差：早期段落和高资源语言（如英语）被过度表示，而后期段落和低资源语言被边缘化。分析表明位置偏差源于池化标记嵌入中的前端注意力分布，早期标记获得更多关注。为此提出推理时注意力校准方法，将注意力更均匀分布于文档位置，提升后期段落的可发现性。

---

### 11 How Does Personalized Memory Shape LLM Behavior? Benchmarking Rational Preference Utilization in Personalized Assistants

**link**: https://arxiv.org/pdf/2601.16621.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLM）驱动的助手最近集成了记录用户偏好的记忆机制，以提供更个性化和用户对齐的响应。然而，无关的个性化记忆经常被引入上下文中，干扰LLM的意图理解。为全面研究个性化的双重影响，本文开发了RPEval基准，包括个性化意图推理数据集和多粒度评估协议。RPEval揭示了现有LLM中普遍存在的非理性个性化现象，并通过错误模式分析说明了其对用户体验的负面影响。最后，本文引入RP-Reasoner，将记忆利用视为语用推理过程，实现个性化信息的选择性整合。实验结果表明，该方法在RPEval上显著优于精心设计的基线，并解决了大规模商业个性化助手中80%的不良案例，突显了语用推理在缓解非理性个性化方面的潜力。

---

### 12 Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations

**link**: https://arxiv.org/pdf/2601.16651.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 基于梯度的大型语言模型（LLM）实例级解释方法受限于模型梯度的巨大维度。在实践中，影响估计通常限于模型参数的子集以提高计算可行性，但该子集的选择往往是临时的且缺乏系统评估。本文研究通过选择少量架构感知的模型组件子集或通过将完整梯度投影到低维空间来创建低维表示哪种方法更优。使用新基准，本文表明贪婪选择的组件子集比完整梯度或随机投影更有效地捕获检索任务所需的训练数据影响信息。进一步发现，该方法比随机投影计算效率更高，证明目标组件选择是使大型模型实例级解释更具计算可行性的实用策略。

---

### 13 EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents

**link**: https://arxiv.org/pdf/2601.16690.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 本文引入EMemBench，一个通过交互式游戏评估智能体长期记忆的程序化基准。EMemBench不使用固定问题集，而是从每个智能体自身的轨迹生成问题，涵盖文本和视觉游戏环境。每个模板从底层游戏信号计算可验证的真值，控制可回答性并平衡覆盖多种记忆技能：单跳/多跳回忆、归纳、时间、空间、逻辑和对抗性记忆。本文使用以强大语言模型/视觉语言模型为骨干的记忆智能体进行评估，并以上下文提示作为基线。在15个文本游戏和多个视觉种子上的结果显示性能远未饱和：归纳和空间推理是持续瓶颈，尤其在视觉环境中。持久记忆显著提升开放式骨干在文本游戏上的性能，但对视觉语言模型智能体的改进不一致，表明视觉接地的情景记忆仍是开放挑战。人类研究进一步证实了EMemBench的难度。

---

### 14 Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach

**link**: https://arxiv.org/pdf/2601.16724.pdf  
**date**: 2026-01-26  
**keywords**: cs.CL  
**abs**: 随着自动化作文评分（AES）系统在高风险教育环境中的应用增加，其对英语作为第二语言（ESL）学习者的评分偏差问题备受关注。本文通过ASAP 2.0和ELLIPSE数据集对微调的DeBERTa-v3模型进行偏差研究，发现高熟练度ESL作文的评分比同等人类评分质量的母语者作文低10.3%。为缓解此问题，本文提出基于匹配作文对的对比学习方法：Contrastive Learning with Matched Essay Pairs。构建了包含17,161个匹配作文对的数据集，并使用三元组边际损失微调模型以对齐ESL和母语写作的 latent 表示。该方法将高熟练度评分差距减少39.9%（降至6.2%），同时保持0.76的二次加权Kappa（QWK）。事后语言分析表明，模型成功分离句子复杂性与语法错误，避免惩罚有效的第二语言句法结构。
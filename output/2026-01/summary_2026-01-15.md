### 1 Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability

**link**: https://arxiv.org/pdf/2601.09261.pdf
**date**: 2026-01-15
**keywords**: cs.LG
**abs**: 在不可观测反馈可靠性下的学习提出了独特挑战：系统不仅需要稳定学习，还需决定是否信任经验。本文将此设置定义为不可观测可靠性下的认知可识别性（EIUR），其中每个经验具有潜在可信度，可靠与不可靠反馈可能局部难以区分，且数据由学习者自身演化的信念和行动以闭环方式生成。在EIUR中，标准鲁棒学习可能稳定收敛但形成高置信度的系统性错误信念。

---

### 2 Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay

**link**: https://arxiv.org/pdf/2601.09400.pdf
**date**: 2026-01-15
**keywords**: cs.LG
**abs**: 本文介绍了ACS2HER，这是一种将预期分类器系统（ACS2）与事后经验回放（HER）机制相结合的新方法。虽然ACS2通过潜在学习在构建认知地图方面非常有效，但其在稀疏奖励环境中的性能往往停滞不前。我们提出了一种特定的架构变体，当智能体未能达到其主要目标时触发事后学习，将访问过的状态重新标记为虚拟目标以增强学习信号。该模型在两个基准任务上进行了评估：确定性的Maze 6和随机性的FrozenLake。结果表明，与标准ACS2相比，ACS2HER显著加速了知识获取和环境掌握。然而，这种效率提升伴随着计算开销的增加和分类器数量的大幅扩展。这项工作首次分析了在学习分类器系统中结合预期机制与回顾性目标重标记的方法。

---

### 3 Deep Incomplete Multi-View Clustering via Hierarchical Imputation and Alignment

**link**: https://arxiv.org/pdf/2601.09051.pdf
**date**: 2026-01-15
**keywords**: cs.LG
**abs**: 不完全多视图聚类（IMVC）旨在从具有部分观测的多视图数据中发现共享的聚类结构。核心挑战在于准确填补缺失视图而不引入偏差，同时保持视图间的语义一致性和聚类内的紧凑性。为此，本文提出DIMVC-HIA，一种新颖的深度IMVC框架，整合了层次化填补与对齐，包含四个关键组件：（1）视图特定的自编码器用于潜在特征提取，结合视图共享的聚类预测器生成软聚类分配；（2）层次化填补模块，首先基于跨视图对比相似度估计缺失的聚类分配，然后利用视图内和聚类内统计信息重建缺失特征；（3）基于能量的语义对齐模块，通过最小化低能量聚类锚点周围的能量方差来促进聚类内紧凑性；（4）对比分配对齐模块，增强跨视图一致性并鼓励自信、分离良好的聚类预测。实验表明，该框架在不同缺失程度下均实现了优越性能。

---

### 4 Breaking the Bottlenecks: Scalable Diffusion Models for 3D Molecular Generation

**link**: https://arxiv.org/pdf/2601.08963.pdf
**date**: 2026-01-15
**keywords**: cs.LG
**abs**: 扩散模型是分子设计中强大的生成模型，能捕捉复杂结构分布并实现高保真3D分子生成。但长期受限于长采样轨迹、反向过程随机方差及去噪动力学中有限的结构感知。直接去噪扩散模型（DDDM）通过确定性去噪步骤替代随机反向MCMC更新，大幅减少推理时间，但其确定性更新的理论基础尚不明确。本文通过Huang等人2024年提出的反向过渡核（RTK）框架对DDDM进行原则性重新解释，将确定性和随机扩散统一在共享概率形式下。通过将DDDM反向过程表示为近似核算子，表明直接去噪过程隐式优化噪声与干净样本间的结构化传输映射，阐明了确定性去噪实现高效推理的原因。此重构解决了分子扩散中的多个长期瓶颈：RTK视角通过强制良好条件的反向核确保数值稳定性，消除随机方差提高样本一致性，并实现尊重SE(3)等变性的可扩展对称保持去噪器。实验表明，RTK引导的确定性去噪比随机扩散模型收敛更快、结构保真度更高，同时在GEOM-DRUGS数据集上保持化学有效性。

---

### 5 Energy-Entropy Regularization: The True Power of Minimal Looped Transformers

**link**: https://arxiv.org/pdf/2601.09588.pdf
**date**: 2026-01-15
**keywords**: cs.LG
**abs**: 近期研究表明，循环Transformer相较于标准深度架构具有更优越的推理能力。当前在基准任务上训练单头循环架构的方法常因高度非凸且不规则的损失函数曲面而失败或产生次优性能。在这种情况下，优化过程往往停滞在损失函数曲面的较差局部极小值和鞍点，阻碍模型发现全局最优点。这些单头循环Transformer模型的内部机制仍未被充分理解，从头开始训练它们仍是一项重大挑战。本文提出了一种新的训练框架，该框架利用Tsallis熵和哈密顿动力学来改变损失函数曲面的几何结构。通过将参数更新视为物理流，我们成功训练了一个模型维度为d=8的单头循环Transformer，以解决输入序列长度为1000个标记的归纳头任务。这一成功揭示了其优越推理能力背后的内部机制。

---

### 6 Directional Attractors in LLM Reasoning: How Similarity Retrieval Steers Iterative Summarization Based Reasoning

**link**: https://arxiv.org/pdf/2601.08846.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 迭代摘要推理框架（如InftyThink）通过控制上下文增长实现LLM的长程推理，但在不同任务中反复生成相似推理策略。本文引入带跨链记忆的InftyThink，通过基于嵌入的语义缓存存储先前成功的推理模式，在每个推理步骤检索语义最相似的引理，引导推理而不过度扩展上下文窗口。实验表明语义引理检索能提高结构化领域的准确性，几何分析显示缓存检索在嵌入空间中引入方向偏差，形成稳定的吸引子。研究揭示了基于相似性的记忆在LLM自改进推理中的优势与局限，涉及潜在记忆和潜在空间的应用。

---

### 7 Imagine-then-Plan: Agent Learning from Adaptive Lookahead with World Models

**link**: https://arxiv.org/pdf/2601.08955.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 世界模型在建模环境状态未来动态方面显示出潜力，使智能体无需访问真实环境即可进行推理和行动。本文提出Imagine-then-Plan（ITP）框架，通过前瞻想象实现智能体学习，其中策略模型与学习到的世界模型交互生成多步“想象轨迹”。引入自适应前瞻机制，通过权衡最终目标和任务进度调整想象 horizon。想象轨迹提供关于未来结果的丰富信号，与当前观察融合形成部分可观察和可想象的马尔可夫决策过程，指导策略学习。实验验证ITP显著优于基线，自适应前瞻增强了智能体的推理能力，涉及潜在空间和潜在推理。

---

### 8 Triples and Knowledge-Infused Embeddings for Clustering and Classification of Scientific Documents

**link**: https://arxiv.org/pdf/2601.08841.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 科学文献的数量和复杂性不断增加，需要强大的方法来组织和理解研究文档。本研究探讨结构化知识（特别是主谓宾三元组）如何增强科学论文的聚类和分类。我们提出了一个模块化流水线，结合无监督聚类和有监督分类，处理多种文档表示：原始摘要、提取的三元组以及整合两者的混合格式。使用过滤后的arXiv语料库，我们从摘要中提取关系三元组，并构建四种文本表示，使用四种最先进的 transformer 模型（MiniLM、MPNet、SciBERT 和 SPECTER）进行嵌入。我们使用 KMeans、GMM 和 HDBSCAN 评估所得嵌入的无监督聚类效果，并微调分类模型以预测 arXiv 主题。结果表明，完整的摘要文本产生最连贯的聚类，但结合三元组的混合表示始终提高分类性能，准确率高达 92.6%，宏 F1 为 0.925。我们还发现轻量级句子编码器（MiniLM、MPNet）在聚类中优于领域特定模型（SciBERT、SPECTER），而 SciBERT 在结构化输入分类中表现出色。这些发现突出了结合非结构化文本和结构化知识的互补优势，为科学文档的语义组织提供了知识注入表示的新见解。

---

### 9 Is Grokking Worthwhile? Functional Analysis and Transferability of Generalization Circuits in Transformers

**link**: https://arxiv.org/pdf/2601.09049.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 虽然大型语言模型（LLMs）在事实检索方面表现出色，但它们在组合任务中经常受到“两跳推理诅咒”的困扰。最近的研究表明，参数共享的Transformer可以通过在长时间的“grokking”阶段形成“泛化电路”来弥合这一差距。一个基本问题随之产生：在下游任务中，经过grokking的模型是否优于未经过grokking的模型？此外，等待grokking阶段所付出的大量计算成本是否值得？在这项工作中，我们进行了一项机制研究，以评估泛化电路在知识吸收和迁移中的作用。我们证明：（i）未经过grokking和经过grokking的模型为分布内组合查询建立的推理路径是相同的。这表明“泛化电路”并不代表突然获得了新的推理范式。相反，我们认为grokking是将记忆的原子事实整合到自然建立的推理路径中的过程。（ii）经过长时间训练后在未见案例上实现高精度与形成特定推理路径并不绑定；在特定数据机制下，它们可以独立发生。（iii）即使是成熟的电路在整合新知识时也表现出有限的迁移能力，这表明“经过grokking的”Transformer并未完全掌握组合逻辑。

---

### 10 SITA: Learning Speaker-Invariant and Tone-Aware Speech Representations for Low-Resource Tonal Languages

**link**: https://arxiv.org/pdf/2601.09050.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 声调低资源语言使用广泛，但现代语音技术对其服务不足。一个关键挑战是学习对性别等干扰变量具有鲁棒性的表示，同时对不同词汇意义保持声调感知。为解决这一问题，我们提出SITA，这是一种轻量级适应方法，用于增强预训练wav2vec风格编码器的说话人不变性和声调感知能力。SITA采用分阶段多目标训练：（i）跨性别对比目标鼓励说话人之间的词汇一致性，而声调排斥损失通过明确分离同词不同调的实现来防止声调坍缩；（ii）基于辅助连接主义时间分类（CTC）的ASR目标与蒸馏一起稳定识别相关结构。我们主要在苗族语（一种高度声调且严重资源不足的语言，现成的多语言编码器无法有效表示其声调）上进行评估。在一个精心构建的苗族语单词语料库上，SITA提高了跨性别词汇检索准确性，同时保持了相对于经过ASR适应的XLS-R教师模型的可用ASR准确性。当将相同方法迁移到普通话时，我们进一步观察到类似的增益，表明SITA是一种通用的插件式方法，用于将多语言语音编码器适应于声调语言。

---

### 11 TaxoBell: Gaussian Box Embeddings for Self-Supervised Taxonomy Expansion

**link**: https://arxiv.org/pdf/2601.09633.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 分类法是跨领域结构化知识表示的核心，但手动扩展耗时且无法跟上新概念的出现。现有方法依赖基于点的向量嵌入，难以建模分类法中基本的不对称“is-a”关系。盒嵌入通过包含和不相交关系提供了有前景的替代方案，但存在梯度不稳定、缺乏语义不确定性概念以及多义性表示能力有限等问题。本文提出TaxoBell，一种高斯盒嵌入框架，将盒几何与多元高斯分布相互转换，其中均值编码语义位置，协方差编码不确定性。基于能量的优化实现了稳定的优化、模糊概念的鲁棒建模和可解释的层次推理。在五个基准数据集上的实验表明，TaxoBell显著优于八个最先进的分类法扩展基线，MRR提升19%，Recall@k提升约25%。

---

### 12 Where Knowledge Collides: A Mechanistic Study of Intra-Memory Knowledge Conflict in Language Models

**link**: https://arxiv.org/pdf/2601.09445.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 在语言模型（LMs）中，内存内知识冲突主要源于同一事件的不一致信息被编码到模型的参数化知识中。尽管先前的研究主要关注通过微调或知识编辑等方法解决模型内部知识与外部资源之间的冲突，但对于预训练期间在模型内部表示中产生的冲突的定位问题仍未被探索。本文设计了一个基于机制可解释性方法的框架，以识别预训练数据中的冲突知识在LMs中的编码位置和方式。研究结果进一步证明，语言模型的特定内部组件负责编码预训练中的冲突知识，并且展示了如何利用机制可解释性方法在推理时对冲突知识进行因果干预和控制。

---

### 13 The AI Hippocampus: How Far are We From Human Memory?

**link**: https://arxiv.org/pdf/2601.09113.pdf
**date**: 2026-01-15
**keywords**: cs.AI
**abs**: 本综述全面系统地综合了大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中的记忆机制，将相关文献组织为包含隐性、显性和代理记忆范式的分类体系。其中，隐性记忆指预训练Transformer内部参数中嵌入的知识，包括模型的记忆、关联检索和上下文推理能力，近期研究已探索了解释、操纵和重新配置这种潜在记忆的方法。综述还探讨了多模态环境中记忆的整合，以及记忆容量、对齐、事实一致性和跨系统互操作性等关键挑战。

---

### 14 RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering

**link**: https://arxiv.org/pdf/2601.09269.pdf
**date**: 2026-01-15
**keywords**: cs.AI
**abs**: 针对领域特定推理中现有激活引导方法依赖静态手动干预的局限性，本文提出RISER（Router-based Intervention for Steerable Enhancement of Reasoning）框架，通过插件式干预动态引导大型语言模型的推理过程。该框架构建了可重用的推理向量库，并利用轻量级路由器根据输入动态组合这些向量，通过强化学习优化路由器以任务级奖励激活潜在认知原语。在七个基准测试中，RISER相比基础模型实现了3.4-6.5%的零样本准确率提升，同时比思维链（CoT）推理效率高2-3倍。

---

### 15 Contrastive Bi-Encoder Models for Multi-Label Skill Extraction: Enhancing ESCO Ontology Matching with BERT and Attention Mechanisms

**link**: https://arxiv.org/pdf/2601.09119.pdf
**date**: 2026-01-15
**keywords**: Latent Space
**abs**: 细粒度劳动力市场分析越来越依赖于将非结构化招聘广告映射到ESCO等标准化技能分类体系，这本质上是极端多标签分类问题，但监督解决方案受限于大规模、分类对齐标注数据的稀缺性（尤其在非英语环境中）。本文提出一种零样本技能提取框架，无需人工标注的招聘广告训练数据。该框架利用大型语言模型从ESCO定义合成训练实例，并引入基于ESCO二级类别的层次约束多技能生成以提高多标签语境下的语义连贯性。基于合成语料库，训练对比双编码器将招聘广告句子与ESCO技能描述对齐到共享嵌入空间（一种潜空间），编码器增强BERT骨干网络与BiLSTM和注意力池化以更好地建模冗长、信息密集的要求陈述。上游基于RoBERTa的二进制过滤器移除非技能句子以提高端到端精度。实验表明：（i）层次条件生成提高了流畅性和可辨别性；（ii）所得多标签模型有效迁移到真实世界中文招聘广告，实现强零样本检索性能（F1@5=0.72），优于TF-IDF和标准BERT基线。总体而言，该框架为劳动经济学和劳动力分析中的自动化技能编码提供了可扩展、数据高效的途径。

---

### 16 OrthoGeoLoRA: Geometric Parameter-Efficient Fine-Tuning for Structured Social Science Concept Retrieval on theWeb

**link**: https://arxiv.org/pdf/2601.09185.pdf
**date**: 2026-01-15
**keywords**: Latent Space
**abs**: 大型语言模型和文本编码器越来越多地为社会科学中的网络信息系统（如数字图书馆、数据目录）提供支持，但全量微调计算和能源成本高昂，对Web4Good生态系统中的小型机构和非营利组织构成障碍。参数高效微调（PEFT）（尤其是低秩适应LoRA）通过仅更新少量参数降低成本。本文表明标准LoRA更新ΔW=BA⊤存在几何缺陷：规范自由度、尺度模糊和秩崩溃倾向。提出OrthoGeoLoRA，通过将低秩因子约束为正交（Stiefel流形）来强制SVD类形式ΔW=BΣA⊤。几何重参数化实现此约束，同时与标准优化器（如Adam）和现有微调流程兼容。还提出欧洲语言社会科学叙词表（ELSST）上的层次概念检索基准。多语言句子编码器实验表明，在相同低秩预算下，OrthoGeoLoRA在排名指标上优于标准LoRA和多种PEFT变体，为资源受限环境中的基础模型适配提供了更计算和参数高效的途径，其核心是通过优化低秩因子几何结构改进潜空间对齐效果。

---

### 17 UserLM-R1: Modeling Human Reasoning in User Language Models with Multi-Reward Reinforcement Learning

**link**: https://arxiv.org/pdf/2601.09215.pdf
**date**: 2026-01-15
**keywords**: Latent Reasoning
**abs**: 用户模拟器是智能体训练后的关键交互环境，理想的用户模拟器应能跨域泛化并通过质疑或讨价还价主动参与协商。然而现有方法存在两个问题：依赖静态、上下文无关的配置文件，需为新场景大量手动重新设计，限制泛化性；忽略人类战略思维，易受智能体操纵。为解决这些问题，本文提出UserLM-R1，一种具有推理能力的新型用户语言模型。具体而言，首先构建包含静态角色和动态场景特定目标的综合用户配置文件以适应不同场景；然后提出目标驱动的决策策略，在生成响应前生成高质量推理依据（rationale），并通过监督微调与多奖励强化学习进一步优化推理过程和战略能力。大量实验结果表明，UserLM-R1优于竞争基线，尤其在更具挑战性的对抗性数据集上表现突出，其推理过程涉及模型内部的潜推理步骤。

---

### 18 Ability Transfer and Recovery via Modularized Parameters Localization

**link**: https://arxiv.org/pdf/2601.09398.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 大型语言模型可以通过持续预训练或微调来提升特定领域、语言或技能的性能，但这种特化往往会降低其他能力，并可能导致灾难性遗忘。本文通过分析密切相关模型在特定领域和语言输入下的模块激活，研究能力在LLM参数中的分布情况。跨层和模块的研究发现，与能力相关的激活高度集中在一小部分通道中（通常<5%），且这些通道具有良好的充分性和稳定性，大部分是解耦的。基于这些观察，我们提出了ACT（激活引导的通道级能力迁移）方法，通过激活差异定位与能力相关的通道，并选择性地迁移相应参数，随后进行轻量级微调以实现兼容性。在多语言数学和科学推理任务上的实验表明，ACT能够恢复遗忘的能力，同时保留已有的技能。它还可以合并多个特化模型，将多种能力集成到单个模型中，且干扰最小。我们的代码和数据将公开发布。

---

### 19 PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records

**link**: https://arxiv.org/pdf/2601.09636.pdf
**date**: 2026-01-15
**keywords**: cs.AI
**abs**: 尽管GUI代理在显式和完成指令下表现出强大的性能，但实际部署需要与用户更复杂的隐式意图对齐。在这项工作中，我们提出了面向个性化GUI代理的分层隐式意图对齐（PersonalAlign），这是一项新的代理任务，要求代理利用长期用户记录作为持久上下文，以解决模糊指令中省略的偏好，并通过用户状态预测潜在例程以提供主动协助。为促进这项研究，我们引入了AndroidIntent基准，旨在评估代理通过对长期用户记录的推理来解决模糊指令和提供主动建议的能力。我们从不同用户的2万条长期记录中注释了775个用户特定偏好和215个例程用于评估。此外，我们引入了分层意图记忆代理（HIM-Agent），它维护不断更新的个人记忆，并分层组织用户偏好和例程以实现个性化。最后，我们在AndroidIntent上评估了一系列GUI代理，包括GPT-5、Qwen3-VL和UI-TARS，结果显示HIM-Agent将执行性能和主动性能分别显著提高了15.7%和7.3%。

---

### 20 Value-Aware Numerical Representations for Transformer Language Models

**link**: https://arxiv.org/pdf/2601.09706.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 基于Transformer的语言模型在数学推理基准上通常表现出色，但在基本数值理解和算术运算方面仍然脆弱。一个核心限制是数字被作为符号标记处理，其嵌入没有显式编码数值，导致系统性错误。我们引入了一种值感知数值表示，通过专用前缀标记增强标准分词输入，该前缀标记的嵌入显式依赖于底层数值。这种机制将量级信息直接注入模型的输入空间，同时与现有分词器和解码器-only Transformer架构兼容。在算术任务上的评估表明，所提出的方法在数值格式、任务和操作数长度上均优于基线。这些结果表明，显式编码数值是提高语言模型基本数值鲁棒性的有效且高效的方法。

---

### 21 Companion Agents: A Table-Information Mining Paradigm for Text-to-SQL

**link**: https://arxiv.org/pdf/2601.08838.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 大规模Text-to-SQL基准（如BIRD）通常假设存在完整准确的数据库注释以及 readily available的外部知识，但这无法反映注释缺失、不完整或错误的常见工业场景。这种不匹配严重限制了最先进（SOTA）Text-to-SQL系统的实际适用性。为弥合这一差距，我们探索了一种以数据库为中心的方法，利用关系数据库中固有的细粒度信息来构建缺失证据，并在注释稀缺的情况下提高Text-to-SQL的准确性。我们的核心假设是，当查询需要对大量表信息进行多步推理时，现有方法往往难以可靠地识别和利用真正相关的知识。因此，我们建议在数据库端预先“缓存”与查询相关的知识，以便在推理时可以选择性地激活。基于此思想，我们引入了Companion Agents（CA），这是一种新的Text-to-SQL范式，它包含一组伴随数据库模式的代理，在查询生成前主动挖掘和整合隐藏的表间关系、值域分布、统计规律和潜在语义线索。在BIRD的完全缺失证据设置下的实验表明，CA在RSL-SQL/CHESS/DAIL-SQL上分别恢复了+4.49/+4.37/+14.13的执行准确率，在具有挑战性的子集上增益更大（+9.65/+7.58/+16.71）。这些改进源于CA在数据库端的自动挖掘和证据构建，为无需依赖人工整理证据的工业级Text-to-SQL部署提供了实用途径。

---

### 22 Recursive Knowledge Synthesis for Multi-LLM Systems: Stability Analysis and Tri-Agent Audit Framework

**link**: https://arxiv.org/pdf/2601.08839.pdf
**date**: 2026-01-15
**keywords**: cs.CL
**abs**: 本文提出了一种三代理交叉验证框架，用于分析多模型大型语言系统的稳定性和可解释性。该架构将三个异构LLM（用于语义生成、分析一致性检查和透明度审计）集成到一个递归交互循环中。这种设计引发了递归知识合成（RKS），其中中间表示通过相互约束的转换不断细化，这种转换无法简化为单模型行为。在使用公共访问LLM部署的47次对照试验中（2025年10月），我们通过四个指标评估系统稳定性：反射可靠性分数（RRS）、透明度分数（TS）、偏差检测率（DDR）和纠正成功率（CSR）。该系统实现了平均RRS=0.78±0.06，并在约68%的试验中保持TS≥0.8。约89%的试验收敛，支持透明度审计作为复合验证映射中的收缩算子这一理论预测。贡献有三：（1）用于跨异构LLM协调推理的结构化三代理框架；（2）基于不动点理论的形式化RKS模型；（3）在现实、非API公共访问条件下对模型间稳定性的实证评估。这些结果提供了初步的经验证据，表明一种安全保留、人类监督的多LLM架构可以在现实的公开部署环境中实现稳定的递归知识合成。

---

### 23 A³-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation

**link**: https://arxiv.org/pdf/2601.09274.pdf
**date**: 2026-01-15
**keywords**: cs.AI
**abs**: 科学推理不仅依赖逻辑推理，还依赖激活先验知识和经验结构。记忆可有效重用知识并增强推理的一致性和稳定性。然而现有基准主要评估最终答案或步骤连贯性，忽略了人类推理背后涉及激活锚点和吸引子并整合到多步推理中的“记忆驱动”机制。为此，本文提出A³-Bench以解决这一研究空白。

---

### 24 EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines

**link**: https://arxiv.org/pdf/2601.09465.pdf
**date**: 2026-01-15
**keywords**: cs.AI
**abs**: 基于LLM的智能体在深度研究中展现潜力，但现有方法多依赖固定工作流，难以适应开放式查询。近期研究探索通过重写代码或提示实现自我进化以提升问题解决能力，但无约束优化易导致不稳定、幻觉和指令漂移。本文提出EvoFSM框架，通过进化显式有限状态机实现可控自进化，将优化空间解耦为宏观流程与微观技能，结合自我进化记忆提炼成功轨迹作为先验知识。在多跳QA基准测试中，EvoFSM准确率达58.0%，验证了其有效性和泛化能力。
### 1 TabPFN Through The Looking Glass: An interpretability study of TabPFN and its internal representations

**link**: https://arxiv.org/pdf/2601.08181.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 表格基础模型是为多种表格数据任务设计的预训练模型，它们在不同领域表现出强大性能，但其内部表示和所学概念仍知之甚少。这种缺乏可解释性的问题使得研究这些模型如何处理和转换输入特征变得重要。本文分析了模型隐藏表示中编码的信息，并研究了这些表示在各层之间的演变。我们进行了一系列探测实验，测试早期层中是否存在线性回归系数、复杂表达式的中间值以及最终答案。这些实验使我们能够推断模型在内部执行的计算。结果表明，表格基础模型的表示中存储了有意义且结构化的信息。我们观察到与模型预测过程中涉及的中间量和最终量相对应的清晰信号。这为模型如何细化输入以及最终输出如何形成提供了见解。我们的发现有助于深入理解表格基础模型的内部机制，表明这些模型编码了具体且可解释的信息，使我们更接近使其决策过程更加透明和可信。

---

### 2 E^2-LLM: Bridging Neural Signals and Interpretable Affective Analysis

**link**: https://arxiv.org/pdf/2601.07877.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: E²-LLM（EEG到情感的大型语言模型）是首个用于从EEG进行可解释情感分析的多模态LLM框架。该模型通过可学习的投影层整合预训练的EEG编码器与基于Qwen的LLM，采用多阶段训练流程，包括情感区分预训练、跨模态对齐以及结合思维链推理的指令调优。实验表明，E²-LLM在七个情感类别的数据集上实现了优异的情感分类性能，较大的模型变体在复杂推理场景中表现出更强的可靠性和零样本泛化能力，为生理信号与LLM推理能力的结合建立了新范式。

---

### 3 Beyond the Next Port: A Multi-Task Transformer for Forecasting Future Voyage Segment Durations

**link**: https://arxiv.org/pdf/2601.08013.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 准确预测航段级航行持续时间对于提高 maritime 调度可靠性和优化长期港口运营至关重要。然而，传统的预计到达时间（ETA）模型主要针对下一个停靠港口设计，且严重依赖实时自动识别系统（AIS）数据，而这些数据对于未来航段本质上不可用。为解决此差距，本研究将未来港口 ETA 预测重新表述为航段级时间序列预测问题。研究开发了基于 transformer 的架构，整合历史航行持续时间、目的港拥堵代理指标和静态船舶描述符。该框架采用因果掩码注意力机制捕捉长期时间依赖关系，并通过多任务学习头联合预测航段航行持续时间与港口拥堵状态，利用共享的潜在信号（latent signals）减轻高度不确定性。在 2021 年全球真实数据集上的评估表明，该模型持续优于一系列竞争基线，与序列基线模型相比，平均绝对误差（MAE）相对降低 4.85%，平均绝对百分比误差（MAPE）相对降低 4.95%；与梯度提升机相比，MAE 相对降低 9.39%，MAPE 相对降低 52.97%。主要目的港的案例研究进一步证明了模型的卓越准确性。

---

### 4 Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning

**link**: https://arxiv.org/pdf/2601.07903.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 大型语言模型（LLMs）在时间序列预测（TSF）中的应用面临预训练语料与时间序列数据差异大、直接应用预测质量低以及微调计算开销大的双重挑战。为解决此问题，本文提出LVICL方法，通过向量注入的上下文学习（ICL）将示例信息注入冻结的LLM，以增强其在TSF任务上的性能，同时避免参数微调的计算开销。具体而言，利用LLM和可学习的上下文向量适配器从多个示例中自适应提取包含压缩示例相关信息的上下文向量，并在正向传播中将该向量注入LLM的每一层以提升预测性能。与传统ICL相比，向量注入式ICL不增加提示长度，且通过自适应从示例中推导上下文向量抑制了对预测有害的成分，从而提高模型性能。

---

### 5 Coupled Diffusion-Encoder Models for Reconstruction of Flow Fields

**link**: https://arxiv.org/pdf/2601.07946.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 数据驱动的流场重建通常依赖将高维状态压缩为低维潜在表示的自编码器架构。然而，变分自编码器（VAEs）等传统方法在强压缩下难以保留流体流动的高阶统计结构。本文提出DiffCoder，一种将概率扩散模型与传统卷积ResNet编码器集成并端到端训练的耦合框架。编码器将流场压缩为潜在表示，而扩散模型学习基于压缩状态的重建生成先验。该设计使DiffCoder能够恢复对于忠实表示流场统计特性至关重要的分布和频谱特性。在Kolmogorov流场数据集上的评估表明，在激进压缩下，DiffCoder显著提高频谱精度，同时更好地保留流场的潜在分布结构。

---

### 6 Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance

**link**: https://arxiv.org/pdf/2601.08379.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 预训练扩散模型已成为无条件和条件样本生成的强大生成先验，但其输出往往偏离用户特定目标数据的特征。这种不匹配在领域自适应任务中尤为突出，此类任务中仅存在少量参考示例，且重新训练扩散模型不可行。现有的推理时引导方法可以调整采样轨迹，但它们通常优化分类器似然等代理目标，而非直接与目标分布对齐。我们提出MMD引导（MMD Guidance），这是一种无需训练的机制，通过生成样本与参考数据集之间的最大均值差异（MMD）梯度来增强反向扩散过程。MMD能从有限数据中提供可靠的分布估计，在实践中表现出低方差，且可高效微分，因此特别适合引导任务。我们的框架通过乘积核自然扩展到条件生成模型中的提示感知自适应。此外，由于引导应用于潜在扩散模型（LDM）的潜在空间（latent space），因此它可以高效地应用于LDM。在合成和真实世界基准上的实验表明，MMD引导能够在保持样本保真度的同时实现分布对齐。

---

### 7 TRACE: Reconstruction-Based Anomaly Detection in Ensemble and Time-Dependent Simulations

**link**: https://arxiv.org/pdf/2601.08659.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 高维、时间依赖模拟数据中的异常检测因复杂的空间和时间动态而具有挑战性。本文研究基于重建的异常检测方法，使用卷积自编码器处理参数化卡门涡街模拟的集合数据。比较了在单个帧上运行的2D自编码器与处理短时序堆栈的3D自编码器：2D模型识别单时间步中的局部空间不规则性，而3D模型利用时空上下文检测异常运动模式并减少跨时间的冗余检测。进一步评估体积时间依赖数据发现，重建误差受质量空间分布的强烈影响，高度集中区域比分散配置产生更大误差。研究结果强调时间上下文对动态模拟中鲁棒异常检测的重要性，其核心依赖自编码器学习的潜在空间(latent space)表示实现数据重建与异常识别。

---

### 8 DiffMM: Efficient Method for Accurate Noisy and Sparse Trajectory Map Matching via One Step Diffusion

**link**: https://arxiv.org/pdf/2601.08482.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 稀疏轨迹的地图匹配是许多轨迹应用（如交通调度和交通流分析）的基础问题。现有基于隐马尔可夫模型（HMM）或编码器-解码器框架的方法在处理噪声或稀疏采样的GPS轨迹时仍面临重大挑战。为此，本文提出DiffMM，一种基于编码器-扩散的地图匹配框架，通过一步扩散过程产生有效且高效的匹配结果。首先，引入路段感知轨迹编码器，通过注意力机制将输入轨迹及其周围候选路段联合嵌入到共享潜空间。然后，提出一步扩散方法，利用轨迹和候选路段的联合嵌入作为条件上下文，通过捷径模型实现地图匹配。在大规模轨迹数据集上的广泛实验表明，该方法在准确性和效率上均优于最先进的地图匹配方法，尤其在稀疏轨迹和复杂路网拓扑情况下表现突出。

---

### 9 Temporal Fusion Nexus: A task-agnostic multi-modal embedding model for clinical narratives and irregular time series in post-kidney transplant care

**link**: https://arxiv.org/pdf/2601.08503.pdf  
**date**: 2026-01-14  
**keywords**: cs.LG  
**abs**: 本文提出Temporal Fusion Nexus（TFN），一种多模态、任务无关的嵌入模型，用于整合不规则时间序列和非结构化临床叙事。在肾移植后（KTx）护理中对TFN进行了分析，回顾性队列包含3382名患者，关注三个关键结局：移植物丢失、移植物排斥和死亡率。与肾移植后护理的最先进模型相比，TFN在移植物丢失（AUC 0.96 vs. 0.94）和移植物排斥（AUC 0.84 vs. 0.74）方面取得了更高的性能，死亡率预测的AUC为0.86。TFN优于单模态基线（比仅时间序列基线AUC提高约10%，比时间序列加静态患者数据基线提高约5%）。整合临床文本改善了所有任务的性能。解纠缠度量证实嵌入空间中存在稳健且可解释的潜因子，基于SHAP的归因分析证实其与临床推理一致。TFN有望应用于KTx以外的临床任务，特别是在存在异构数据源、不规则纵向数据和丰富叙事文档的场景中。

---

### 10 From Word Sequences to Behavioral Sequences: Adapting Modeling and Evaluation Paradigms for Longitudinal NLP

**link**: https://arxiv.org/pdf/2601.07988.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 传统NLP通常将文档视为独立无序的样本，但在纵向研究中，文档嵌套于作者并按时间排序，形成个人索引的时间有序行为序列。本文提出纵向建模与评估范式，更新NLP pipeline的四个部分：（1）对齐人员泛化（横断面）和/或时间泛化（前瞻性）的评估分割；（2）区分人际差异与人内动态的准确率指标；（3）默认纳入历史信息的序列输入；（4）支持历史数据上不同粗细潜在状态（latent state）的模型内部结构（池化摘要、显式动态或交互模型）。通过17k篇每日日记转录与238名参与者的PTSD症状严重度数据验证，传统文档级评估可能得出与生态有效建模评估截然不同甚至相反的结论，强调需从单词序列评估转向行为序列范式。

---

### 11 Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge

**link**: https://arxiv.org/pdf/2601.08808.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 大型语言模型通常使用思维链（CoT）更有效地解决复杂推理任务，但代价是冗长、低带宽的token序列。相比之下，人类通常通过维持对合理下一步的分布来进行软性推理。受此启发，本文提出了多重思维（Multiplex Thinking），这是一种随机软性推理机制，在每个思考步骤中，采样K个候选token并将其嵌入聚合为单个连续的多重token。这保留了词汇嵌入先验和标准离散生成的采样动态，同时诱导出可处理的多重展开概率分布。因此，多重轨迹可以直接通过在线策略强化学习（RL）进行优化。重要的是，多重思维具有自适应性：当模型自信时，多重token接近离散，表现得像标准CoT；当不确定时，它紧凑地表示多个合理的下一步，而不增加序列长度。在具有挑战性的数学推理基准上，多重思维在Pass@1到Pass@1024上始终优于强大的离散CoT和RL基线，同时生成更短的序列。

---

### 12 EmbeddingRWKV: State-Centric Retrieval with Reusable States

**link**: https://arxiv.org/pdf/2601.07861.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 当前的检索增强生成（RAG）系统通常采用传统的两阶段管道：用于初始检索的嵌入模型和用于优化的重排序器。然而，这种范式由于阶段之间缺乏共享信息而存在显著的低效性，导致大量冗余计算。为解决这一限制，我们提出了以状态为中心的检索（State-Centric Retrieval），这是一种统一的检索范式，利用“状态”作为连接嵌入模型和重排序器的桥梁。首先，我们通过微调基于RWKV的LLM进行状态表示学习，将其转换为EmbeddingRWKV，这是一个同时用作嵌入模型和状态骨干的统一模型，用于提取紧凑、可重用的状态。基于这些可重用状态，我们进一步设计了基于状态的重排序器，以充分利用预计算的信息。在重排序过程中，模型仅处理查询token，将推理成本与文档长度解耦，实现了5.4倍至44.8倍的加速。此外，我们观察到保留所有中间层状态是不必要的；通过均匀层选择策略，我们的模型仅使用25%的层即可保持98.62%的全模型性能。大量实验表明，以状态为中心的检索在实现高质量检索和重排序结果的同时，显著提高了整体系统效率。

---

### 13 An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing Active Network of Concepts with Energy E3

**link**: https://arxiv.org/pdf/2601.08224.pdf  
**date**: 2026-01-14  
**keywords**: cs.AI  
**abs**: 通用智能必须将经验重组为内部结构，以在有限资源下实现预测和行动。现有系统隐含预设固定基本单元（如标记、子词等），回避了表征单元如何出现和稳定的问题。本文提出SANC(E3)公理框架，其中表征单元非先验给定，而是通过有限激活容量下的竞争选择、重构和压缩形成稳定结果，受能量泛函E3最小化控制。该框架区分系统标记（如结构锚点和感官源）与共现事件中自组织出现的标记，通过五个核心公理形式化有限容量、共现关联等机制，并引入伪内存映射I/O机制，使感知、想象等认知活动在单一表征和能量过程中统一。从公理推导出的命题表明，类别形成、层次组织等认知活动可理解为E3最小化下的格式塔完成实例。

---

### 14 Silence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering

**link**: https://arxiv.org/pdf/2601.08427.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 群体相对策略优化（GRPO）虽提升大型语言模型推理性能，但依赖昂贵外部验证器或人类规则，导致计算成本高、训练延迟及稀疏奖励问题。本文提出Latent-GRPO框架，从 latent 空间几何结构导出内在奖励。实证分析发现：正确推理轨迹的终端标记表示在 latent 空间形成高类内相似性的密集簇，错误轨迹则为离群点。据此引入迭代鲁棒质心估计（IRCE）算法，通过球面投影减轻幅度波动，迭代聚合估计稳健“真实质心”以生成密集连续奖励。实验表明，该方法在保持性能的同时实现超2倍训练加速，并具有强泛化能力和稳健性。

---

### 15 Robust low-rank estimation with multiple binary responses using pairwise AUC loss

**link**: https://arxiv.org/pdf/2601.08618.pdf  
**date**: 2026-01-14  
**keywords**: stat.ML  
**abs**: 多二元响应存在于现代数据分析中，单独逻辑回归忽略共享结构，在高维和类别不平衡时效率低。低秩模型可编码任务间 latent 依赖性，但现有二元数据方法多基于似然且专注逐点分类。本文提出统一框架，通过最小化AUC替代损失针对判别能力，聚合跨响应成对AUC损失并对系数矩阵施加低秩约束以利用共享结构。开发基于截断奇异值分解的可扩展投影梯度下降算法，利用成对损失仅依赖线性预测器差异简化计算分析，建立非渐近收敛保证，在标签切换和数据污染等场景稳健，优于基于似然方法。

---

### 16 Reasoning Beyond Chain-of-Thought: A Latent Computational Mode in Large Language Models

**link**: https://arxiv.org/pdf/2601.08058.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 思维链（CoT）提示提升了大型语言模型（LLMs）的推理性能，但其工作原理以及是否是触发LLMs推理的唯一机制仍不明确。本研究通过稀疏自编码器（SAEs）直接分析和干预LLMs的内部表示，识别出一小部分与LLM推理行为有因果关联的潜在特征。在多个模型家族和推理基准测试中，研究发现引导单个推理相关的潜在特征无需显式CoT提示即可显著提高准确性。对于大型模型，潜在引导能达到与标准CoT提示相当的性能，同时产生更高效的输出。研究进一步观察到，这种面向推理的内部状态在生成早期被触发，并且可以覆盖提示级别的、阻止显式推理的指令。总体而言，结果表明LLMs中的多步推理由可被外部激活的潜在内部激活支持，而CoT提示是激活该机制的一种有效但非唯一的方式，并非其必要原因。

---

### 17 MemoBrain: Executive Memory as an Agentic Brain for Reasoning

**link**: https://arxiv.org/pdf/2601.08079.pdf  
**date**: 2026-01-14  
**keywords**: cs.AI  
**abs**: 工具增强型智能体框架中的复杂推理本质上是长时程的，这导致推理轨迹和瞬时工具产物不断累积，给大型语言模型有限的工作上下文带来压力。若没有显式的记忆机制，这种累积会破坏逻辑连续性并削弱任务对齐。这使得记忆不再仅仅是辅助效率的问题，而是在长时程上维持连贯、目标导向推理的核心组件。

---

### 18 PrivGemo: Privacy-Preserving Dual-Tower Graph Retrieval for Empowering LLM Reasoning with Memory Augmentation

**link**: https://arxiv.org/pdf/2601.08739.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 知识图谱为大型语言模型（LLM）的知识密集型问答推理提供了结构化证据，但许多实际知识图谱是私有的，将检索到的三元组或探索轨迹发送到闭源LLM API会带来泄露风险。现有隐私处理方法侧重于实体名称 masking，但存在结构泄露、远程交互不可控、多跳多实体推理脆弱及经验复用有限等问题。为此，本文提出PrivGemo，一种隐私保护的检索增强框架，用于基于知识图谱的推理，具有记忆引导的暴露控制。该框架采用双塔设计，将原始知识图谱知识保留在本地，同时支持对匿名化视图的远程推理，通过超越名称 masking 来限制语义和结构暴露。PrivGemo通过检索连接所有主题实体的匿名化长跳路径，支持多跳和多实体推理，同时在本地知识图谱上进行 grounding 和验证。分层控制器和隐私感知经验记忆进一步减少不必要的探索和远程交互。实验表明，PrivGemo在六个基准上实现了最先进的结果，优于最强基线达17.1%，并使小模型（如Qwen3-4B）达到接近GPT-4-Turbo的推理性能。

---

### 19 Inferring Latent Intentions: Attributional Natural Language Inference in LLM Agents

**link**: https://arxiv.org/pdf/2601.08742.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 归因推理（预测观察到的行为背后的潜在意图）是大型语言模型（LLM）在多智能体环境中运行的关键能力，但尚未得到充分探索。传统自然语言推理（NLI）无法捕捉复杂交互系统所需的细微意图驱动推理。为此，本文引入归因自然语言推理（Att-NLI）框架，将NLI与社会心理学原理相结合，评估智能体的溯因意图推理（生成关于潜在意图的假设）和演绎验证（得出有效逻辑结论）能力。通过文本游戏Undercover-V进行实验，比较三种不同推理能力和外部工具访问的LLM智能体：仅使用演绎推理的标准NLI智能体、采用溯因-演绎推理的Att-NLI智能体，以及使用外部定理证明器的神经符号Att-NLI智能体。实验表明，神经符号智能体的归因推理能力显著优于其他智能体，平均胜率达17.08%。研究结果强调了Att-NLI在开发复杂推理智能体中的作用，并展示了神经符号AI在构建多智能体环境中理性LLM智能体的潜力。

---

### 20 CLaS-Bench: A Cross-Lingual Alignment and Steering Benchmark

**link**: https://arxiv.org/pdf/2601.08331.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 理解和控制大型语言模型（LLMs）的行为在多语言自然语言处理中日益重要。除了提示工程或微调之外，在推理过程中操纵内部表示已成为一种更高效且可解释的模型适应目标语言的技术。然而，目前尚无专门的基准或评估协议来量化转向技术的有效性。本文介绍CLaS-Bench，一个轻量级的平行问题基准，用于评估LLMs在32种语言上的语言强制行为，支持系统评估多语言转向方法。作者评估了多种转向技术，包括残差流DiffMean干预、探针导出方向、语言特定神经元、PCA/LDA向量、稀疏自编码器和提示基线。转向性能沿语言控制和语义相关性两个轴进行衡量，并结合为单一的调和平均转向分数。研究发现，在各种语言中，简单的基于残差的DiffMean方法始终优于其他所有方法。此外，分层分析显示，语言特定结构主要出现在较后层，且转向方向基于语言家族聚类。CLaS-Bench是第一个多语言转向标准化基准，为语言表示的严谨科学分析和作为低成本适应替代方案的转向评估提供了基础。

---

### 21 Fine-Mem: Fine-Grained Feedback Alignment for Long-Horizon Memory Management

**link**: https://arxiv.org/pdf/2601.08435.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 有效的内存管理对于大型语言模型代理处理长程任务至关重要。最近的研究探索了使用强化学习开发专门的内存管理器代理。然而，现有方法依赖最终任务性能作为主要奖励，导致严重的奖励稀疏性和低效的信用分配，无法为个体内存操作提供足够指导。为此，本文提出Fine-Mem，一个用于细粒度反馈对齐的统一框架。首先，通过辅助块特定问答任务引入块级步骤奖励，提供即时的步骤级监督。其次，设计证据锚定奖励归因，基于推理中用作证据的特定内存项，将全局奖励重新分配，锚定关键内存操作的信用。这些组件共同实现稳定的策略优化，并使局部内存操作与内存的长期效用对齐。在Memalpha和MemoryAgentBench上的实验结果表明，Fine-Mem在复杂任务上比依赖统一执行范式的现有工具中心代理基线实现了更高的执行成功率和鲁棒性。

---

### 22 Surgical Refusal Ablation: Disentangling Safety from Intelligence via Concept-Guided Spectral Cleaning

**link**: https://arxiv.org/pdf/2601.08489.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 安全对齐的语言模型系统地拒绝有害请求。虽然激活转向可以调制拒绝行为，但从对比的有害和无害提示中计算的原始“拒绝向量”通常会导致附带损害和分布漂移。本文认为这种退化发生是因为原始向量是多语义的，将拒绝信号与核心能力电路和语言风格纠缠在一起。

---

### 23 Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety

**link**: https://arxiv.org/pdf/2601.08000.pdf  
**date**: 2026-01-14  
**keywords**: cs.AI  
**abs**: 确保大型语言模型（LLMs）遵守安全原则同时不拒绝良性请求仍然是一项重大挑战。尽管OpenAI引入了 deliberative alignment（DA），通过对详细的“类代码”安全规则进行推理来增强其o系列模型的安全性，但这种方法在通常缺乏高级推理能力的开源LLMs中的有效性尚未得到充分研究。本研究系统评估了明确指定广泛安全代码与通过说明性案例演示这些代码的影响。研究发现，引用明确代码对无害性的改善不一致，且会系统性降低有用性，而在案例增强的简单代码上训练则能产生更稳健和更通用的安全行为。通过使用案例增强推理而非广泛的类代码安全规则来指导LLMs，可以避免对狭隘列举规则的僵化遵守，并实现更广泛的适应性。基于这些见解，我们提出了CADA，一种基于案例增强的LLM deliberative alignment方法，该方法利用强化学习对自生成的安全推理链进行训练。CADA有效增强了无害性，提高了抵御攻击的稳健性，减少了过度拒绝，同时在各种基准测试中保持了实用性，为仅基于规则的DA提供了一种实用替代方案，以在保持有用性的同时提高安全性。

---

### 24 Embedded AI Companion System on Edge Devices

**link**: https://arxiv.org/pdf/2601.08128.pdf  
**date**: 2026-01-14  
**keywords**: cs.AI  
**abs**: 边缘设备上的计算资源限制使得开发具有令人满意用户体验的全嵌入式AI伴侣系统变得困难。现有文献中详细介绍的AI伴侣和记忆系统由于缺乏计算资源和延迟问题，无法直接用于此类环境。本文提出了一种在活动和非活动阶段之间交替的记忆范式：在用户活动阶段，系统通过对现有记忆和上下文进行轻量级检索来执行低延迟、实时对话；而在用户非活动阶段，系统则对整个对话会话进行计算密集型的记忆提取、整合和维护。这种设计在嵌入式硬件的严格约束下最小化了延迟，同时保持了长期个性化。我们还引入了一个AI伴侣基准，旨在从对话质量和记忆能力两方面全面评估AI伴侣。在实验中，我们发现我们的系统（使用非常弱的模型：量化为int4的Qwen2.5-7B-Instruct）在大多数指标上优于没有记忆的等效原始LLM，并且与具有16k上下文窗口的GPT-3.5性能相当。

---

### 25 SwiftMem: Fast Agentic Memory via Query-aware Indexing

**link**: https://arxiv.org/pdf/2601.08160.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 智能体记忆系统对于使大型语言模型（LLM）智能体能够维持长期上下文并高效检索相关信息至关重要。然而，现有记忆框架存在一个根本局限：它们会忽略查询特征而对整个存储层执行 exhaustive 检索。随着记忆增长，这种蛮力方法会造成严重的延迟瓶颈，阻碍智能体的实时交互。本文提出 SwiftMem，一种查询感知的智能体记忆系统，通过在时间和语义维度上的专门索引实现亚线性检索。我们的时间索引支持对数时间范围查询以进行时间敏感型检索，而语义 DAG-Tag 索引通过层次化标签结构将查询映射到相关主题。为解决记忆增长过程中的碎片化问题，我们引入嵌入-标签协同整合机制，基于语义簇重组存储以提高缓存局部性。在 LoCoMo 和 LongMemEval 基准测试上的实验表明，SwiftMem 相比最先进的基线实现了 47 倍的搜索加速，同时保持了具有竞争力的准确性，使记忆增强型 LLM 智能体的实际部署成为可能。

---

### 26 Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis

**link**: https://arxiv.org/pdf/2601.08196.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 将大型语言模型（LLMs）集成到自主智能体中已实现复杂的工具使用，但在高风险领域，这些系统必须严格遵守超出简单功能正确性的监管标准。然而，现有基准测试往往忽视隐式监管合规性，因此无法评估 LLMs 是否能够自主执行强制性安全约束。为填补这一空白，我们引入 LogiSafetyGen，一个将非结构化法规转换为线性时序逻辑预言机并采用逻辑引导的模糊测试来合成有效、安全关键轨迹的框架。基于此框架，我们构建了 LogiSafetyBench 基准测试，包含 240 个人工验证的任务，要求 LLMs 生成既满足功能目标又符合潜在合规规则的 Python 程序。对 13 个最先进（SOTA）LLMs 的评估表明，更大的模型尽管在功能正确性上表现更好，但往往优先考虑任务完成而非安全，从而导致不合规行为。

---

### 27 Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models

**link**: https://arxiv.org/pdf/2601.08209.pdf  
**date**: 2026-01-14  
**keywords**: cs.CL  
**abs**: 在生物医学、材料科学和金融等领域，大型语言模型（LLMs）的高风险部署需要注入私有、特定领域的知识，这些知识具有专有性、快速演化性且在公共预训练中代表性不足。然而，两种主流的私有知识注入范式各有明显缺陷：微调迭代成本高，持续更新可能导致灾难性遗忘和通用能力退化；检索增强生成（RAG）保持基础模型不变，但在专业私有语料库中由于块导致的证据碎片化、检索漂移和长上下文压力导致查询依赖的提示膨胀而显得脆弱。受多模态 LLMs 将异质模态对齐到共享语义空间的启发，我们提出生成增强生成（GAG），将私有专业知识视为额外的专家模态，并通过与冻结基础模型对齐的紧凑表示级接口注入，避免提示时的证据序列化，同时实现即插即用的专业化和可扩展的多域组合以及可靠的选择性激活。在两个私有科学问答基准（免疫学佐剂和催化材料）和混合域评估中，GAG 在两个基准上分别比强大的 RAG 基线提高了 15.34% 和 14.86% 的专家性能，同时保持了在六个开放通用基准上的性能，并实现了接近 oracle 的选择性激活以支持可扩展的多域部署。

---

### 28 YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation

**link**: https://arxiv.org/pdf/2601.08441.pdf  
**date**: 2026-01-14  
**keywords**: cs.AI  
**abs**: 通过激活干预引导大型语言模型（LLMs）已成为对齐和个性化的轻量级替代微调方法。近期双向偏好优化（BiPO）研究表明，可通过直接偏好优化（DPO）方式从偏好数据中学习密集引导向量，实现对真实性、幻觉和安全行为的控制。然而，由于神经元的多语义性，密集引导向量常纠缠多个潜在因素，在细粒度场景（如需区分中东文化中密切相关价值观和行为的文化对齐）中限制了有效性和稳定性。本文提出无参考方法Yet another Policy Optimization（YaPO），在稀疏自编码器（SAE）的潜在空间中学习稀疏引导向量。通过优化稀疏编码，YaPO产生可解耦、可解释且高效的引导方向。实证显示，与密集引导基线相比，YaPO收敛更快、性能更强且训练稳定性更好。除文化对外，YaPO还可推广到幻觉、财富追求、越狱和权力追求等一系列对齐相关行为。重要的是，YaPO保留通用知识，在MMLU上无显著性能下降。总体而言，结果表明YaPO为LLMs的高效、稳定和细粒度对齐提供通用方案，在可控性和领域适应方面有广泛应用。相关代码和数据已公开。

---

### 29 AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation

**link**: https://arxiv.org/pdf/2601.08323.pdf  
**date**: 2026-01-14  
**keywords**: cs.AI  
**abs**: 为智能体配备记忆对于解决现实世界中的长期任务至关重要。然而，大多数现有智能体记忆机制依赖于静态和手工设计的工作流程，这限制了这些记忆设计的性能和泛化能力，因此需要一个更灵活、基于学习的记忆框架。本文提出了AtomMem，将记忆管理重构为一个动态决策问题。我们将高层记忆过程解构为基本的原子CRUD（创建、读取、更新、删除）操作，将记忆工作流程转化为可学习的决策过程。通过结合监督微调与强化学习，AtomMem学习到一个自主的、与任务对齐的策略，以协调针对特定任务需求的记忆行为。在三个长上下文基准测试中的实验结果表明，经过训练的AtomMem-8B持续优于先前的静态工作流记忆方法。对训练动态的进一步分析显示，我们的基于学习的框架使智能体能够发现结构化、与任务对齐的记忆管理策略，凸显了其相对于预定义例程的关键优势。

---

### 30 Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs

**link**: https://arxiv.org/pdf/2601.08403.pdf  
**date**: 2026-01-14  
**keywords**: cs.AI  
**abs**: 大型语言模型越来越多地通过强化学习进行训练以用于个性化推荐任务，但GRPO等标准方法依赖稀疏的序列级奖励，这会产生信用分配差距，掩盖驱动成功的标记。当模型必须从没有 ground truth 标签的不明确语言中推断潜在用户意图时，这种差距尤其成问题，这是一种在预训练期间很少见到的推理模式。我们引入了Owen-Shapley策略优化（OSPO），这是一个基于标记对结果的边际贡献重新分配序列级优势的框架。与需要额外计算的基于价值模型的方法不同，OSPO通过Shapley-Owen归因采用基于势的奖励塑造来分配段级信用，同时保留最优策略，无需参数化价值模型即可直接从任务反馈中学习。通过形成语义连贯单元的联盟（描述产品属性的短语或捕捉偏好的句子），OSPO识别出驱动性能的响应部分。在Amazon ESCI和H&M Fashion数据集上的实验表明，OSPO持续优于基线，并且在测试时对训练期间未见过的分布外检索器具有显著的鲁棒性。
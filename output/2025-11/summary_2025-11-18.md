### 1 Experience-Guided Adaptation of Inference-Time Reasoning Strategies

**link**: https://arxiv.org/pdf/2511.11519.pdf  
**date**: 2025-11-18  
**keywords**: cs.AI  
**abs**: 本文提出了Experience-Guided Reasoner (EGuR)，一种能基于累积经验在推理时动态生成定制化策略的系统。该系统通过LLM-based元策略实现对所有策略组件（提示、采样参数、工具配置和控制逻辑）的自适应调整。EGuR包含两个组件：Guide根据当前问题和过去经验的结构化记忆生成多个候选策略，Consolidator整合执行反馈以改进未来策略生成。在五个具有挑战性的基准测试中，EGuR相比最强基线准确率提升高达14%，计算成本降低111倍，且随着系统积累经验，两个指标均有改善。  

---

### 2 Multi-Phase Spacecraft Trajectory Optimization via Transformer-Based Reinforcement Learning

**link**: https://arxiv.org/pdf/2511.11402.pdf  
**date**: 2025-11-18  
**keywords**: cs.LG  
**abs**: 航天器在发射、上升、级分离和轨道插入等任务阶段的自主控制需要适应动态变化的策略。现有强化学习方法通常为不同任务阶段设计单独策略，限制了适应性并增加了操作复杂性。本文提出一种基于Transformer的强化学习框架，通过单个策略架构统一多阶段轨迹优化。该框架利用Transformer固有的长时序上下文建模能力，结合Gated Transformer-XL (GTrXL)架构，使智能体能够在关键操作中维持跨秒到分钟级任务阶段的连贯记忆，无需手动设置阶段转换。通过在双积分器、范德波尔振荡器等单阶段基准测试，以及包含大气飞行、级分离和真空操作的复杂多阶段火箭上升问题上的验证，结果表明该框架不仅能匹配简单场景的解析解，还能有效学习跨动态不同区域的连贯控制策略，为减少对阶段特定控制器的依赖、实现可扩展自主任务规划奠定了基础。  

---

### 3 Cognitively-Inspired Episodic Memory Architectures for Accurate and Efficient Character AI

**link**: https://arxiv.org/pdf/2511.10652.pdf  
**date**: 2025-11-18  
**keywords**: cs.CL  
**abs**: 该研究针对角色AI对话系统中准确性与效率的权衡问题，提出了一种认知启发的情景记忆架构。该架构通过离线数据增强将传记数据转化为1774条带有情感语义元数据的第一人称记忆，并采用两阶段检索机制实现高效的提示生成（0.52秒）。实验表明，该方法在GPT-4上与传统RAG性能相当，在较小模型（如GPT-3.5、GPT-3）上显著优于传统RAG，特别适用于资源受限场景。此外，结构化记忆支持时空热图、情感轨迹分析等可视化工具，使其成为兼具对话接口和传记研究功能的多用途系统。以梵高为测试案例验证了架构的通用性，可扩展至任何具有丰富文本记录的历史人物，适用于教育、博物馆和研究等领域。  

---

### 4 Empirical Characterization of Temporal Constraint Processing in LLMs

**link**: https://arxiv.org/pdf/2511.10654.pdf  
**date**: 2025-11-18  
**keywords**: cs.CL  
**abs**: 当在需要实时决策的智能体架构中部署大型语言模型（LLMs）时，我们假设它们能可靠判断行动窗口是否开放或关闭，但这一假设未经检验。本文通过截止日期检测任务，对8个生产级模型（2.8-8B参数）的时间约束处理能力进行了实证表征，揭示了系统性部署风险：双峰性能分布（模型准确率要么95%要么50%）、极端的提示脆弱性（仅格式变化就导致30-60个百分点的波动）和系统性行动偏差（失败模型的假阳性率100%）。在此参数范围内，参数数量与能力无关——3.8B模型与7B模型相当，而其他7B模型完全失败。在200个合成示例上微调可将部分有能力的模型提高12-37个百分点。研究表明，即使进行针对性微调，时间约束满足也无法通过自然语言的下一个标记预测可靠学习。这种能力需要架构机制：（1）连续时间状态表示，（2）独立于语言模式匹配的显式约束检查，（3）对时间关系的系统性组合推理。当前自回归架构缺乏这些机制，在没有结合符号推理模块的混合架构的情况下，将此类系统部署在时间关键型应用中存在不可接受的风险。  

---

### 5 Continual Learning of Domain Knowledge from Human Feedback in Text-to-SQL

**link**: https://arxiv.org/pdf/2511.10674.pdf  
**date**: 2025-11-18  
**keywords**: Agent Memory, Procedural Memory  
**abs**: 大型语言模型（LLMs）能从自然语言生成SQL查询，但在数据库特定模式和隐性领域知识方面存在不足。本文提出一种从人类反馈中持续学习的框架，学习代理通过自然语言反馈优化查询，并将提炼的知识存储在结构化记忆中，以便未来任务重用。设计了多种捕获和检索过往经验的代理架构，实验表明记忆增强型代理（尤其是过程代理）通过人类反馈显著提升执行准确率并减少错误。研究强调将隐性人类专业知识转化为可重用知识的重要性，为构建自适应、领域感知的文本到SQL系统奠定基础。  

---

### 6 $π$-Attention: Periodic Sparse Transformers for Efficient Long-Context Modeling

**link**: https://arxiv.org/pdf/2511.10696.pdf  
**date**: 2025-11-18  
**keywords**: cs.CL  
**abs**: Transformer彻底改变了自然语言处理，但其与序列长度相关的二次复杂度仍是长程建模的基本瓶颈。尽管RingAttention等稀疏注意力机制通过将注意力限制在局部邻域降低了计算成本，但存在感受野有限和缺乏适应性的问题。本文提出π-Attention，一种周期性稀疏Transformer，将注意力分解为环形局部邻域、确定性π步长跳跃和自适应融合门。该周期性结构提供了对远距离标记的可预测覆盖，而稀疏足迹使每层复杂度与上下文长度呈线性关系。我们证明π-Attention实现了O(kL + π log L)的感受野增长，相比之下RingAttention为O(kL)（其中k为局部窗口大小，π为跳跃周期，L为序列长度）。在语言建模、检索和视觉-语言任务上的大量实验表明，π-Attention匹配或超越了密集注意力的质量，困惑度比RingAttention低8.3%，同时在相同上下文长度下使用的GPU减少50%。详细的消融实验和可视化揭示了周期性跳跃、自适应融合和头级稀疏协调对高效长上下文建模的重要性。  

---

### 7 Sabiá: Um Chatbot de Inteligência Artificial Generativa para Suporte no Dia a Dia do Ensino Superior

**link**: https://arxiv.org/pdf/2511.10787.pdf  
**date**: 2025-11-18  
**keywords**: cs.CL  
**abs**: 学生经常报告难以获取日常学术信息，这些信息通常分散在众多机构文件和网站中。这种碎片化导致日常大学信息缺乏清晰度并引起混淆。本项目提出开发一种使用生成式人工智能（GenAI）和检索增强生成（RAG）的聊天机器人，以简化对此类信息的访问。我们基于质量指标和LLM-as-a-Judge方法测试和评估了多个GenAI模型。其中，Gemini 2.0 Flash在质量和速度方面表现突出，而Gemma 3n则因其良好的性能和开源特性而表现优异。  

---

### 8 Requirements for Aligned, Dynamic Resolution of Conflicts in Operational Constraints

**link**: https://arxiv.org/pdf/2511.10952.pdf  
**date**: 2025-11-18  
**keywords**: cs.AI  
**abs**: 已部署的自主AI系统必须在新颖或未明确说明的环境中评估多种可能的行动方案（即行为的扩展序列）。尽管经过广泛训练，这些系统仍不可避免地会遇到没有任何行动方案能完全满足所有操作约束（如操作程序、规则、法律、规范和目标）的场景。为了按照人类期望和价值观实现目标，智能体必须超越其训练策略，转而构建、评估和证明候选行动方案。这些过程需要可能超出先前（策略）训练范围的上下文“知识”。本文描述了智能体在这些环境中决策的要求，并确定了智能体做出对目标稳健且与人类期望一致的决策所需的知识类型。通过分析和实证案例研究，我们探讨了智能体如何需要整合规范性、实用性和情境性理解，以在复杂的现实世界环境中选择并追求更一致的行动方案。  

---

### 9 HARNESS: Human-Agent Risk Navigation and Event Safety System for Proactive Hazard Forecasting in High-Risk DOE Environments

**link**: https://arxiv.org/pdf/2511.10810.pdf  
**date**: 2025-11-18  
**keywords**: cs.AI  
**abs**: 在任务关键工作场所的操作安全是首要任务，鉴于日常任务的复杂性和危险性。本文提出了人类-智能体风险导航与事件安全系统（HARNESS），这是一个模块化AI框架，旨在预测高危DOE环境中的危险事件并分析操作风险。HARNESS集成了大型语言模型（LLMs）与结构化工作数据、历史事件检索和风险分析，以主动识别潜在危险。人在回路机制允许领域专家（SMEs）优化预测，创建自适应学习循环，随时间提升性能。通过结合SME协作与迭代智能体推理，HARNESS提高了预测安全系统的可靠性和效率。初步部署显示出良好结果，未来工作将专注于准确性、SME一致性和决策延迟的定量评估。
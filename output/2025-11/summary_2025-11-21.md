### 1 Knowledge Graphs as Structured Memory for Embedding Spaces: From Training Clusters to Explainable Inference

**link**: https://arxiv.org/pdf/2511.14961.pdf  
**date**: 2025-11-21  
**keywords**: cs.LG  
**abs**: 本文提出了图记忆（Graph Memory, GM）框架，这是一种结构化非参数框架，通过区域级原型上的紧凑关系记忆增强基于嵌入的推理。GM不孤立处理每个训练实例，而是将嵌入空间总结为带有可靠性指标的原型节点，并通过边编码几何和上下文关系。该设计统一了实例检索、基于原型的推理和基于图的标签传播，形成支持高效推理和可信解释的归纳模型。在合成数据集和乳腺组织病理学（IDC）等真实数据集上的实验表明，GM实现了与kNN和标签传播相当的准确性，同时提供了更好的校准和更平滑的决策边界，且样本数量减少了一个数量级。通过显式建模可靠性和关系结构，GM为非参数学习中的局部证据与全局一致性之间提供了原则性桥梁。

---

### 2 Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs

**link**: https://arxiv.org/pdf/2511.15163.pdf  
**date**: 2025-11-21  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）越来越多地集成到智能辅导系统中，以提供类人化和适应性教学。然而，大多数现有方法未能捕捉学生知识如何随着其能力、概念差距和遗忘模式动态演变。在数学辅导中，有效教学需要精确校准到每个学生掌握水平和认知保留的细粒度支架，这一挑战尤为突出。为解决此问题，本文提出TASA（因材施教）框架，该框架整合了角色、记忆和遗忘动态，用于个性化数学学习。具体而言，TASA维护一个结构化的学生角色（捕捉能力概况）和事件记忆（记录先前学习交互）。通过结合具有知识追踪的连续遗忘曲线，TASA动态更新每个学生的掌握状态，并生成上下文适当、难度校准的问题和解释。实证结果表明，TASA相比代表性基线实现了更优的学习成果和更具适应性的辅导行为，强调了在基于LLM的辅导系统中建模时间遗忘和学习者概况的重要性。

---

### 3 LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering

**link**: https://arxiv.org/pdf/2511.15424.pdf  
**date**: 2025-11-21  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）凭借其深度语义理解能力正在重塑无监督学习，尤其在文本聚类方面展现出前所未有的潜力。然而，它们的直接应用受到根本性限制：缺乏用于迭代优化的有状态记忆（stateful memory）以及难以管理聚类粒度。因此，现有方法通常依赖带有外部模块的复杂流水线，无法实现真正的端到端。我们提出LLM-MemCluster，这是一种将聚类重新概念化为完全LLM原生任务的新框架。它利用动态记忆（Dynamic Memory）来注入状态感知，并采用双提示策略（Dual-Prompt Strategy）使模型能够推理和确定聚类数量。在多个基准数据集上的评估表明，我们的无调优框架显著且持续地优于强基线。LLM-MemCluster为基于LLM的文本聚类提供了一种有效、可解释且真正端到端的范式。

---

### 4 Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges

**link**: https://arxiv.org/pdf/2511.15652.pdf  
**date**: 2025-11-21  
**keywords**: cs.LG  
**abs**: 持续学习（CL）是机器学习的一个分支，旨在使智能体能够适应和泛化先前学习的能力，以便将其重新应用于新任务或环境。这在多任务设置或动态随时间变化的非平稳环境中特别有用，例如在自动驾驶等网络物理系统中尤为相关。然而，尽管持续学习近年来取得了进展，但将其成功应用于强化学习（RL）仍然是一个开放问题。

---

### 5 SNAP: Low-Latency Test-Time Adaptation with Sparse Updates

**link**: https://arxiv.org/pdf/2511.15276.pdf  
**date**: 2025-11-21  
**keywords**: cs.LG  
**abs**: 测试时自适应（TTA）利用未标记的测试数据调整模型以应对动态分布偏移。然而，现有方法依赖频繁的自适应和高计算成本，使其不适用于资源受限的边缘环境。为此，我们提出SNAP，一种稀疏TTA框架，可降低自适应频率和数据使用量，同时保持准确性。SNAP即使仅基于1%的输入数据流进行自适应，仍能保持竞争力的准确性，证明了其在非频繁更新下的鲁棒性。我们的方法引入了两个关键组件：（i）类别和域代表性记忆（CnDRM），它识别并存储一小部分同时代表类别和域特征的样本，以支持有限数据下的高效自适应；（ii）仅推理批量感知记忆归一化（IoBMN），它通过利用这些代表性样本在推理时动态调整归一化统计量，实现对变化目标域的高效对齐。与五种最先进的TTA算法集成后，SNAP将延迟降低高达93.12%，同时即使在1%至50%的自适应率范围内，准确率下降也保持在3.3%以下。这证明了其在服务于延迟敏感应用的边缘设备上的强大实用潜力。

---

### 6 Parameter Importance-Driven Continual Learning for Foundation Models

**link**: https://arxiv.org/pdf/2511.15375.pdf  
**date**: 2025-11-21  
**keywords**: cs.LG  
**abs**: 领域特定的后训练常导致灾难性遗忘，使基础模型丧失通用推理能力，限制其对动态现实环境的适应性。在大型语言模型和多模态模型中，保留通用能力同时获取下游领域知识是核心挑战。传统持续学习方法存在下游性能差、依赖不可访问的历史数据或额外参数开销等问题。本文提出PIECE，一种基于参数重要性估计的持续增强方法，无需访问先前训练数据或增加模型参数，即可保留通用能力并高效学习领域知识。PIECE在两种重要性估计器（基于Fisher信息的PIECE-F和结合梯度与曲率信息的二阶归一化PIECE-S）的指导下，仅选择性更新与新任务最相关的0.1%核心参数。在三种语言模型和两种多模态模型上的实验表明，PIECE能维持通用能力，并在多种下游任务上实现最先进的持续学习性能。研究结果为可扩展、领域自适应的基础模型提供了无灾难性遗忘的实用路径。

---

### 7 ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression

**link**: https://arxiv.org/pdf/2511.15069.pdf  
**date**: 2025-11-21  
**keywords**: cs.AI  
**abs**: 本文提出了ProRAC（基于进展的动作与变化推理），这是一种神经符号框架，利用大型语言模型（LLMs）解决动作与变化推理（RAC）问题。ProRAC从问题中提取包括动作和问题在内的基本RAC元素，逐步执行每个动作以推导出最终状态，然后根据进展后的状态评估查询以得出答案。在多个RAC基准上的评估表明，该方法在不同基准、领域、LLM基础模型和RAC任务类型上均表现出较强的性能。

---

### 8 Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents

**link**: https://arxiv.org/pdf/2511.15074.pdf  
**date**: 2025-11-21  
**keywords**: cs.AI  
**abs**: 机器学习模型在表格数据上的性能严重依赖高质量的特征工程。尽管大型语言模型（LLMs）在自动化特征提取（AutoFE）方面显示出潜力，但现有方法常受限于单一LLM架构、简单的定量反馈以及未能系统整合外部领域知识。本文介绍了Rogue One，一种新型的基于LLM的多智能体框架，用于知识驱动的自动特征提取。Rogue One实现了一个由三个专业智能体（科学家、提取器和测试器）组成的去中心化系统，它们通过迭代协作来发现、生成和验证预测性特征。关键的是，该框架超越了原始的准确率分数，引入了丰富的定性反馈机制和"泛洪-剪枝"策略，使其能够动态平衡特征的探索与利用。通过集成检索增强（RAG）系统主动融入外部知识，Rogue One生成的特征不仅具有统计效力，还具有语义意义和可解释性。在包含19个分类和9个回归数据集的综合测试中，Rogue One显著优于最先进的方法。此外，定性结果显示该系统能发现新的可测试假设，例如在心肌数据集中识别出新的潜在生物标志物，突显了其作为科学发现工具的实用性。

---

### 9 Dynamic Nested Hierarchies: Pioneering Self-Evolution in Machine Learning Architectures for Lifelong Intelligence

**link**: https://arxiv.org/pdf/2511.14823.pdf  
**date**: 2025-11-21  
**keywords**: cs.LG  
**abs**: 当代机器学习模型（包括大型语言模型）在静态任务中表现出卓越能力，但在非平稳环境中因架构僵化而难以持续适应和终身学习。基于嵌套学习范式（将模型分解为具有固定更新频率的多级优化问题），本研究提出动态嵌套层次结构，作为推进人工智能和机器学习的下一步进化。动态嵌套层次结构使模型能在训练或推理过程中自主调整优化层级数量、嵌套结构和更新频率，受神经可塑性启发，实现无预定义约束的自我进化。这一创新解决了现有模型的顺行性遗忘问题，通过动态压缩上下文流和适应分布偏移促进真正的终身学习。通过严格的数学公式、收敛性理论证明、表达能力边界、不同机制下的次线性遗憾，以及在语言建模、持续学习和长上下文推理中优越性能的实证演示，动态嵌套层次结构为自适应通用智能奠定了基础进展。

---

### 10 The Illusion of Procedural Reasoning: Measuring Long-Horizon FSM Execution in LLMs

**link**: https://arxiv.org/pdf/2511.14777.pdf  
**date**: 2025-11-21  
**keywords**: cs.AI  
**abs**: 大型语言模型（LLMs）在被构建为推理问题的任务上取得了显著成果，但其执行多步骤、基于规则计算的程序推理真实能力仍不明确。与能确定性执行长程符号程序的算法系统不同，LLMs在扩展推理链时往往表现下降，但缺乏可控、可解释的基准来隔离和测量这种崩溃。本文引入有限状态机（FSM）执行为评估LLMs程序推理能力的最小化、完全可解释框架。在该设置中，模型被给予明确的FSM定义，并需在给定输入动作时逐步执行，在多轮中保持状态一致性。该任务无需世界知识，仅需忠实应用确定性转换规则，是对模型内部程序保真度的直接探测。我们测量轮次准确率和任务准确率以区分即时计算与累积状态维护。实证结果显示，随着任务 horizon 或分支复杂度增加，性能系统性下降。当规则检索涉及高分支因子时，模型表现显著差于仅内存跨度长的情况。更大的模型显示出更高的局部准确率，但除非明确提示外化中间步骤，否则在多步推理中仍脆弱。基于FSM的评估为诊断这种失败模式和指导设计归纳偏置以实现真正的长程程序能力提供了透明、复杂度可控的探测方法。通过将推理建立在可测量的执行保真度而非表面正确性上，这项工作有助于为理解和提高LLMs的算法可靠性建立严格的实验基础。

---

### 11 Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents

**link**: https://arxiv.org/pdf/2511.14780.pdf  
**date**: 2025-11-21  
**keywords**: cs.AI  
**abs**: 本文提出Ask WhAI，一个用于检查和扰动多智能体交互中信念状态的系统级框架。该框架记录和重放智能体交互，支持带外查询每个智能体的信念和基本原理，并能注入反事实证据以测试信念结构对新信息的响应。我们将该框架应用于一个医疗案例模拟器，该模拟器具有多智能体共享内存（带时间戳的电子病历EMR）和一个持有仅在明确查询时才揭示的真实实验室结果的 oracle 智能体（LabAgent）。我们在一个儿童突发神经精神症状的多专科诊断过程中对系统进行压力测试。每个大型语言模型智能体都带有强烈的特定角色先验（“像神经科医生一样行动”、“像传染病专家一样行动”），写入共享医疗记录，并在顺序或并行会诊中与主持人交互。关键诊断时刻的断点允许事件前后的信念查询，能够区分根深蒂固的先验与推理或证据整合效应。模拟显示，智能体信念通常反映现实世界的学科立场，包括过度依赖规范研究和抵制反证据，并且这些信念可以通过人类专家无法实现的方式进行追踪和询问。通过使这些动态可见且可测试，Ask WhAI提供了一种可重现的方法来研究多智能体科学推理中的信念形成和认知孤岛。

---

### 12 As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files

**link**: https://arxiv.org/pdf/2511.15192.pdf  
**date**: 2025-11-21  
**keywords**: cs.AI  
**abs**: 大型语言模型（LLMs）的卓越语言能力源于在海量数据集（通常包含版权材料）上的广泛训练，这引发了关于未授权使用的严重担忧。虽然成员推理攻击（MIAs）为检测此类违规行为提供了潜在解决方案，但由于LLMs固有的过度自信、对真实训练数据的有限访问以及对经验确定阈值的依赖，现有方法面临关键限制和挑战。本文研究发现LLMs在识别见过的文件时表现出确定性，这一现象揭示了LLM记忆机制中可能存在的特性与漏洞。

---

### 13 IPR-1: Interactive Physical Reasoner

**link**: https://arxiv.org/pdf/2511.15407.pdf  
**date**: 2025-11-21  
**keywords**: cs.AI  
**abs**: 人类通过观察、与环境交互以及内化物理和因果关系来学习。本文旨在探究智能体是否能通过类似方式从交互中获取类人推理能力，并通过更多经验不断改进。研究在"游戏到未知"（G2U）设置中进行，构建了1000多个具有多样化物理和因果机制的异质游戏，并从生存、好奇、效用三个类人水平（从原始直觉到目标驱动推理）进行评估。分析揭示了互补性缺陷：VLM/VLA智能体能够推理但在交互环境中缺乏前瞻性，而世界模型能够想象但倾向于模仿视觉模式而非分析物理和因果关系。因此，本文提出IPR（交互式物理推理器），利用世界模型滚动来评分和强化VLM的策略，并引入PhysCode（一种以物理为中心的动作代码），将语义意图与动态对齐，为预测和推理提供共享动作空间。在1000多个游戏上预训练后，IPR在三个水平上表现稳健，总体性能与GPT-5相当，并在好奇水平上超越GPT-5。研究发现，随着训练游戏和交互步骤的增加，性能会提升，且模型能零样本迁移到未见过的游戏。这些结果支持以物理为中心的交互是稳步提升物理推理能力的有效途径，涉及智能体记忆与经验学习机制。
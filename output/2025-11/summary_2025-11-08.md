### 1 REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs

**link**: https://arxiv.org/pdf/2511.04228.pdf  
**date**: 2025-11-08  
**keywords**: cs.CL  
**abs**: 机器遗忘旨在无需完全重训练即可移除特定训练数据对模型的影响，这对确保隐私、安全和法规遵从性至关重要。然而，现有评估方法常局限于单个输入层面，可能忽略语义相似示例中存在的残余影响，从而危及隐私并导致间接信息泄露。本文提出REMIND（Residual Memorization In Neighborhood Dynamics），一种新的评估方法，通过分析模型在输入微小变化下的损失情况，揭示未被察觉的残余记忆并分类数据是否被有效遗忘。研究表明，未遗忘数据呈现更平坦的损失景观，而保留或无关数据则表现出更陡峭、更易变的模式。REMIND仅需基于查询的访问，在相似约束下优于现有方法，并在不同模型、数据集和释义输入上表现出鲁棒性，为评估语言模型中的遗忘效果提供了可靠框架。

---

### 2 DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration

**link**: https://arxiv.org/pdf/2511.04646.pdf  
**date**: 2025-11-08  
**keywords**: cs.AI  
**abs**: 合作多智能体规划要求智能体在信息不完全和通信有限的情况下做出联合决策。本文提出DR. WELL，一个用于合作多智能体规划的去中心化神经符号框架。合作通过两阶段协商协议展开：智能体首先提出带有推理的候选角色，然后在共识和环境约束下承诺联合分配。承诺后，每个智能体独立为其角色生成并执行符号计划，无需透露详细轨迹。计划通过共享世界模型（编码当前状态并随智能体行动更新）基于执行结果进行接地。通过对符号计划而非原始轨迹进行推理，DR. WELL避免了脆弱的步骤级对齐，并实现了可重用、可同步和可解释的更高层次操作。在合作推块任务上的实验表明，智能体能够跨 episode 适应，动态世界模型捕捉可重用模式并提高任务完成率和效率。

---

### 3 RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG

**link**: https://arxiv.org/pdf/2511.04502.pdf  
**date**: 2025-11-08  
**keywords**: cs.CL  
**abs**: 检索增强生成（RAG）是将大型语言模型（LLMs）基于事实证据的关键技术，但在专业、安全关键领域评估RAG系统仍面临重大挑战。现有评估框架常依赖无法捕捉领域特定细微差别的启发式指标，或使用缺乏与人类判断验证对齐的LLM-as-a-Judge方法。本文介绍RAGalyst，这是一个自动化、与人类对齐的智能体框架，专为领域特定RAG系统的严格评估而设计。RAGalyst具有智能体管道，能从源文档生成高质量的合成问答（QA）数据集，并结合智能体过滤步骤确保数据保真度。该框架通过提示优化改进两个关键的LLM-as-a-Judge指标——答案正确性和可回答性，以实现与人类注释的强相关性。将该框架应用于评估三个不同领域（军事行动、网络安全和桥梁工程）的各种RAG组件，发现性能高度依赖上下文，没有单一的嵌入模型、LLM或超参数配置被证明是普遍最优的。此外，还分析了RAG中答案正确性低的最常见原因。这些发现凸显了像RAGalyst这样的系统评估框架的必要性，它使从业者能够发现领域特定的权衡，并为构建可靠有效的RAG系统做出明智的设计选择。

---

### 4 Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics

**link**: https://arxiv.org/pdf/2511.04527.pdf  
**date**: 2025-11-08  
**keywords**: cs.CL  
**abs**: 当语言模型生成文本时，单个标记的选择可能会引导其进入截然不同的推理路径，这使得不确定性难以量化。在这项工作中，我们研究推理型语言模型是否在生成过程中表示它们可能采取的替代路径。在实验中，我们发现模型在不同标记处的不确定性与通过控制其激活来引导模型的难易程度之间存在明显相关性。这表明，当模型存在替代路径时——即尚未确定特定最终答案时，激活干预最为有效。我们还发现，隐藏激活能够预测模型的未来结果分布，表明模型隐式地表示了可能路径的空间。

---

### 5 Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing

**link**: https://arxiv.org/pdf/2511.04002.pdf  
**date**: 2025-11-08  
**keywords**: cs.LG  
**abs**: 大型语言模型（LLMs）在各种推理任务上已达到接近人类的性能，但其在资源受限的物联网（IoT）设备上的部署仍不切实际，这主要由于其庞大的参数规模和内存密集型的自回归解码过程。尽管拆分计算通过在边缘设备和云服务器之间分配模型执行提供了一种有前景的解决方案，但现有方法未能解决自回归推理的独特挑战，特别是迭代式令牌生成过程和不断扩展的键值（KV）缓存需求。本文介绍了首个专为边缘设备上LLM部署设计的自回归感知拆分计算框架。该方法有三个主要贡献：首先，开发了单点拆分压缩（OPSC），这是一种混合精度量化方案，通过将模型策略性地划分为具有不同精度级别的前端和后端部分，防止内存不足故障；其次，提出了一种两阶段中间压缩管道，结合阈值拆分（TS）和令牌级自适应位量化（TAB-Q），以保留对精度至关重要的激活，同时显著减少通信开销；第三，构建了一个统一的优化框架，联合选择最佳拆分点、量化设置和序列长度，以满足严格的内存和延迟约束。在不同LLM和硬件平台上的广泛评估表明，与SmoothQuant、OmniQuant和Atom等最先进的量化方法相比，该框架实现了1.49倍的推理加速和显著的通信开销减少，同时保持或提高了模型精度。

---

### 6 Forgetting is Everywhere

**link**: https://arxiv.org/pdf/2511.04666.pdf  
**date**: 2025-11-08  
**keywords**: cs.LG  
**abs**: 开发通用学习算法的一个基本挑战是它们在适应新数据时往往会忘记过去的知识。解决这一问题需要对遗忘有原则性的理解；然而，尽管经过数十年的研究，尚未出现一个统一的定义来深入了解学习的潜在动态。本文提出了一种与算法和任务无关的理论，将遗忘描述为学习者对未来经验的预测分布缺乏自一致性，表现为预测信息的丢失。该理论自然地产生了一种衡量算法遗忘倾向的通用方法。为了验证这一理论，作者设计了一系列全面的实验，涵盖分类、回归、生成建模和强化学习。实验结果表明，遗忘存在于所有学习环境中，并且在决定学习效率方面起着重要作用。这些结果共同建立了对遗忘的原则性理解，并为分析和改进通用学习算法的信息保留能力奠定了基础。

---

### 7 Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context

**link**: https://arxiv.org/pdf/2511.04464.pdf  
**date**: 2025-11-08  
**keywords**: Agent Memory, Personal Memory, cs.AI  
**abs**: 传统车辆路由系统优化单一指标，缺乏整合人类驾驶员复杂语义和动态上下文（如多步任务、情境约束或紧急需求）的能力。本文提出PAVe（个性化智能车辆路由），一种混合智能助手，通过多目标Dijkstra算法生成候选路线，结合LLM代理评估用户提供的任务、偏好和规避规则。该系统利用预处理的城市兴趣点地理空间缓存，在现实城市场景基准测试中，本地模型初始路线选择准确率超88%。研究表明，经典路由算法与基于LLM的语义推理层结合，能有效创建个性化、自适应的城市移动优化解决方案，涉及Agent对用户偏好等个人记忆的整合与应用。

---

### 8 Scaling Agent Learning via Experience Synthesis

**link**: https://arxiv.org/pdf/2511.03773.pdf  
**date**: 2025-11-08  
**keywords**: cs.AI  
**abs**: 尽管强化学习（RL）可通过交互增强大型语言模型（LLM）智能体的自我改进能力，但其实际应用因昂贵的rollouts、有限的任务多样性、不可靠的奖励信号和基础设施复杂性而受限，这些因素阻碍了可扩展经验数据的收集。为此，本文引入DreamGym，这是首个旨在合成多样化经验以实现自主智能体高效在线RL训练的统一框架。该框架不依赖昂贵的真实环境rollouts，而是将环境动态提炼为基于推理的经验模型，通过逐步推理生成一致的状态转换和反馈信号，从而实现可扩展的智能体rollout收集。为提升转换的稳定性和质量，DreamGym利用由离线真实世界数据初始化的经验回放缓冲区，并通过持续补充新交互来支持智能体训练。实验表明，DreamGym在多种环境和智能体架构上显著改进了RL训练效果，在纯合成设置和模拟到真实迁移场景中均表现优异。

---

### 9 ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering

**link**: https://arxiv.org/pdf/2511.03985.pdf  
**date**: 2025-11-08  
**keywords**: cs.AI  
**abs**: 基于LLM的智能体在自动化机器学习工程中展现出强大能力，但其严重依赖重复的完整训练运行来评估候选解决方案，导致计算开销大、搜索空间可扩展性有限和迭代周期缓慢。为解决这些挑战，本文提出ArchPilot，一种集成架构生成、基于代理的评估和自适应搜索的多智能体系统。其中，编排智能体采用受蒙特卡洛树搜索（MCTS）启发的新算法（含重启机制）协调搜索过程，并管理先前候选者的记忆；生成智能体迭代生成、改进和调试候选架构；评估智能体执行代理训练运行等任务。这种多智能体协作使ArchPilot能以最小化依赖昂贵完整训练的方式优先考虑高潜力候选方案，从而在有限预算下实现高效机器学习工程。

---

### 10 Shared Spatial Memory Through Predictive Coding

**link**: https://arxiv.org/pdf/2511.04235.pdf  
**date**: 2025-11-08  
**keywords**: cs.AI  
**abs**: 本文针对多智能体系统中共享和重建一致空间记忆这一关键挑战展开研究，提出了一种多智能体预测编码框架，将协调问题转化为智能体间 mutual uncertainty 的最小化。该框架以自监督运动预测自发形成的类网格细胞 metric 作为内部空间编码基础，在此之上，智能体逐步发展出带宽高效的通信机制，并形成编码伙伴位置的特化神经群体——人工海马社会位置细胞（SPCs）类似物。通过分层强化学习策略主动探索以减少联合不确定性，在 Memory-Maze 基准测试中，该方法对带宽约束表现出极强的韧性：当带宽从 128 位/步缩减至 4 位/步时，成功率从 73.5% 平缓降至 64.4%，而全广播基线则从 67.6% 骤降至 28.6%。研究结果为复杂社会表征如何从统一的预测驱动中涌现提供了理论严谨且生物学合理的基础，进而促进社会集体智能。
### 1 ALEX:A Light Editing-knowledge Extractor

**link**: https://arxiv.org/pdf/2511.14018.pdf
**date**: 2025-11-20
**keywords**: cs.AI
**abs**: 大型语言模型（LLMs）中的知识具有静态特性，难以适应不断变化的信息，因此知识编辑成为关键任务。然而现有方法在处理需要多步推理的复杂多跳问题时，面临可扩展性和检索效率的挑战。本文提出ALEX（轻量级编辑知识提取器），一种轻量级知识编辑框架。其核心创新在于分层记忆架构，将知识更新（编辑）组织为语义簇，将检索复杂度从线性O(N)降至高度可扩展的O(K+N/C)。此外，该框架集成推理查询合成（IQS）模块以弥合查询与事实间的语义差距，并采用动态证据裁决（DEA）引擎执行高效的两阶段检索过程。在MQUAKE基准上的实验表明，ALEX显著提高了多跳答案的准确性（MultiHop-ACC）和推理路径的可靠性（HopWise-ACC），同时将所需搜索空间减少80%以上，为构建可扩展、高效且准确的知识编辑系统提供了有前景的路径。

---

### 2 Object-Centric World Models for Causality-Aware Reinforcement Learning

**link**: https://arxiv.org/pdf/2511.14262.pdf
**date**: 2025-11-20
**keywords**: cs.LG
**abs**: 世界模型已被开发用于支持样本高效的深度强化学习智能体。然而，对于高维、非平稳且由多个具有丰富交互的对象组成的环境，世界模型难以准确复制，因为大多数世界模型学习所有环境组件的整体表示。相比之下，人类通过将环境分解为离散对象来感知环境，从而促进高效决策。受此启发，本文提出STICA（Slot Transformer Imagination with CAusality-aware reinforcement learning）框架，其中对象中心Transformer作为世界模型以及因果感知的策略和价值网络。STICA将每个观察表示为一组对象中心令牌，连同智能体动作和结果奖励的令牌，使世界模型能够预测令牌级别的动态和交互。策略和价值网络随后估计令牌级别的因果关系，并在注意力层中使用它们，实现因果引导的决策。在对象丰富的基准测试上的实验表明，STICA在样本效率和最终性能方面均优于最先进的智能体。

---

### 3 AutoTool: Efficient Tool Selection for Large Language Model Agents

**link**: https://arxiv.org/pdf/2511.14650.pdf
**date**: 2025-11-20
**keywords**: cs.AI
**abs**: LLM智能体借助LLM的推理和决策能力实现复杂任务自动化，但当前智能体框架在工具选择方面存在推理成本高的瓶颈，尤其是类似ReAct的方法需反复调用LLM来决定每一步使用的工具。本文提出AutoTool，一种基于图的新框架，其利用“工具使用惯性”（工具调用倾向于遵循可预测的顺序模式）这一关键经验观察来绕过重复的LLM推理。AutoTool从历史智能体轨迹构建有向图，节点表示工具，边捕获转移概率，有效建模工具选择中的惯性，并整合参数级信息优化工具输入生成。通过遍历此结构化表示，AutoTool以最小化对LLM推理的依赖高效选择工具及其参数。实验表明，AutoTool在多种智能体任务中减少高达30%的推理成本，同时保持有竞争力的任务完成率。该工作强调将统计结构整合到LLM智能体设计中以提高效率的潜力，其中历史智能体轨迹的使用涉及智能体记忆（Agent Memory）。

---

### 4 SkillGen: Learning Domain Skills for In-Context Sequential Decision Making

**link**: https://arxiv.org/pdf/2511.14670.pdf
**date**: 2025-11-20
**keywords**: cs.AI
**abs**: 大型语言模型（LLMs）通过上下文学习（ICL）越来越多地应用于序列决策，但其实效性高度依赖提示质量。有效的提示应满足三个原则：聚焦决策关键信息、提供步骤级粒度、通过标签效率减少对专家标注的依赖。然而现有ICL方法常无法同时满足这三个标准。为此，本文引入SkillGen，一种基于技能的ICL框架，用于结构化序列推理。它从采样轨迹构建以行动为中心的领域级图，通过时序差分信用分配识别高效用行动，并检索逐步技能以生成细粒度、上下文感知的提示。理论分析表明，聚焦高效用片段支持任务可识别性并为更有效的ICL提示设计提供信息。在ALFWorld、BabyAI和ScienceWorld上的实验显示，SkillGen实现了一致的性能提升，平均提高5.9%-16.5%的进度率。该框架中从采样轨迹学习逐步技能的过程涉及过程记忆（Procedural Memory）和智能体记忆（Agent Memory）。

---

### 5 AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance

**link**: https://arxiv.org/pdf/2511.14043.pdf
**date**: 2025-11-20
**keywords**: cs.AI
**abs**: AI科学辅助核心（AISAC）是阿贡国家实验室开发的集成多智能体系统，用于科学和工程工作流。该系统基于LangGraph（编排）、FAISS（向量搜索）和SQLite（持久化）等现有技术构建，集成到一个统一的原型中，重点关注透明度、溯源跟踪和科学适应性。其中SQLite的持久化功能涉及智能体记忆的存储与管理，属于Agent Memory的应用范畴。

---

### 6 APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design

**link**: https://arxiv.org/pdf/2511.14101.pdf
**date**: 2025-11-20
**keywords**: cs.AI
**abs**: APD-Agents是一个由大型语言模型驱动的多智能体协作框架，用于移动应用的自动页面设计。框架包含OrchestratorAgent、SemanticParserAgent、PrimaryLayoutAgent、TemplateRetrievalAgent和RecursiveComponentAgent。其中TemplateRetrievalAgent负责检索语义相关的少样本示例以增强布局生成质量，涉及智能体的检索记忆机制，属于Agent Memory的具体应用。实验结果表明，该框架在RICO数据集上实现了最先进的性能。

---

### 7 What Works for 'Lost-in-the-Middle' in LLMs? A Study on GM-Extract and Mitigations

**link**: https://arxiv.org/pdf/2511.13900.pdf
**date**: 2025-11-20
**keywords**: cs.CL
**abs**: 大型语言模型（LLMs）有效利用长程上下文的能力下降——即“中间遗忘”现象——在基于检索的LLM应用中构成重大挑战。本文引入GM-Extract基准数据集以评估LLM对控制变量的检索性能，并提出包含空间检索能力（文档指标）和语义检索能力（变量提取指标）的评估系统。通过对7-8B参数模型在多文档任务（键值提取和问答）上的评估，发现改变数据在上下文窗口中的表示方式会显著影响检索性能。研究还调查了黑盒和白盒两类缓解方法，分析了它们在实际场景中的效用，包括成功提升性能的情况及意外负面影响的案例。

---

### 8 Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports

**link**: https://arxiv.org/pdf/2511.14010.pdf
**date**: 2025-11-20
**keywords**: cs.CL
**abs**: 灾后勘察报告包含多灾害相互作用的关键证据，但其非结构化特性阻碍系统知识转移。本文提出混合检索智能体RAG（MoRA-RAG）框架，将勘察报告转化为多灾害推理的结构化基础。该框架集成混合检索机制动态路由查询，采用智能体分块保持检索时的上下文连贯性，并通过验证循环评估证据充分性、优化查询及启动定向搜索。基于GEER勘察报告构建的HazardRecQA数据集上，MoRA-RAG准确率达94.5%，优于零样本LLMs（+30%）和先进RAG系统（+10%），同时减少虚构内容，使开源LLMs性能接近专有模型，为灾后文档转化为可信灾害韧性情报提供新范式。

---

### 9 Tell Me: An LLM-powered Mental Well-being Assistant with RAG, Synthetic Dialogue Generation, and Agentic Planning

**link**: https://arxiv.org/pdf/2511.14445.pdf
**date**: 2025-11-20
**keywords**: cs.CL
**abs**: 本文提出了Tell Me，这是一个利用大型语言模型（LLM）技术的心理健康辅助系统，旨在为用户和研究人员提供可访问的、上下文感知的支持。该系统集成了三个核心组件：（1）基于检索增强生成（RAG）的助手，用于提供个性化、知识接地的对话（RAG技术与LLM Memory相关，通过检索外部知识来增强生成能力，属于记忆增强的一种形式）；（2）基于客户档案生成的合成客户-治疗师对话生成器，以促进治疗语言研究和数据增强；（3）借助CrewAI实现的“Well-being AI crew”，能够生成每周自我护理计划和引导式冥想音频（体现了Agent Memory的应用，智能体需要进行规划并可能保留上下文或计划信息）。该系统被设计为情感处理的反思空间，而非专业治疗的替代品。它展示了对话助手如何降低支持门槛、补充现有护理并扩大心理健康资源的获取。为解决保密治疗数据的短缺问题，本文引入了基于客户档案的合成客户-治疗师对话生成方法。最后，规划器展示了一种创新的智能体工作流程，用于动态适应的个性化自我护理，弥补了静态健康工具的局限性。文章描述了系统架构，展示了其功能，并通过自动LLM判断和人类用户研究报告了RAG助手在特定健康场景中的评估结果。这项工作凸显了NLP研究人员与心理健康专业人员之间跨学科合作的机会，以推动负责任的人类-AI健康交互创新。

---

### 10 ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents

**link**: https://arxiv.org/pdf/2511.14584.pdf
**date**: 2025-11-20
**keywords**: cs.LG
**abs**: ReflexGrad是一种新型架构，通过紧密耦合三种互补机制来实现LLM智能体的零样本泛化：（1）基于LLM的分层任务分解用于战略规划；（2）历史感知的因果反思，分析最近行动模式以识别失败根源并实现trial内学习；（3）基于梯度的优化以实现系统性改进。该系统通过纯LLM语义推理实现真正的零样本泛化，无需任务特定示例、微调或硬编码相似性度量。在ALFWorld基准任务上，ReflexGrad在首次尝试（Trial 0）中展示了67%的零样本成功率，无需任何先前任务经验或演示。实证分析识别了稳定收敛（零行动循环）和有效跨任务迁移（67%至78%的改进）背后的架构机制。该研究表明，互补学习机制的协同整合使LLM智能体能够实现强大的零样本泛化能力，涉及Agent Memory中的历史感知反思和经验学习机制。

---

### 11 Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning

**link**: https://arxiv.org/pdf/2511.14460.pdf
**date**: 2025-11-20
**keywords**: cs.CL
**abs**: 大型语言模型（LLMs）正越来越多地被探索用于构建能够主动与环境交互（例如通过工具使用）以解决复杂问题的智能体（Agents）。强化学习（RL）被认为是训练此类智能体的关键技术，具有巨大潜力；然而，RL在LLM智能体中的有效应用仍处于起步阶段，并面临相当大的挑战。目前，这一新兴领域缺乏针对LLM智能体上下文的RL方法的深入探索，同时也缺乏为此目的设计的灵活且易于扩展的训练框架。为了推动这一领域的发展，本文首先通过系统扩展马尔可夫决策过程（MDP）框架来重新审视和阐明LLM智能体的强化学习方法，以全面定义LLM智能体的关键组件。其次，我们引入Agent-R1，这是一个模块化、灵活且用户友好的基于RL的LLM智能体训练框架，旨在轻松适应各种任务场景和交互环境。我们在多跳问答基准任务上进行了实验，为我们提出的方法和框架的有效性提供了初步验证。

---

### 12 CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design

**link**: https://arxiv.org/pdf/2511.14510.pdf
**date**: 2025-11-20
**keywords**: cs.LG
**abs**: 百万token规模的大型语言模型（LLM）的发展暴露了推理系统的可扩展性限制，其中KV缓存（KVCache）主导了内存使用和数据传输开销。近期的卸载系统将KV缓存迁移到CPU内存，并结合top-k注意力机制以减少从CPU传输的数据量，同时进一步应用系统级优化（如GPU端缓存和预取）来降低传输开销。然而，这些系统忽视了CPU在三个方面的瓶颈：（1）CPU端执行的细粒度动态缓存管理带来的大量开销；（2）CPU端繁重的聚集操作导致PCIe带宽利用率低下，从而产生显著的传输开销；（3）以CPU为中心的粗粒度同步引入的GPU运行时气泡。为解决这些挑战，本文提出CLO，一种通过算法-系统协同设计实现的轻CPU KV缓存卸载系统。CLO的特点包括：（1）一种粗粒度的基于头的近似GPU端缓存策略，缓存管理成本可忽略不计；（2）将数据预取与GPU端持久化缓存无缝结合，以降低传输开销；（3）零拷贝传输引擎以充分利用PCIe带宽，以及GPU中心同步方法以消除GPU停滞。在两个广泛使用的LLM上的评估表明，CLO实现了与最先进系统相当的准确性，同时显著降低了CPU开销，充分利用了PCIe带宽，从而将解码吞吐量提高了9.3%-66.6%。研究结果强调，算法-系统协同设计对于现代GPU平台上内存受限的LLM推理至关重要。

---

### 13 π*₀.₆: a VLA That Learns From Experience

**link**: https://arxiv.org/pdf/2511.14759.pdf
**date**: 2025-11-20
**keywords**: cs.LG
**abs**: 本文研究视觉-语言-动作（VLA）模型如何通过强化学习（RL）在真实世界部署中实现改进。提出了一种通用方法——基于优势条件策略的经验与修正强化学习（RECAP），该方法通过优势条件对VLA模型进行RL训练。此方法将异构数据（包括演示数据、在线策略收集的数据以及自主执行过程中提供的专家远程操作干预）整合到自我改进过程中。RECAP首先通过离线RL预训练一个通用VLA模型π*₀.₆，该模型可通过机器人数据收集专门化以在下游任务上实现高性能。研究表明，使用完整RECAP方法训练的π*₀.₆模型能够在真实家庭中折叠衣物、可靠地组装盒子以及使用专业咖啡机制作浓缩咖啡。在一些最困难的任务上，RECAP将任务吞吐量提高了一倍以上，并将任务失败率大致降低了一半。
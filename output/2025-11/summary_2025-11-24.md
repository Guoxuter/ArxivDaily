### 1 Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach

**link**: https://arxiv.org/pdf/2511.16786.pdf  
**date**: 2025-11-24  
**keywords**: LLM Memory, KV Cache Compression, 多模态大语言模型, 推理优化  
**abs**: 多模态大型语言模型因多模态KV缓存随视觉输入长度成比例增长而面临巨大的推理开销。现有多模态KV缓存压缩方法大多依赖注意力分数来减小缓存大小，这使得它们与已建立的高效注意力内核（如FlashAttention）不兼容，并且忽略了值向量对注意力输出的贡献。本文从KV矩阵分布的角度重新审视多模态KV缓存压缩。首先，观察到多模态KV矩阵的频域能量主要集中在低频，并通过低通滤波器提取这一主能量。进一步发现，移除显著偏离此主能量的KV对会导致明显的性能下降，将其定义为异常KV。考虑到异常KV更可能编码对推理至关重要的特征，提出了FlashCache，一种频域引导的、异常KV感知的KV缓存压缩框架。该框架包括异常KV识别模块（在频域中建模多模态KV矩阵的主成分，并优先保留显著偏离主成分的KV对）和动态预算分配模块（自适应确定每层KV缓存大小以保留更多异常KV）。在多个MLLM和基准测试上的实验表明，FlashCache优于最先进的多模态KV压缩方法，实现了高达1.69倍的解码速度提升和80%的KV内存使用降低，同时保持了任务性能。

---

### 2 PersonalizedRouter: Personalized LLM Routing via Graph-based User Preference Modeling

**link**: https://arxiv.org/pdf/2511.16883.pdf  
**date**: 2025-11-24  
**keywords**: cs.LG  
**abs**: 随着具有不同能力和响应风格的大型语言模型（LLMs）数量不断增加，用户在选择合适模型时面临挑战，因为用户在性能、成本和响应风格等方面的偏好存在差异。当前的LLM选择方法通常针对单一固定目标进行优化，未能从交互数据中学习个体用户偏好。为此，本文提出PersonalizedRouter，这是一个基于图的框架，通过利用包含任务上下文、查询、候选LLMs和用户决策的交互数据，对多样化的用户档案进行建模并执行个性化LLM选择。该框架将交互数据转换为异质图，以捕获用户查询与最优LLM之间的上下文信息。实验结果表明，PersonalizedRouter显著优于现有LLM选择方法，在包含1000名模拟用户和10个LLM的PersonaRoute-Bench基准测试中表现出优越性能，同时具有较强的少样本泛化能力。

---

### 3 InTAct: Interval-based Task Activation Consolidation for Continual Learning

**link**: https://arxiv.org/pdf/2511.17439.pdf  
**date**: 2025-11-24  
**keywords**: cs.LG  
**abs**: 持续学习旨在使神经网络能够获取新知识而不忘记先前学习的信息。尽管最近的基于提示的方法在类别增量设置中表现出色，但在输入分布变化而标签空间固定的领域偏移情况下仍然脆弱，这暴露了一个被称为表示漂移的持续问题。共享表示的演变会覆盖先前有用的特征，即使提示隔离了任务特定参数，也会导致遗忘。为解决此问题，本文提出InTAct方法，该方法无需冻结参数或存储过去数据即可保留共享层中的功能行为。InTAct捕获与先前学习任务相关的特征激活范围，并约束更新以确保网络在这些区域内保持一致性，同时允许在其他地方灵活适应。通过这种方式，InTAct稳定重要神经元的功能角色，而非直接限制参数值。该方法与架构无关，可无缝集成到现有的基于提示的持续学习框架中。通过调节过去知识编码处的表示变化，InTAct实现了稳定性和可塑性之间的原则性平衡。在包括DomainNet和ImageNet-R在内的多种领域增量基准测试中，InTAct持续减少表示漂移并提高性能，平均准确率比最先进的基线高出多达8个百分点。

---

### 4 Towards Hyper-Efficient RAG Systems in VecDBs: Distributed Parallel Multi-Resolution Vector Search

**link**: https://arxiv.org/pdf/2511.16681.pdf  
**date**: 2025-11-24  
**keywords**: cs.CL  
**abs**: 检索增强生成（RAG）系统已成为利用外部知识增强大型语言模型（LLMs）的主要方法。然而，现有的向量数据库（VecDB）检索管道依赖于扁平或单分辨率索引结构，无法适应不同用户查询所需的不同语义粒度。这一限制导致检索速度和上下文相关性之间的次优权衡。

---

### 5 Reproducibility Report: Test-Time Training on Nearest Neighbors for Large Language Models

**link**: https://arxiv.org/pdf/2511.16691.pdf  
**date**: 2025-11-24  
**keywords**: cs.CL  
**abs**: 我们重现了《大型语言模型的最近邻测试时训练》（Hardt 和 Sun，2024）的核心观点，该研究提出通过在检索到的最近邻序列上进行微调来在推理时适配语言模型。使用预训练的 RoBERTa 嵌入（通过 Faiss 建立索引），我们为每个测试输入检索 20 个邻居，并在 GPT-2（117M、774M）、GPT-Neo（1.3B）和 R1-Distilled-Qwen2.5-1.5B 模型上对每个邻居应用一次梯度更新。我们的实验证实，测试时训练显著降低了来自 The Pile 中不同领域数据的困惑度和每字节比特数指标，在结构化或专业数据集（如 GitHub 和 EuroParl）上的改进最为显著。我们进一步验证，未在 The Pile 上预训练的模型比已在相似数据上训练的模型从这种适配中获益更多，使较小模型能够接近较大模型的性能。由于基础设施限制，我们引入了一种内存高效的检索实现，仅加载所需的行偏移量而非整个文件，将每台服务器的 RAM 需求从超过 128 GB 降至 32 GB。我们还通过评估 R1-Distilled-Qwen2.5-1.5B 扩展了原始研究，表明即使对于现代推理优化架构，测试时训练也能产生一致的收益。总体而言，我们的结果支持最近邻测试时训练的稳健性和通用性，同时强调了重现大规模检索增强适配的实际考虑因素。

---

### 6 Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation

**link**: https://arxiv.org/pdf/2511.17129.pdf  
**date**: 2025-11-24  
**keywords**: cs.CL, LLM Memory  
**abs**: 文本表示在聚类、检索等下游任务中至关重要。当前LLM因优化目标为下一个token预测，在生成整体表示方面并非最优。现有研究多采用token级别的 pretext任务（如LLM2Vec的掩码下一个token预测）来适应LLM进行文本表示，但效果有限。本文探索上下文压缩作为无监督适应LLM的pretext任务，模型学习生成紧凑的memory tokens以替代整个上下文用于下游序列预测。实验表明，精心设计的压缩目标能显著增强基于LLM的文本表示，优于token级pretext任务训练的模型。通过对比学习进一步改进，提出的LLM2Comp模型在多种任务上超越当代LLM文本编码器，且样本效率更高，所需训练数据显著减少。

---

### 7 PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM

**link**: https://arxiv.org/pdf/2511.17467.pdf  
**date**: 2025-11-24  
**keywords**: cs.LG  
**abs**: 我们提出了一种基于角色的语言模型系统新框架，旨在满足个性化AI代理适应个体用户偏好的需求。该框架中，代理体现用户的“角色”（如用户档案或喜好）并由大型语言模型（LLM）驱动。为使代理能利用丰富的上下文信息，我们引入知识图谱增强的检索增强生成（Graph RAG）机制，构建LLM衍生的相关文档图索引并总结相关信息社区。框架通过结合两部分生成个性化提示：（1）从知识图谱提取的用户历史行为与偏好摘要；（2）通过基于图的社区检测识别的相关全局交互模式。这种动态提示工程方法使代理在保持与角色一致行为的同时，还能受益于集体知识。在LaMP基准测试中，该方法将新闻分类F1提高11.1%，电影标签F1提高56.1%，产品评分MAE降低10.4%，性能优于先前方法。

---

### 8 Predicting the Formation of Induction Heads

**link**: https://arxiv.org/pdf/2511.16893.pdf  
**date**: 2025-11-24  
**keywords**: cs.CL  
**abs**: 可以说，被称为归纳头（IHs）的专门注意力头是现代语言模型（LMs）卓越的上下文学习（ICL）能力的基础；然而，对其形成的精确描述仍不明确。在本研究中，我们调查了训练数据（包括自然数据和合成数据）的统计特性与归纳头形成之间的关系。我们发现：（1）一个结合批量大小和上下文大小的简单方程可以预测归纳头形成的时间点；（2）表面二元组重复频率和可靠性强烈影响归纳头的形成，并且我们在这两个值方面发现了精确的帕累托前沿；（3）具有高二元组重复频率和可靠性的局部依赖性足以形成归纳头，但当频率和可靠性较低时，分类性和边缘分布的形状则变得重要。

---

### 9 A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM Agents

**link**: https://arxiv.org/pdf/2511.17208.pdf  
**date**: 2025-11-24  
**keywords**: cs.CL  
**abs**: 基于LLM的对话代理在多轮会话中仍难以维持连贯且个性化的交互：固定上下文窗口限制了可查看的历史记录量，而大多数外部记忆方法在对大块内容的粗略检索与对话的细粒度但碎片化视图之间存在权衡。受新戴维森事件语义学的启发，本文提出一种以事件为中心的替代方案，将对话历史表示为简短的类事件命题，这些命题将参与者、时间线索和最小局部上下文捆绑在一起，而非独立的关系三元组或不透明的摘要。与积极压缩或遗忘过去内容的工作不同，本设计旨在以非压缩形式保留信息并提高其可访问性，而非增加信息损失。具体而言，本文指导LLM将每个会话分解为丰富的基本话语单元（EDUs）——具有标准化实体和源轮归因的自包含语句，并将会话、EDUs及其参数组织在支持关联回忆的异构图中。在LoCoMo和LongMemEval_S基准上的实验表明，这些以事件为中心的记忆与强基线相当或超越，同时使用更短的QA上下文。结果表明，结构简单的事件级记忆为长时对话代理提供了原则性和实用性的基础。

---

### 10 Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs

**link**: https://arxiv.org/pdf/2511.16837.pdf  
**date**: 2025-11-24  
**keywords**: cs.AI  
**abs**: Cognitive BASIC是一种极简的类BASIC提示语言和模型内解释器，将大型语言模型（LLM）的推理过程结构化为由显式、逐步执行的轨迹。受复古BASIC语言简洁性的启发，该方法重新利用编号行和简单命令作为可解释的认知控制层。现代LLM能够可靠地模拟此类短程序，从而在模型内部实现透明的多步推理。自然语言解释器文件指定命令语义、内存更新和日志记录行为。其心智模型解释器可提取声明性和程序性知识（Procedural Memory相关），检测矛盾并在必要时生成解决方案。在知识提取、冲突检测和推理任务的基准测试中，所有模型均能执行Cognitive BASIC程序，表现出较强但不一致的性能。

---

### 11 MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists

**link**: https://arxiv.org/pdf/2511.16997.pdf  
**date**: 2025-11-24  
**keywords**: cs.AI  
**abs**: 当前AI科学家研究多将科学发现视为孤立的优化或搜索过程，忽视知识生产的社会性和历史性。人类科学洞见源于个体认知轨迹（研究历史和风格偏好）与集体学科记忆（引文和概念网络），而现有LLM难以表示这些结构化认知和社会语境。为此，本文提出MirrorMind，一种分层认知架构，通过三级框架整合双记忆表示：（1）个体层：通过捕捉情景记忆、语义记忆和人格记忆（Personal Memory相关）构建研究者的高保真认知模型；（2）领域层：将集体知识映射为结构化学科概念图；（3）跨学科层：作为正交协调引擎。该架构分离记忆存储与智能体执行（Agent Memory相关），使AI科学家智能体可灵活访问个体记忆获取独特视角或集体结构进行推理。在作者级认知模拟、互补推理等任务上的评估表明，MirrorMind超越简单事实检索，实现结构化、个性化和洞见生成的科学推理。

---

### 12 The Belief-Desire-Intention Ontology for modelling mental reality and agency

**link**: https://arxiv.org/pdf/2511.17162.pdf  
**date**: 2025-11-24  
**keywords**: cs.AI  
**abs**: 信念-愿望-意图（BDI）模型是人工智能和认知科学中表示理性智能体的基石，但其与结构化、语义互操作的知识表示的集成仍有限。本文提出了一个正式的BDI本体论，将其设计为模块化的本体设计模式（ODP），通过信念、愿望、意图及其动态相互关系捕捉智能体的认知架构。该本体论通过与基础本体论和模块化设计最佳实践对齐，确保了语义精确性和可重用性。两项互补的实验展示了其适用性：（i）通过逻辑增强生成（LAG）将本体论与大型语言模型（LLMs）耦合，以评估本体论基础对推理连贯性和一致性的贡献；（ii）将本体论集成到Semas推理平台中，该平台实现了三元组到信念到三元组（T2B2T）范式，支持RDF三元组与智能体心理状态之间的双向流动。这些实验共同表明，BDI本体论可作为声明式和过程式智能之间的概念和操作桥梁，为在数据网络中运行的认知接地、可解释且语义互操作的多智能体和神经符号系统铺平了道路。

---

### 13 Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism

**link**: https://arxiv.org/pdf/2511.17198.pdf  
**date**: 2025-11-24  
**keywords**: cs.AI  
**abs**: LLM驱动的智能体，尤其是使用ReAct等通用框架或类人角色扮演的智能体，在需要严格结构化工作流的专业领域常常面临困难。本文提出了一种以分层任务抽象机制（HTAM）为中心的新型智能体设计框架。HTAM超越了模拟社会角色，而是将多智能体系统构建为反映特定领域内在任务依赖图的逻辑层次结构。这种以任务为中心的架构确保了过程正确性，并将复杂问题分解为顺序层，其中每一层的子智能体基于前一层的输出进行操作。我们将该框架实例化为EarthAgent，这是一个专为复杂地理空间分析设计的多智能体系统。为评估此类复杂规划能力，我们构建了GeoPlan-bench，一个包含真实、多步骤地理空间规划任务的综合基准，并配有评估工具选择、路径相似性和逻辑完整性的指标套件。实验表明，EarthAgent显著优于一系列已建立的单智能体和多智能体系统。我们的工作表明，使智能体架构与领域的内在任务结构对齐是构建稳健可靠的专业自主系统的关键一步。

---

### 14 Agentifying Agentic AI

**link**: https://arxiv.org/pdf/2511.17332.pdf  
**date**: 2025-11-24  
**keywords**: cs.AI  
**abs**: 智能体化人工智能（Agentic AI）旨在赋予系统持续的自主性、推理和交互能力。为实现这一愿景，其关于智能体的假设必须辅以认知、合作和治理的显式模型。本文认为，自主智能体与多智能体系统（AAMAS）社区开发的概念工具，如BDI架构、通信协议、机制设计和制度建模，恰好提供了这样的基础。通过将自适应、数据驱动的方法与结构化的推理和协调模型相结合，我们概述了构建智能体系统的路径，这类系统不仅具备能力和灵活性，而且透明、合作且负责任。其结果是一种弥合形式理论与实际自主性的智能体视角。
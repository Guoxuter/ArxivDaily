### 1 Retracing the Past: LLMs Emit Training Data When They Get Lost

**link**: https://arxiv.org/pdf/2511.05518.pdf  
**date**: 2025-11-12  
**keywords**: LLM Memory  
**abs**: 该论文探讨了大型语言模型（LLMs）对训练数据的记忆问题，这一问题引发了严重的隐私和版权担忧。现有数据提取方法（尤其是基于启发式的发散攻击）成功率有限，且对记忆泄漏的根本驱动因素缺乏深入了解。本文提出了混淆诱导攻击（CIA）框架，通过系统性最大化模型不确定性来提取记忆数据。实验表明，在发散过程中记忆文本的释放之前，会出现标记级预测熵的持续峰值。CIA利用这一洞察，通过优化输入片段来故意诱导这种连续的高熵状态。对于对齐的LLMs，作者进一步提出不匹配监督微调（SFT），以同时削弱其对齐并诱导目标混淆，从而增加对攻击的敏感性。在各种未对齐和对齐的LLMs上的实验表明，该攻击在无需训练数据先验知识的情况下，在提取逐字和近逐字训练数据方面优于现有基线。研究结果突显了各种LLMs中持续存在的记忆风险，并提供了一种更系统的评估这些漏洞的方法。

---

### 2 FlowMM: Cross-Modal Information Flow Guided KV Cache Merging for Efficient Multimodal Context Inference

**link**: https://arxiv.org/pdf/2511.05534.pdf  
**date**: 2025-11-12  
**keywords**: LLM Memory  
**abs**: 传统的KV缓存驱逐策略基于注意力分数丢弃不太关键的KV对，往往会降低生成质量，导致上下文丢失或幻觉。最近的研究转向KV合并，基于相似性将驱逐标记与保留标记合并。然而，在多模态场景中，模态标记的分布偏差和跨模态交互中的注意力偏差限制了其有效性。本文介绍了FlowMM，一种用于跨模态信息流引导的多模态KV缓存合并的自适应框架。FlowMM利用跨模态信息流动态应用特定层的合并策略，捕捉模态特定模式同时保持上下文完整性。此外，作者引入了敏感度自适应标记匹配机制，联合评估标记相似性和任务关键敏感度，合并低风险标记同时保护高敏感度标记。在各种领先的多模态大型语言模型上的广泛实验表明，FlowMM将KV缓存内存减少80%至95%，解码延迟减少1.3-1.8倍，同时保持有竞争力的任务性能。

---

### 3 DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning

**link**: https://arxiv.org/pdf/2511.05784.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLM）的遗忘技术对于保护隐私数据和移除有害知识至关重要。现有方法多依赖微调来平衡遗忘效率与通用语言能力，但通常需要训练数据或保留数据，这在现实场景中常不可用。本文提出DRAGON框架，一种基于推理的系统化框架，利用上下文思维链（CoT）指令在推理前保护已部署的LLM。该框架无需修改基础模型，而是利用LLM固有的指令跟随能力，并引入轻量级检测模块识别需遗忘的提示（无需保留数据），再通过专用CoT保护模型进行安全准确的上下文干预。此外，还引入了新的遗忘性能指标和持续遗忘设置。实验验证了DRAGON在三个代表性遗忘任务中的有效性，展示了其强大的遗忘能力、可扩展性和实际适用性。

---

### 4 Quantifying Edits Decay in Fine-tuned LLMs

**link**: https://arxiv.org/pdf/2511.05852.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 知识编辑是大型语言模型（LLMs）中用于纠正或注入特定事实的轻量级替代方案，而微调仍是适应新领域和任务的默认操作。本文系统量化了微调后编辑的衰减情况，研究微调如何影响知识编辑。通过评估两种最先进的编辑方法（MEMIT、AlphaEdit）和三种微调方式（全参数、LoRA、DoRA），在五个LLM和三个数据集上的232种实验配置中发现，微调后编辑会衰减，且不同配置下的存活率不同（如AlphaEdit编辑比MEMIT衰减更严重）。进一步提出选择性层微调策略，发现仅微调编辑层可有效移除编辑，但会略微降低下游性能。研究为知识编辑与微调的集成建立了实证基线和可行策略。

---

### 5 Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations

**link**: https://arxiv.org/pdf/2511.05901.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 检索增强生成（RAG）技术有望增强大型语言模型（LLMs）在医疗领域的临床适用性。本文综述了医疗RAG的技术实现、临床应用和伦理考虑，发现现有研究主要依赖公开数据，私有数据应用有限；检索方法多采用英语为中心的嵌入模型，LLM多为通用模型，医疗专用LLM使用有限；评估方面，自动指标关注生成质量和任务性能，人类评估侧重准确性、完整性等，但对偏差和安全性关注不足。应用集中在问答、报告生成、文本摘要和信息提取。研究指出医疗RAG仍处于早期阶段，需要在临床验证、跨语言适应和低资源支持方面取得进展，以实现可信和负责任的全球应用。

---

### 6 Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs

**link**: https://arxiv.org/pdf/2511.05933.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 强化学习（RL）通常被认为能提升语言模型的推理和泛化能力，但会降低记忆知识的性能。本文挑战这一观点，发现RL增强模型在纯知识回忆任务上（尤其是需要遍历层次结构化知识如医疗编码的任务）始终优于基础模型和监督微调（SFT）模型。研究假设这些增益源于模型在导航和搜索参数化知识层次结构时程序性技能的提升。通过结构化提示实验，发现明确引导SFT模型进行层次遍历可缩小性能差距（如在MedConceptsQA上从24pp降至7pp）。进一步发现，尽管提示能提高最终答案准确性，但RL增强模型在深度检索任务中仍保留更优的程序性路径回忆能力。层内激活分析显示，事实表示在SFT和RL模型间余弦相似度高，而查询表示差异显著，表明RL主要改变模型遍历知识的方式而非知识表示本身。

---

### 7 SR-KI: Scalable and Real-Time Knowledge Integration into LLMs via Supervised Attention

**link**: https://arxiv.org/pdf/2511.06446.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 本文提出SR-KI，一种将实时大规模结构化知识库（KB）整合到大型语言模型（LLM）中的新方法。SR-KI首先使用预训练编码器将知识库编码为键值对，并注入LLM的KV缓存。基于此表示，采用两阶段训练范式：首先定位LLM中的专用检索层，然后在该层应用基于注意力的损失以显式监督对相关KB条目的注意力。与依赖外部检索器和多阶段 pipeline 的传统检索增强生成方法不同，SR-KI通过在模型 latent 空间内执行检索支持端到端推理。该设计实现了注入知识的高效压缩并促进动态知识更新。综合实验表明，SR-KI能够在单个A100 40GB GPU上将多达40K个KB整合到7B LLM中，并实现强大的检索性能，在最佳任务上保持超过98%的Recall@10，所有任务平均超过88%。问答和KB ID生成任务的性能也表明，SR-KI在保持强大性能的同时实现了高达99.75%的注入KB压缩。

---

### 8 Rep2Text: Decoding Full Text from a Single LLM Token Representation

**link**: https://arxiv.org/pdf/2511.06571.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）在各种任务上取得了显著进展，但其内部机制仍大部分不透明。在本研究中，我们解决一个基本问题：能否从LLM中的单个最后token表示中恢复原始输入文本？我们提出Rep2Text，一种从最后token表示解码完整文本的新框架。Rep2Text采用可训练适配器，将目标模型的内部表示投影到解码语言模型的嵌入空间，然后自回归重建输入文本。在各种模型组合（Llama-3.1-8B、Gemma-7B、Mistral-7B-v0.1、Llama-3.2-3B）上的实验表明，平均而言，16-token序列中超过一半的信息可以从这种压缩表示中恢复，同时保持强大的语义完整性和连贯性。此外，我们的分析揭示了信息瓶颈效应：较长序列的token级恢复能力下降，但仍保持强大的语义完整性。此外，我们的框架对分布外医疗数据也表现出稳健的泛化能力。

---

### 9 IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction

**link**: https://arxiv.org/pdf/2511.07327.pdf  
**date**: 2025-11-12  
**keywords**: cs.AI  
**abs**: 近期深度研究智能体在通过外部资源动态推理进行自主知识构建方面展现出潜力，但现有方法依赖单一扩展上下文窗口，导致上下文窒息和噪声污染，限制了其在长程任务中的有效性。本文提出IterResearch，一种新颖的迭代深度研究范式，将长程研究重构为具有策略性工作空间重构的马尔可夫决策过程。通过将不断演化的报告作为记忆并定期合成见解，该方法在任意探索深度下保持一致的推理能力。此外，本文开发了效率感知策略优化（EAPO），一种通过几何奖励折扣激励高效探索并通过自适应下采样实现稳定分布式训练的强化学习框架。实验表明，IterResearch在六个基准上平均提升14.5个百分点，缩小了与前沿专有系统的差距，并能扩展到2048次交互，性能显著提升（从3.5%到42.5%），同时作为提示策略也能提升前沿模型在长程任务上的性能。

---

### 10 Discourse Graph Guided Document Translation with Large Language Models

**link**: https://arxiv.org/pdf/2511.07230.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL, Agent Memory  
**abs**: 将大型语言模型应用于全文档翻译仍具有挑战性，因为难以捕捉长距离依赖关系并在整个扩展文本中保持语篇连贯性。尽管最近的智能体机器翻译系统通过多智能体编排和持久记忆来缓解上下文窗口限制，但它们需要大量计算资源，并且对记忆检索策略敏感。我们提出了TransGraph，这是一种语篇引导框架，通过结构化语篇图明确建模块间关系，并选择性地将每个翻译片段基于相关图邻域进行条件限制，而不是依赖顺序或 exhaustive 上下文。在涵盖六种语言和不同领域的三个文档级机器翻译基准测试中，TransGraph在翻译质量和术语一致性方面始终超越强大的基线，同时显著降低了令牌开销。

---

### 11 Mixtures of SubExperts for Large Language Continual Learning

**link**: https://arxiv.org/pdf/2511.06237.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG, LLM Memory  
**abs**: 本文提出了一种名为“混合子专家（MoSEs）”的自适应参数高效微调方法，旨在解决大型语言模型（LLMs）在持续学习流任务中的挑战。传统PEFT方法面临灾难性遗忘或参数线性增长的困境，而MoSEs通过在Transformer层中集成稀疏混合子专家和任务特定路由机制，实现了最小化遗忘和高效扩展。该框架能隔离和保护子专家中的知识，同时允许知识迁移，在TRACE基准上显著优于传统持续学习方法，实现了内存和计算效率的提升。

---

### 12 Rethinking Retrieval-Augmented Generation for Medicine: A Large-Scale, Systematic Expert Evaluation and Practical Insights

**link**: https://arxiv.org/pdf/2511.06738.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）正在改变医学领域，但仍面临跟上快速发展的医学知识和提供可验证、基于证据的推理这两个基本挑战。检索增强生成（RAG）被广泛采用以通过检索到的证据补充模型输出来解决这些限制。然而，RAG是否能可靠地实现这些目标仍不清楚。本文呈现了迄今为止最全面的医学领域RAG专家评估，18位医学专家贡献了80,502条注释，评估了由GPT-4o和Llama-3.1-8B针对200个真实世界患者和USMLE风格查询生成的800个模型输出。系统地将RAG管道分解为证据检索、证据选择和响应生成三个组件。与预期相反，标准RAG常常降低性能：只有22%的top-16段落相关，证据选择仍然薄弱（精确率41-43%，召回率27-49%），与非RAG变体相比，事实性和完整性分别下降高达6%和5%。检索和证据选择仍是模型的关键失败点。进一步表明，包括证据过滤和查询重构在内的简单有效策略可显著缓解这些问题，提高MedMCQA和MedXpertQA的性能。

---

### 13 Learning to Focus: Focal Attention for Selective and Scalable Transformers

**link**: https://arxiv.org/pdf/2511.06818.pdf  
**date**: 2025-11-12  
**keywords**: cs.CL  
**abs**: 注意力是Transformer架构的核心组件，无论是仅编码器、仅解码器还是编码器-解码器模型。然而，标准的softmax注意力通常会产生嘈杂的概率分布，这可能会损害这些模型每一层的有效特征选择，特别是对于长上下文。本文提出了Focal Attention，这是一种简单而有效的修改，通过控制softmax温度来锐化注意力分布，该温度可以作为固定超参数或在训练期间作为可学习参数。这种锐化使模型能够专注于最相关的标记，同时抑制无关的标记。经验表明，Focal Attention在模型大小、训练数据和上下文长度方面比标准Transformer具有更好的扩展性。在各种基准测试中，它使用多达42%的更少参数或33%的更少训练数据实现了相同的准确性。在长上下文任务上，它提供了17%到82%的显著相对改进，证明了其在实际应用中的有效性。

---

### 14 Next-Latent Prediction Transformers Learn Compact World Models

**link**: https://arxiv.org/pdf/2511.05963.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: Transformer 用随序列长度增长的记忆和允许对过去标记进行临时查找的自注意力取代了循环机制。因此，它们缺乏将历史压缩为具有一致转换规则的紧凑潜在状态的内在动力，这往往导致学习到的解决方案泛化能力较差。我们引入了 Next-Latent Prediction (NextLat)，它通过在潜在空间中进行自监督预测来扩展标准的下一个标记训练。具体而言，NextLat 训练 Transformer 学习潜在表示，这些表示能够根据下一个输出标记预测其下一个潜在状态。理论上，我们证明这些潜在状态可证明收敛到信念状态，即预测未来所需的历史压缩信息。这个简单的辅助目标还为 Transformer 注入了循环归纳偏置，同时保持其架构、并行训练和推理不变。NextLat 有效地鼓励 Transformer 形成具有自身信念状态和转换动态的紧凑内部世界模型——这是标准下一个标记预测 Transformer 所缺乏的关键属性。在针对核心序列建模能力（世界建模、推理、规划和语言建模）的基准测试中，NextLat 在下游准确性、表示压缩和前瞻规划方面均显著优于标准下一个标记训练。NextLat 是一种简单高效的范式，用于塑造 Transformer 表示以实现更强的泛化能力。

---

### 15 MoSKA: Mixture of Shared KV Attention for Efficient Long-Sequence LLM Inference

**link**: https://arxiv.org/pdf/2511.06010.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 大型语言模型（LLMs）中不断增长的上下文长度导致键值（KV）缓存成为严重的性能瓶颈，其内存受限特性导致GPU利用率显著低下。本文提出混合共享KV注意力（MoSKA）架构，通过利用上下文数据的异质性解决此挑战。它区分每个请求的唯一序列和大量复用的共享序列。MoSKA的核心是新颖的共享KV注意力机制，通过批处理并发请求，将共享数据的注意力从一系列内存受限的GEMV操作转换为单个计算受限的GEMM。这得到了受MoE启发的稀疏注意力策略（用于修剪搜索空间）和专门针对唯一与共享数据的分离式基础设施的支持。这种综合方法在高上下文共享的工作负载中实现了高达538.7倍的吞吐量提升，为可扩展的LLM推理提供了清晰的架构路径。

---

### 16 Lethe: Layer- and Time-Adaptive KV Cache Pruning for Reasoning-Intensive LLM Serving

**link**: https://arxiv.org/pdf/2511.06029.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 大型语言模型（LLMs）的生成式推理通常涉及长解码序列，导致累积键值（KV）缓存产生大量内存和延迟开销。现有KV压缩方法主要关注减少长输入序列的预填充内存，但未能解决长文本生成中动态且层敏感的特性（这对推理任务至关重要）。本文提出Lethe，一种动态KV缓存管理框架，从解码的空间和时间维度引入适应性。在空间维度，Lethe执行分层稀疏感知分配，基于估计的注意力冗余为每个Transformer层分配令牌修剪预算。在时间维度，Lethe在生成过程中通过最近感知选择性保留（RASR）机制进行多轮令牌修剪。RASR通过考虑从演化注意力模式中导出的令牌相关性扩展传统的基于近期性的启发式方法，实现关于保留或驱逐哪些令牌的知情决策。实证结果表明，Lethe在不同模型和任务中实现了效率与生成质量的良好平衡，吞吐量提升高达2.56倍。

---

### 17 FLEX: Continuous Agent Evolution via Forward Learning from Experience

**link**: https://arxiv.org/pdf/2511.06449.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 由大型语言模型（LLMs）驱动的自主智能体已经革新了推理和问题解决能力，但在训练后仍保持静态，无法像智能生物在部署过程中那样通过经验成长。本文提出了基于经验的前向学习（FLEX），这是一种无梯度学习范式，能够使LLM智能体通过积累的经验实现持续进化。具体而言，FLEX通过在与环境交互过程中不断反思成功和失败，构建结构化的经验库，从而实现可扩展和可继承的进化。FLEX在数学推理、化学逆合成和蛋白质适应性预测任务上取得了显著改进（在AIME25上提升23%，USPTO50k上提升10%，ProteinGym上提升14%）。我们进一步发现了经验增长的明确缩放定律以及智能体间的经验继承现象，为可扩展和可继承的智能体持续进化迈出了一步。

---

### 18 Scaling Laws and In-Context Learning: A Unified Theoretical Framework

**link**: https://arxiv.org/pdf/2511.06232.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 本文提出了一个统一的理论框架，将缩放定律与Transformer中的上下文学习（ICL）涌现联系起来。分析表明，ICL性能与模型深度L、宽度d、上下文长度k和训练数据D遵循幂律关系，其指数由任务结构决定。研究显示，在特定条件下，Transformer在其前向传播中实现了基于梯度的元学习，有效学习率η_eff=Θ(1/√(Ld))。本文证明了在临界尺度上存在急剧的相变，并推导出在固定参数预算N=Ld下，最优深度-宽度分配倾向于L*∝N^(2/3)，d*∝N^(1/3)。在合成任务上的系统实验验证了预测，测量的缩放指数与理论密切匹配。该工作为ICL的涌现提供了必要和充分条件，并确立了Transformer在上下文中可学习内容的基本计算限制。

---

### 19 MrCoM: A Meta-Regularized World-Model Generalizing Across Multi-Scenarios

**link**: https://arxiv.org/pdf/2511.06252.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 基于模型的强化学习（MBRL）是提升泛化能力和样本效率的关键方法，但现有MBRL方法主要关注为单一任务构建世界模型，很少涉及跨不同场景的泛化。本文提出了元正则化上下文世界模型（MrCoM），一种能够跨多场景泛化的统一世界模型。该方法首先基于动态特性分解latent状态空间，以提高世界模型预测的准确性。此外，MrCoM采用元状态正则化来提取场景相关信息的统一表示，并通过元价值正则化使世界模型优化与跨多样场景目标的策略学习对齐。本文从理论上分析了MrCoM在多场景设置下的泛化误差上界，并通过系统实验证明其在不同场景中的泛化能力显著优于现有最先进方法。

---

### 20 Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward Reflective Intelligence

**link**: https://arxiv.org/pdf/2511.06798.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 本研究提出快速权重稳态重入层（FH-RL），这是一种整合快速权重联想记忆、稳态正则化和学习重入反馈的神经机制，用于近似神经网络中的自指计算。与标准Transformer架构在推理时的纯前馈方式不同，FH-RL无需外部循环即可实现内部递归，允许将先前的 latent 状态动态重新输入到持续的计算流中。研究通过三个新指标（信息重入比IRR、特征谱递归指数ESRI、表征漂移周期性RDP）评估内部动态，结果显示重入量随增益γ成比例增加，而学习反馈矩阵在中等增益下保持有界且结构更清晰。关键发现是在γ≈0.10-0.20区间出现稳定反射带，此时内部反馈表达性最强且频谱稳定：IRR平稳上升，ESRI接近零，RDP呈现一致低频周期。这些结果为反馈放大与稳态调节的平衡可产生类思考的内部处理提供定量证据，将现代快速权重架构与皮层重入及递归认知理论相联系。

---

### 21 MobileLLM-Pro Technical Report

**link**: https://arxiv.org/pdf/2511.06719.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG, LLM Memory  
**abs**: 本文介绍了MobileLLM-Pro，一个针对移动设备优化的10亿参数语言模型。该模型在11项标准基准测试中取得了最先进的结果，显著优于Gemma 3-1B和Llama 3.2-1B，同时支持长达128,000 tokens的上下文窗口，并且在4位量化下性能退化较小。其核心创新包括隐式位置蒸馏、专家模型合并框架、模拟驱动的数据混合以及4位量化感知训练与自蒸馏，旨在解决移动设备上低延迟AI应用的部署挑战。

---

### 22 Multi-Modal Continual Learning via Cross-Modality Adapters and Representation Alignment with Knowledge Preservation

**link**: https://arxiv.org/pdf/2511.06723.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG, LLM Memory, Agent Memory  
**abs**: 本文提出了一种基于预训练模型的多模态持续学习框架，旨在解决模型在学习新任务时有效整合多模态信息并防止灾难性遗忘的问题。该框架包含具有混合专家结构的跨模态适配器，用于促进跨任务的多模态信息整合；引入表示对齐损失以学习鲁棒的多模态表示；并通过正则化学习表示之间的关系来保留先前任务的知识。在多个多模态数据集上的实验表明，该方法在类增量和域增量学习中均优于基线，实现了更高的准确率和更少的遗忘。

---

### 23 Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning

**link**: https://arxiv.org/pdf/2511.06757.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG, LLM Memory  
**abs**: 本文提出了隐式联邦上下文学习（IFed-ICL）框架，旨在解决利用组织私有数据增强大型语言模型性能时面临的计算开销问题。该框架借鉴联邦学习思想建立分布式协作范式，通过将客户端本地上下文示例转换为隐式向量表示，实现在推理阶段的分布式协作计算，并注入模型残差流以提升性能。实验表明，IFed-ICL在多个文本分类任务上表现优异，避免了传统微调所需的大量参数更新，同时减少了联邦学习中客户端的数据传输和本地计算，实现了利用本地私有域数据的高效分布式上下文学习。

---

### 24 Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics

**link**: https://arxiv.org/pdf/2511.06776.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG, Procedural Memory  
**abs**: 本文针对通用大型语言模型在垂直领域（如电信）适应时面临的稀缺、低信息密度语料和移动/边缘设备约束问题，提出了数据轨迹对齐（DTA）框架。该框架将解决方案过程（不仅是最终答案）作为首要监督信号，包含两个阶段：初始化阶段利用强教师集成合成多样化、高覆盖率的候选数据；DTA阶段重写教师解决方案以对齐中间步骤和呈现风格与目标学生的归纳偏差，并通过一致性检查和基于反思的判断进行信号感知的示例选择。在电信数学任务上的实验表明，DTA实现了最先进的准确率，且在边缘推理设置下提高了效率，减少了对多样本投票的依赖和能源消耗。

---

### 25 Multi-modal Dynamic Proxy Learning for Personalized Multiple Clustering

**link**: https://arxiv.org/pdf/2511.07274.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 多聚类旨在从不同角度发现多样的潜在结构，但现有方法生成的聚类结果未考虑用户兴趣，需人工筛选。当前多模态解决方案存在静态语义刚性问题：预定义候选词无法适应数据集特定概念，固定融合策略忽略特征交互的演变。为此，本文提出Multi-DProxy，一种新颖的多模态动态代理学习框架，通过可学习的文本代理实现跨模态对齐。该框架引入：1)门控跨模态融合，通过自适应建模特征交互合成判别性联合表示；2)双约束代理优化，其中用户兴趣约束确保与领域概念的语义一致性，概念约束采用难例挖掘增强聚类区分度；3)动态候选管理，通过迭代聚类反馈优化文本代理。因此，Multi-DProxy不仅能通过代理有效捕捉用户兴趣，还能更精确地识别相关聚类。在多聚类基准数据集上的实验表明，该方法显著优于现有方法，为个性化多聚类任务提供了新途径，与个人记忆相关，涉及捕捉和利用用户特定兴趣与概念。

---

### 26 Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning

**link**: https://arxiv.org/pdf/2511.06946.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: Transformer在建模长期依赖关系方面表现出强大能力，并越来越多地被用作部分可观测环境下基于模型的强化学习（RL）中的世界模型。然而，与自然语言语料库不同，RL轨迹具有稀疏性和奖励驱动性，使得标准自注意力机制效率低下，因为它将权重均匀分布在所有过去的标记上，而不是强调对控制至关重要的少数转换。为解决此问题，我们在动态头的自注意力机制中引入结构化归纳先验：（i）头感知的记忆长度先验，将注意力限制在特定任务窗口；（ii）分布先验，学习对过去状态-动作对的平滑高斯加权。我们将这些机制集成到UniZero中，这是一种基于Transformer世界模型的基于模型的RL智能体，支持部分可观测环境下的规划。在Atari 100k基准测试上的实验表明，大多数效率提升来自高斯先验，它能平滑地将注意力分配给信息丰富的转换，而记忆长度先验常因过度严格的截断而丢失有用信号。特别是，高斯注意力相比UniZero在平均人类归一化分数上实现了77%的相对提升。这些发现表明，在具有非平稳时间依赖的部分可观测RL领域，离散记忆窗口难以可靠学习，而平滑分布先验能灵活适应不同时间范围并产生更稳健的数据效率。总体而言，我们的结果表明，将结构化时间先验直接编码到自注意力中可改善对动态建模至关重要的信息历史的优先级排序。

---

### 27 Q-RAG: Long Context Multi-step Retrieval via Value-based Embedder Training

**link**: https://arxiv.org/pdf/2511.07328.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 检索增强生成（RAG）方法通过为大型语言模型（LLM）高效筛选相关上下文来提升其性能，减少幻觉并降低推理成本。然而，大多数现有RAG方法侧重于单步检索，这对于需要多步搜索的复杂问题往往不足。最近出现了多步检索方法，通常涉及微调小型LLM以执行多步检索，但这种微调资源密集且无法使用更大的LLM。本文提出Q-RAG，一种通过强化学习（RL）微调嵌入模型以实现多步检索的新方法。Q-RAG为开放域问答提供了一种具有竞争力且资源高效的多步检索替代方案，并在流行的长上下文基准Babilong和RULER（上下文长达1000万token）上取得了最先进的结果。

---

### 28 TNT: Improving Chunkwise Training for Test-Time Memorization

**link**: https://arxiv.org/pdf/2511.07343.pdf  
**date**: 2025-11-12  
**keywords**: cs.LG  
**abs**: 具有深度测试时记忆模块的循环神经网络（RNN）（如Titans和TTT）代表了一种有前景的、线性扩展的范式，与Transformer不同。虽然这些表达性模型尚未达到最先进Transformer的峰值性能，但由于训练速度过慢和硬件利用率低，其潜力在很大程度上未被挖掘。现有并行化方法因块大小超参数存在根本冲突：大块提升速度但降低性能，需固定的次优折衷。为解决此挑战，本文引入TNT，一种通过两阶段过程将训练效率与推理性能解耦的新训练范式。第一阶段是利用分层记忆的效率聚焦预训练阶段：全局模块处理大型、硬件友好的块以获取长程上下文，多个并行局部模块处理细粒度细节。关键是，通过定期重置局部记忆状态，打破序列依赖以实现大规模上下文并行化。第二阶段是简短的微调阶段，仅将局部记忆模块调整为更小的高分辨率块大小，以最小开销最大化准确性。在Titans和TTT模型上的评估表明，TNT实现了训练速度的大幅提升（比最准确的基线配置快17倍），同时提高了模型准确性。这一改进消除了关键的可扩展性障碍，为开发表达性RNN奠定了实用基础，并促进未来缩小与Transformer性能差距的工作。

---

### 29 The Station: An Open-World Environment for AI-Driven Discovery

**link**: https://arxiv.org/pdf/2511.06309.pdf  
**date**: 2025-11-12  
**keywords**: cs.AI  
**abs**: 本文介绍了STATION，一个开放世界多智能体环境，模拟小型科学生态系统。利用扩展的上下文窗口，环境中的智能体能够进行长期科学探索，包括阅读同行论文、提出假设、提交代码、执行分析和发表结果。重要的是，没有中央系统协调它们的活动——智能体可以自由选择自己的行动并在Station中发展自己的叙事。实验表明，Station中的AI智能体在从数学到计算生物学再到机器学习的广泛基准上取得了新的最先进性能，特别是在圆堆积问题上超越了AlphaEvolve。随着智能体进行独立研究、与同行互动并建立累积历史，出现了丰富的叙事。从这些涌现的叙事中，新方法有机地产生，例如用于单细胞RNA测序批次整合的密度自适应算法。Station标志着在开放世界环境中由涌现行为驱动的自主科学发现的第一步，代表了超越刚性优化的新范式。

---

### 30 AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning

**link**: https://arxiv.org/pdf/2511.07262.pdf  
**date**: 2025-11-12  
**keywords**: cs.AI  
**abs**: 科学机器学习（SciML）将数据驱动推理与物理建模相结合，以解决科学和工程中的复杂问题。然而，SciML架构、损失函数设计和训练策略的设计仍是专家驱动的研究过程，需要大量实验和特定问题的见解。本文介绍了AgenticSciML，这是一个协作式多智能体系统，其中超过10个专业AI智能体通过结构化推理和迭代进化协作提出、批判和完善SciML解决方案。该框架集成了结构化辩论、检索增强的方法记忆（retrieval-augmented method memory）和集成引导的进化搜索，使智能体能够生成和评估关于架构和优化程序的新假设。在物理知情学习和算子学习任务中，该框架发现的解决方法比单智能体和人类设计的基线在误差减少方面高出多达四个数量级。智能体产生了新颖的策略——包括自适应混合专家架构、基于分解的PINNs和物理知情算子学习模型——这些在精选知识库中并未明确出现。这些结果表明，AI智能体之间的协作推理可以产生涌现的方法创新，为科学计算中可扩展、透明和自主的发现提供了一条路径。

---

### 31 DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas

**link**: https://arxiv.org/pdf/2511.07338.pdf  
**date**: 2025-11-12  
**keywords**: cs.AI  
**abs**: 通过向大型语言模型（LLMs）灌输角色来模拟人类档案正在迅速改变智能体行为模拟、LLM个性化和人机对齐领域的研究。然而，大多数现有合成角色仍然肤浅和简单，仅捕捉极少的属性，无法反映真实人类身份的丰富复杂性和多样性。我们引入DEEPPERSONA，这是一种可扩展的生成引擎，通过两阶段、分类法引导的方法合成叙事完整的合成角色。首先，我们通过挖掘数千个真实用户与ChatGPT的对话，算法构建了有史以来最大的人类属性分类法，包含数百个层次化组织的属性。其次，我们从该分类法中逐步采样属性，条件生成连贯且真实的角色，这些角色平均包含数百个结构化属性和约1MB的叙事文本，比先前工作深两个数量级。内在评估证实，与最先进的基线相比，属性多样性（覆盖率高32%）和档案独特性（高44%）有显著改善。在外部应用中，我们的角色将GPT-4.1-mini的个性化问答准确性在十个指标上平均提高11.6%，并大幅缩小（31.7%）模拟LLM公民与真实人类在社会调查中的响应差距。我们生成的国民在大五人格测试上比LLM模拟公民缩小了17%的性能差距。因此，DEEPPERSONA为高保真人类模拟和个性化AI研究提供了一个严谨、可扩展且无隐私问题的平台。

---

### 32 Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement

**link**: https://arxiv.org/pdf/2511.05931.pdf  
**date**: 2025-11-12  
**keywords**: cs.AI  
**abs**: 基于大型语言模型（LLM）的智能体越来越多地用于处理需要多步推理和代码修改的软件工程任务，表现出有前景但有限的性能。然而，大多数现有LLM智能体通常在静态执行框架内运行，缺乏从自身经验和过去轨迹中学习和自我改进的原则性机制。因此，它们的性能仍然受到初始框架设计和底层LLM能力的限制。我们提出了从接地经验中进行自我抽象（SAGE）框架，该框架使智能体能够从自身任务执行中学习，并通过自我抽象改进其行为。在初始轨迹之后，智能体从其接地经验中归纳出简洁的计划抽象，提炼关键步骤、依赖关系和约束。然后，这种学习到的抽象作为上下文指导反馈，优化智能体的策略并支持更结构化、更知情的后续执行。实证表明，SAGE在不同的LLM骨干和智能体架构上都能带来一致的性能提升。值得注意的是，当与GPT-5（high）骨干配对时，它比强大的Mini-SWE-Agent基线产生了7.2%的相对性能提升。SAGE在SWE-Bench Verified基准上进一步实现了强大的整体性能，使用Mini-SWE-Agent和OpenHands CodeAct智能体框架分别达到73.2%和74%的Pass@1解决率。
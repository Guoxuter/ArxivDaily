### EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory

**link**: https://arxiv.org/pdf/2511.01950
**date**: 2025-11-06
**keywords**: cs.LG
**abs**: 标准循环神经网络（如LSTM）难以处理长程依赖和噪声序列。本文提出输出条件门控（Output-Conditioned Gating）架构，使模型通过自我反思调节记忆门控，形成稳定反馈循环以增强记忆保留。最终模型EchoLSTM结合注意力机制，在Distractor Signal Task上准确率达69.0%，优于LSTM基线33个百分点；在ListOps基准测试中性能（69.8%）接近Transformer，但参数效率高5倍。触发敏感性测试证明其记忆系统更稳健。

---

### Learning Interactive World Model for Object-Centric Reinforcement Learning

**link**: https://arxiv.org/pdf/2511.02225
**date**: 2025-11-06
**keywords**: cs.LG
**abs**: 现有以对象为中心的强化学习方法忽略对象间交互。本文提出因子化交互对象中心世界模型（FIOC-WM），通过结构化表示学习对象和交互动态：利用预训练视觉编码器提取对象中心潜变量和交互结构，将任务分解为可组合原语，并训练分层策略（高层选择交互，低层执行）。在模拟机器人和具身AI测试中，FIOC-WM显著提升策略样本效率和泛化能力，证明模块化交互学习对鲁棒控制的关键作用。

---

### BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and Monitoring

**link**: https://arxiv.org/pdf/2511.02490
**date**: 2025-11-06
**keywords**: cs.LG
**abs**: 为应对阿尔茨海默病负担，本文提出BRAINS系统，利用大型语言模型（LLMs）进行检测与监测。系统采用双模块：认知诊断模块通过微调LLMs评估风险（基于MMSE、CDR评分等数据）；病例检索模块编码患者档案并检索相似病例，通过融合层增强上下文理解。真实数据集评估显示，BRAINS在疾病分类和早期认知衰退识别中有效，成为可扩展、可解释的早期检测工具。

---

### LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment

**link**: https://arxiv.org/pdf/2511.02371
**date**: 2025-11-06
**keywords**: cs.LG
**abs**: 多模态流数据索引面临新鲜度维护和跨模态一致性挑战。本文提出LUMA-RAG架构，核心创新包括：流式多层记忆系统（在内存预算下动态管理嵌入）、流式CLAP->CLIP对齐桥（通过增量更新维持一致性）、稳定性感知检索遥测（提供Safe@k保证）。实验显示，该架构实现文本到图像检索Recall@10=0.94，音频到图像排序Safe@1=1.0，性能优雅降级，适用于生产级多模态RAG系统。

---

### In Situ Training of Implicit Neural Compressors for Scientific Simulations via Sketch-Based Regularization

**link**: https://arxiv.org/pdf/2511.02659
**date**: 2025-11-06
**keywords**: cs.LG
**abs**: 本文提出原位训练协议，用于隐式神经压缩器：利用有限完整数据和草图数据样本（防止灾难性遗忘），基于Johnson-Lindenstrauss理论将草图作为正则化器。在复杂2D/3D模拟数据、长时间范围和非结构化网格上评估，该方法在高压缩率下表现强大重建性能。草图技术使原位方案匹配离线方法性能，为持续学习提供新思路。

---

### Curriculum Design for Trajectory-Constrained Agent: Compressing Chain-of-Thought Tokens in LLMs

**link**: https://arxiv.org/pdf/2511.02690
**date**: 2025-11-06
**keywords**: cs.LG
**abs**: 轨迹约束（如资源限制）使智能体训练复杂化。本文提出课程学习策略：通过逐步收紧约束（从简化版本开始），促进智能体适应部署要求。理论分析（二叉树MDP）证明该方法加速训练；在RL和LLM任务（如数学推理）上实证验证，其提升效率和性能。应用于LLM时，压缩思维链令牌实现推理加速，证明在资源受限部署中的有效性。

---

### From Solo to Symphony: Orchestrating Multi-Agent Collaboration with Single-Agent Demos

**link**: https://arxiv.org/pdf/2511.02762
**date**: 2025-11-06
**keywords**: cs.LG
**abs**: 多智能体强化学习（MARL）训练低效，依赖昂贵多智能体数据。本文提出Solo-to-Collaborative RL（SoCo）框架：从单独演示预训练共享策略，再通过策略融合机制（MoE式门控和动作编辑器）适应协作。在不同任务中，SoCo显著提高训练效率和性能，证明单独演示为多智能体数据提供可扩展补充，使协作学习更实用。

---

### Agentic AI for Mobile Network RAN Management and Optimization

**link**: https://arxiv.org/pdf/2511.02532
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 智能体人工智能（Agentic AI）通过大型AI模型实现复杂系统自动化，提供多模态感知、规划和推理能力。本文探讨其在5G/6G网络RAN优化中的应用：解决手动优化无效问题，但尚无标准框架。强调Agentic AI能自主分解目标、长期保留上下文和动态适应，为动态RAN环境决策提供新范式。

---

### Understanding New-Knowledge-Induced Factual Hallucinations in LLMs: Analysis, Solution, and Interpretation

**link**: https://arxiv.org/pdf/2511.02626
**date**: 2025-11-06
**keywords**: cs.CL
**abs**: 新知识微调导致LLMs事实性幻觉。本文设计Biography-Reasoning数据集分析：特定知识类型陌生性是主要驱动因素，影响问答任务。提出KnownPatch方法（修补少量已知知识样本）缓解幻觉。注意力分析显示，新知识降低关键实体注意力，增加上下文过度关注风险。该方法减轻注意力干扰，提升性能。

---

### Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning

**link**: https://arxiv.org/pdf/2511.02194
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 个体决策受数值属性和语言影响（如偏好）。本文提出ATHENA框架：整合效用理论（挖掘群体级符号效用）和LLM文本推理（个体级语义适应）。在出行和疫苗选择任务中，ATHENA F1分数优于基线6.5%，消融研究证明两阶段互补。为以人为中心决策建模提供新方案。

---

### Training Proactive and Personalized LLM Agents

**link**: https://arxiv.org/pdf/2511.02208
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 有效智能体需优化生产力（任务完成）、主动性（提问）和个性化（适应用户）。引入UserVille环境（模拟用户偏好），提出PPP多目标强化学习方法联合优化三维度。在软件工程和深度研究任务中，PPP智能体平均提升21.6分，展示战略提问、适应偏好和提升交互能力，证明以用户为中心优化的关键性。

---

### MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning

**link**: https://arxiv.org/pdf/2511.02805
**date**: 2025-11-06
**keywords**: cs.CL
**abs**: 搜索代理上下文冗长或信息丢弃限制可扩展性。提出MemSearcher工作流：迭代维护紧凑内存，结合当前轮次生成推理、搜索和更新内存。引入多上下文GRPO强化学习框架，联合优化推理、搜索和内存管理。在七个基准上，基于3B的MemSearcher优于7B基线（相对增益+11-12%），平衡信息完整性和效率。

---

### InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance

**link**: https://arxiv.org/pdf/2511.02119
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 洪水保险参与率低，需建模决策行为。构建基准数据集评估LLMs：LLMs定性理解因素但定量估计不足。提出InsurAgent代理（感知、检索、推理、行动、记忆模块）：检索模块用RAG基于实证数据估计概率；推理模块推断上下文；记忆模块模拟时间决策演变。为行为建模和政策分析提供工具。

---

### Human-AI Co-Embodied Intelligence for Scientific Experimentation and Manufacturing

**link**: https://arxiv.org/pdf/2511.02071
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 科学实验和制造依赖人类监督，限制可重复性和可扩展性。提出人机AI共体智能：整合人类执行、智能体AI（记忆、推理）和可穿戴硬件。演示系统APEX结合混合现实，观察人类动作、对齐标准流程、提供3D指导和分析步骤。在柔性电子制造中，APEX实现上下文感知推理，实时纠错，传授知识，将智能体推理扩展到物理领域。

---

### Kosmos: An AI Scientist for Autonomous Discovery

**link**: https://arxiv.org/pdf/2511.02824
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 数据驱动发现需文献搜索、假设生成和数据分析迭代。提出Kosmos AI科学家：给定目标和数据集，运行长达12小时，执行并行分析、搜索和生成循环，综合为科学报告。核心是结构化世界模型（共享信息），使代理在200次滚动中连贯追求目标（执行42,000行代码，阅读1,500篇论文）。报告引用所有代码或文献，79.4%陈述准确；在代谢组学等领域贡献新发现，单次运行等效6个月研究。

---

### ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning

**link**: https://arxiv.org/pdf/2511.02424
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 长程任务规划中，单一轨迹方法性能受限。提出ReAcTree分层方法：动态构建智能体树分解目标（智能体节点处理子目标，控制流节点协调执行），集成情景记忆（检索示例）和工作记忆（共享观察）。在WAH-NL和ALFRED数据集上，ReAcTree优于ReAct基线（Qwen 2.5 72B上成功率61% vs 31%），证明树结构和记忆系统提升复杂任务处理。

---

### Using Span Queries to Optimize for Cache and Attention Locality

**link**: https://arxiv.org/pdf/2511.02749
**date**: 2025-11-06
**keywords**: cs.AI
**abs**: 推理服务器优化不足，影响非聊天用例（如RAG）。引入跨度查询（span query）泛化接口：表达式树通过交换性约束链接，表示聊天、RAG等任务。自动优化提高KV缓存locality；对vLLM小修改（492行代码）实现高性能执行。实验显示，跨度查询降低TTFT 10-20倍，并优化注意力locality（20亿参数模型准确性超80亿参数普通服务器），解决“中间遗忘”问题。
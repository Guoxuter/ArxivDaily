### 1 HERMES: Towards Efficient and Verifiable Mathematical Reasoning in LLMs

**link**: https://arxiv.org/pdf/2511.18760.pdf  
**date**: 2025-11-26  
**keywords**: cs.AI  
**abs**: HERMES框架首次将非正式推理与正式验证证明步骤结合，通过中间形式化检查防止推理偏移，并采用记忆模块维持长推理链的连续性。实验表明，该框架在数学推理基准上显著提升准确性（如AIME'25数据集准确率提升67%），同时减少80%推理FLOPs和token消耗。

---

### 2 Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation

**link**: https://arxiv.org/pdf/2511.17541.pdf  
**date**: 2025-11-26  
**keywords**: cs.AI  
**abs**: 基于莱布尼茨《单子论》，本研究开发了AI记忆系统评估框架，将形而上学命题映射到信息论架构中。每个单子作为模块化单元，通过真值分数、冗余参数和惩罚函数定义，产生可解释的记忆老化、稳定性和显著性指标，为可证明可靠的AI记忆架构提供蓝图。

---

### 3 Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop

**link**: https://arxiv.org/pdf/2511.17673.pdf  
**date**: 2025-11-26  
**keywords**: cs.AI  
**abs**: 结构化认知循环（SCL）将代理认知分为检索、认知、控制、动作和记忆五阶段，通过软符号控制机制将符号约束应用于概率推理。SCL实现零策略违规、消除冗余工具调用，并保持决策可追溯性，为可靠、可解释的AI代理提供理论基础。

---

### 4 A³: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving

**link**: https://arxiv.org/pdf/2511.17560.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: A³算法基于文本块与问题的相关性预计算并选择性融合KV缓存，解决长上下文处理中的解码延迟问题。实验表明，A³在保持任务性能的同时，将首令牌生成时间（TTFT）减少2倍，优于现有基线。

---

### 5 Generative Caching for Structurally Similar Prompts and Responses

**link**: https://arxiv.org/pdf/2511.17565.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 生成式缓存通过识别相似提示结构的可重用响应模式，为新请求合成定制输出。该方法实现83%缓存命中率，在智能体工作流中将缓存命中率提高20%，端到端延迟减少34%。

---

### 6 General Agentic Memory Via Deep Research

**link**: https://arxiv.org/pdf/2511.18423.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 通用智能体记忆（GAM）框架采用即时编译原则，包含记忆器（轻量记忆存储关键信息）和研究员（检索整合有用信息）。实验表明，GAM在记忆任务中显著优于现有系统，支持端到端性能优化。

---

### 7 SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression

**link**: https://arxiv.org/pdf/2511.18936.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: SWAN通过正交矩阵旋转和剪枝KV缓存，实现无需解压缩的注意力计算。在50-60%内存节省下保持接近基线性能，支持运行时动态调整压缩级别，为长上下文LLM服务提供高效解决方案。

---

### 8 Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic Channel-wise Precision Boost

**link**: https://arxiv.org/pdf/2511.18643.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: Kitty通过混合精度KV缓存量化，仅对高敏感性通道保持更高精度。该方法实现近8倍KV内存削减，精度损失可忽略，在相同内存下支持8倍批处理量和2.1x-4.1x吞吐量提升。

---

### 9 RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context

**link**: https://arxiv.org/pdf/2511.18743.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: RhinoInsight通过可验证检查清单（结构化用户需求）和证据审计（排序高质量证据）模块，防止错误累积和上下文衰退。在深度研究任务中达到最先进性能，保持决策可追溯性。

---

### 10 HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations

**link**: https://arxiv.org/pdf/2511.18808.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: HyperbolicRAG将双曲几何集成到图增强RAG中，通过深度感知表示学习器、对比正则化和互排序融合机制，同时捕捉语义相似性和层次结构。在多QA基准上优于标准RAG和图增强基线。

---

### 11 Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation

**link**: https://arxiv.org/pdf/2511.17813.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 本研究将公共录音转换为带元数据的说话人属性转录本，用于微调LLM建模特定参与者。困惑度降低67%，图灵测试显示模拟与真实商议难以区分，为公民模拟提供可扩展方法。

---

### 12 A superpersuasive autonomous policy debating system

**link**: https://arxiv.org/pdf/2511.17854.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: DeepDebater采用分层多智能体工作流，利用政策辩论证据库生成演讲、交叉询问和反驳。在模拟辩论中一致击败人类撰写案例，支持完全自主或混合人机操作模式。

---

### 13 Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction

**link**: https://arxiv.org/pdf/2511.17908.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 通过conformal prediction进行上下文工程，在保留指定比例相关片段的同时，将上下文减少2-3倍。该方法满足覆盖率目标，在严格过滤下提高事实准确性，为RAG提供模型无关的可靠压缩。

---

### 14 AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention

**link**: https://arxiv.org/pdf/2511.18960.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: AVA-VLA框架从POMDP角度建模，利用主动视觉注意力动态处理任务相关视觉令牌。在LIBERO和CALVIN基准上实现最先进性能，验证了仿真到现实的迁移能力。

---

### 15 MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings

**link**: https://arxiv.org/pdf/2511.19279.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: MapFormer通过输入相关位置编码学习认知地图，将结构关系与内容解耦。在导航任务中实现近乎完美的分布外泛化（如更长序列），优于现有架构。

---

### 16 Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search

**link**: https://arxiv.org/pdf/2511.18313.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 路径约束检索（PCR）将图谱约束与语义搜索结合，限制搜索空间到可达节点。在PathRAG-6基准上实现100%结构一致性（基线为24-32%），平均图谱距离减少78%。

---

### 17 Equivalence of Context and Parameter Updates in Modern Transformer Blocks

**link**: https://arxiv.org/pdf/2511.17864.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: 本研究证明上下文影响可映射为MLP权重的rank-1补丁，适用于Gemma风格及现代LLM架构（包括门控和混合专家）。框架统一了输入/输出可控性属性，简化了transformer权重更新理解。

---

### 18 Mitigating Catastrophic Forgetting in Streaming Generative and Predictive Learning via Stateful Replay

**link**: https://arxiv.org/pdf/2511.17936.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: 状态重放作为流式学习基线，在异构多任务流上将平均遗忘减少2-3倍。梯度对齐分析表明，混合当前和历史样本可有效减少灾难性遗忘，适用于自编码、预测和分类任务。

---

### 19 Controllability Analysis of State Space-based Language Model

**link**: https://arxiv.org/pdf/2511.17970.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: 通过影响分数（基于可控性的度量）分析Mamba模型，揭示模型大小增加时影响分数上升、近期偏差和中后层集中影响等模式。该分数作为解释SSM语言模型的诊断工具。

---

### 20 An Adaptive Resonance Theory-based Topological Clustering Algorithm with a Self-Adjusting Vigilance Parameter

**link**: https://arxiv.org/pdf/2511.17983.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: 基于ART的算法通过多样性驱动机制自主调整警觉阈值，实现无超参数学习。在24个数据集上优于最先进方法，有效减轻灾难性遗忘并维持演化数据流中的聚类一致性。

---

### 21 LLM-Driven Stationarity-Aware Expert Demonstrations for Multi-Agent Reinforcement Learning in Mobile Systems

**link**: https://arxiv.org/pdf/2511.19368.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: RELED框架整合LLM驱动的专家演示与平稳性感知模块，利用理论非平稳性边界提高样本质量。在移动系统实验中优于现有MARL方法，支持策略收敛和泛化。

---

### 22 Learning Robust Social Strategies with Large Language Models

**link**: https://arxiv.org/pdf/2511.19405.pdf  
**date**: 2025-11-26  
**keywords**: cs.LG  
**abs**: 采用Advantage Alignment算法微调LLMs，实现多智能体合作和抗剥削性。在社交困境中实现更高集体收益，群体相对基线简化优势计算，新环境Trust and Split支持自然语言交流。

---

### 23 Concept than Document: Context Compression via AMR-based Conceptual Entropy

**link**: https://arxiv.org/pdf/2511.18832.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 通过AMR图节点级熵量化概念重要性，保留核心语义并过滤无关文本。在PopQA和EntityQuestions上减少上下文长度同时提高准确性，证明语言特征在上下文工程中的潜力。

---

### 24 Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models

**link**: https://arxiv.org/pdf/2511.18177.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 系统评估基于向量（混合搜索+元数据过滤）和分层节点RAG在金融文档上的表现。交叉编码器重排序使MRR@5提升59%，从小到大检索比基线分块胜率高65%，揭示成本-性能权衡。

---

### 25 Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems

**link**: https://arxiv.org/pdf/2511.18194.pdf  
**date**: 2025-11-26  
**keywords**: cs.CL  
**abs**: 将工具和智能体表示为知识图谱节点，通过加权RRF重排序和图遍历优化检索。在LiveMCPBenchmark上Recall@5和nDCG@5分别提升14.9%和14.6%，支持细粒度工具能力匹配。
### Geometric Priors for Generalizable World Models via Vector Symbolic Architecture

**link**: https://arxiv.org/pdf/2602.21467.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 本文提出一种基于向量符号架构（VSA）的可泛化世界模型，通过可学习的傅里叶全息约简表示（FHRR）编码器，将状态和动作映射到高维复向量空间，利用元素级复乘法建模转换。模型在离散网格世界环境中实现高零样本准确率（87.5%）和噪声鲁棒性（4倍提升），证明其能有效支持多步组合推理和泛化性能，为现实世界规划提供结构化途径。

---

### Latent Context Compilation: Distilling Long Context into Compact Portable Memory

**link**: https://arxiv.org/pdf/2602.21221.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 针对长上下文大语言模型部署效率问题，本文提出Latent Context Compilation框架，使用一次性LoRA模块将长上下文提炼为紧凑缓冲令牌。通过自对齐优化策略，无需合成问答对，实现16倍压缩比下的细粒度细节保留，解耦内存密度与模型参数，提升推理效率。

---

### Shared Nature, Unique Nurture: PRISM for Pluralistic Reasoning via In-context Structure Modeling

**link**: https://arxiv.org/pdf/2602.21317.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 为解决大型语言模型分布多样性坍缩问题，本文提出PRISM框架，通过动态即时认知图增强模型推理能力。在创造力基准和罕见病诊断任务中，PRISM显著提升新颖性和多样性，实现多元AI范式从单一共识转向多视角探索。

---

### HiPPO Zoo: Explicit Memory Mechanisms for Interpretable State Space Models

**link**: https://arxiv.org/pdf/2602.21340.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 本研究扩展HiPPO框架，引入“HiPPO zoo”统一框架，通过五项显式多项式内存结构增强状态空间模型（SSMs）。支持内存自适应分配和关联内存，在合成序列建模任务中验证其可解释性和高效更新能力，为流式设置提供鲁棒解决方案。

---

### Interleaved Head Attention

**link**: https://arxiv.org/pdf/2602.21371.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 针对多头注意力（MHA）的头间通信限制，本文提出交错头注意力（IHA），通过伪头线性组合实现头间混合，诱导多注意力模式。在RULER和OpenThoughts基准上，IHA提升多键检索准确率10-20%，推理任务性能提升5.8%，参数效率优于传统MHA。

---

### Breaking Semantic-Aware Watermarks via LLM-Guided Coherence-Preserving Semantic Injection

**link**: https://arxiv.org/pdf/2602.21593.pdf  
**date**: 2026-02-26  
**keywords**: latent space, latent reasoning  
**abs**: 本文揭示语义水印在LLM驱动语义扰动下的漏洞，提出一致性保持语义注入（CSI）攻击。利用LLM引导语义操纵，干扰水印相关语义，导致检测器错误。实证显示CSI优于主流攻击基线，暴露当前水印设计的安全弱点。

---

### NGDB-Zoo: Towards Efficient and Scalable Neural Graph Databases Training

**link**: https://arxiv.org/pdf/2602.21597.pdf  
**date**: 2026-02-26  
**keywords**: latent space, latent reasoning  
**abs**: 针对神经图数据库（NGDBs）训练效率瓶颈，本文提出NGDB-Zoo框架，通过操作符级训练与语义增强协同，实现多流并行。在ogbl-wikikg2等基准上，吞吐量提升1.8-6.8倍，并整合预训练文本编码器减轻混合推理表示摩擦。

---

### Deep Clustering based Boundary-Decoder Net for Inter and Intra Layer Stress Prediction

**link**: https://arxiv.org/pdf/2602.21601.pdf  
**date**: 2026-02-26  
**keywords**: latent space  
**abs**: 本文结合边界解码器网络与深度聚类，研究3D异质集成电路封装应力预测。在IC芯片数据集上，该方法优于基线，训练和测试误差显著减少，提供高效维度不适定问题解决方案。

---

### Overconfident Errors Need Stronger Correction: Asymmetric Confidence Penalties for Reinforcement Learning

**link**: https://arxiv.org/pdf/2602.21420.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 针对强化学习与可验证奖励（RLVR）中的过度自信错误，本文提出非对称置信感知错误惩罚（ACE），通过置信偏移度量动态调节负优势。在Qwen2.5-Math-7B等模型上，ACE提升MATH-500和AIME 2025基准的全Pass@k谱性能。

---

### On the Structural Non-Preservation of Epistemic Behaviour under Policy Transformation

**link**: https://arxiv.org/pdf/2602.21424.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 本文形式化部分可观测环境下强化学习的行为依赖概念，建立行为距离在凸组合下收缩的理论。实验表明行为距离在策略转换中减小，揭示探针条件行为分离的结构条件，为智能体内部信息优化提供依据。

---

### Causal Decoding for Hallucination-Resistant Multimodal Large Language Models

**link**: https://arxiv.org/pdf/2602.21441.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 针对多模态大语言模型对象幻觉，本文提出安全过滤框架，通过控制障碍函数（CBFs）合成反馈控制输入。在约束图像生成等任务中，实现100%约束满足和语义保真度，无需重训练或架构修改。

---

### AgentLTV: An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction

**link**: https://arxiv.org/pdf/2602.21634.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 本文提出AgentLTV框架，利用LLM驱动智能体自动化LTV建模。通过蒙特卡洛树搜索和进化算法优化pipeline，在专有数据集和公共基准上提升排名和误差指标，尤其改善高价值和负LTV细分市场校准。

---

### TiMi: Empower Time Series Transformers with Multimodal Mixture of Experts

**link**: https://arxiv.org/pdf/2602.21693.pdf  
**date**: 2026-02-26  
**keywords**: cs.LG  
**abs**: 针对多模态时间序列预测，本文提出TiMi框架，整合LLM生成推理和MMoE模块。在16个基准上实现SOTA性能，提升预测准确性，同时具备强适应性和可解释性，释放LLM潜在推理能力。

---

### Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models

**link**: https://arxiv.org/pdf/2602.21262.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 通过多轮推箱子游戏研究LLMs说服能力和理性警惕性，发现解谜性能、说服能力和警惕性可分离。LLMs在恶意建议时使用更多token，但仍易被诱导失败，为AI安全提供关键启示。

---

### MrBERT: Modern Multilingual Encoders via Vocabulary, Domain, and Dimensional Adaptation

**link**: https://arxiv.org/pdf/2602.21379.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 本文介绍MrBERT编码器系列，基于ModernBERT架构在35种语言上预训练。通过词汇、领域和维度适应，在加泰罗尼亚语和西班牙语任务上实现SOTA，同时整合Matryoshka表示学习降低推理成本。

---

### Distill and Align Decomposition for Enhanced Claim Verification

**link**: https://arxiv.org/pdf/2602.21857.pdf  
**date**: 2026-02-26  
**keywords**: cs.AI  
**abs**: 针对复杂声明验证，本文提出强化学习方法，通过组相对策略优化（GRPO）联合优化分解质量和验证器对齐。在六种设置中，8B分解器提升下游验证性能至71.75% macro-F1，优于现有方法。

---

### Probing the Geometry of Diffusion Models with the String Method

**link**: https://arxiv.org/pdf/2602.22122.pdf  
**date**: 2026-02-26  
**keywords**: stat.ML  
**abs**: 本文引入基于字符串方法的框架，探索扩散模型几何结构。通过计算最小能量路径和主曲线，揭示图像扩散模型中似然最大值不真实，蛋白质结构预测中生成物理合理路径，为模态结构提供原则性工具。

---

### Dynamic Personality Adaptation in Large Language Models via State Machines

**link**: https://arxiv.org/pdf/2602.22157.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 针对LLMs人格表达调整问题，提出动态人格模拟框架，利用状态机表示潜在人格状态。通过模块化管道评分人格维度，动态重配置系统提示，提升复杂交互环境表现。

---

### EPSVec: Efficient and Private Synthetic Data Generation via Dataset Vectors

**link**: https://arxiv.org/pdf/2602.21218.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 本文提出EPSVec，一种差分私有合成数据生成方法，通过数据集向量引导LLM生成。仅需一次提取引导向量，实现高保真度合成，在低数据场景下优于基线，降低计算开销。

---

### Reasoning-Based Personalized Generation for Users with Sparse Data

**link**: https://arxiv.org/pdf/2602.21219.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 针对稀疏数据用户个性化生成，提出GraSPer框架，通过预测未来交互项目并推理对齐生成文本。在三个基准上显著提升性能，改善冷启动用户个性化。

---

### Field-Theoretic Memory for AI Agents: Continuous Dynamics for Context Preservation

**link**: https://arxiv.org/pdf/2602.21220.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 本文提出基于场论的AI代理记忆系统，将信息视为连续场。在LoCoMo和LongMemEval基准上，多会话推理F1提升116%，时间推理提升43.8%，多代理场景集体智能达99.8%。

---

### Task-Aware LoRA Adapter Composition via Similarity Retrieval in Vector Databases

**link**: https://arxiv.org/pdf/2602.21222.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 针对LoRA适配器跨任务组合，提出基于向量数据库相似性检索的动态框架。通过嵌入训练示例，推理时加权融合适配器，在PIQA和RTE任务上优于单任务基线，实现高效可解释组合。

---

### ExpLang: Improved Exploration and Exploitation in LLM Reasoning with On-Policy Thinking Language Selection

**link**: https://arxiv.org/pdf/2602.21887.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 本文提出ExpLang框架，通过策略内思维语言选择增强LLM推理。在相同训练预算下，稳定优于仅英语训练，提升探索空间利用，对已见和未见语言均保持高一致性。

---

### RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning

**link**: https://arxiv.org/pdf/2602.21951.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 针对知识图谱推理，提出RADAR框架，将生成式模式匹配重构为判别式关系推理。在四个基准上，链接预测和三元组分类性能相对提升5-6%，中间表示任务相关互信息增加62.9%。

---

### Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models

**link**: https://arxiv.org/pdf/2602.22072.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 通过扰动错误信念任务研究LLMs心理理论（ToM）能力，发现任务扰动下ToM稳健性显著下降。思维链提示能提升性能但对某些扰动意外降低准确率，质疑LLMs存在稳健ToM。

---

### ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices

**link**: https://arxiv.org/pdf/2602.21858.pdf  
**date**: 2026-02-26  
**keywords**: cs.AI  
**abs**: 本文提出ProactiveMobile基准，形式化主动任务为意图推断和函数序列生成。包含14个场景3660+实例，微调Qwen2.5-VL-7B-Instruct成功率19.15%，证实主动性为可学习关键能力。

---

### DySCO: Dynamic Attention-Scaling Decoding for Long-Context LMs

**link**: https://arxiv.org/pdf/2602.22175.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL, LLM Memory, latent reasoning  
**abs**: 针对长上下文推理，提出DySCO解码算法，利用检索头动态调整注意力。在128K上下文长度下，MRCR和LongBenchV2基准性能提升高达25%，提供可解释注意力行为见解。

---

### Improving Parametric Knowledge Access in Reasoning Language Models

**link**: https://arxiv.org/pdf/2602.22193.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL, latent reasoning  
**abs**: 本研究优化推理语言模型参数知识访问机制，通过世界知识问答奖励训练模型。在TriviaQA上性能提升9.9%，Natural Questions等基准提升0.6-4.2%，证明训练可显著增强推理能力。

---

### Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem

**link**: https://arxiv.org/pdf/2602.21814.pdf  
**date**: 2026-02-26  
**keywords**: cs.AI, latent reasoning  
**abs**: 通过洗车问题变量隔离实验，发现STAR推理框架单独使用将准确率从0%提升至85%。结构化推理支架对隐式约束任务的重要性远超上下文注入，全栈条件下实现100%准确率。

---

### DWA-KD: Dual-Space Weighting and Time-Warped Alignment for Cross-Tokenizer Knowledge Distillation

**link**: https://arxiv.org/pdf/2602.21669.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 针对跨tokenizer知识蒸馏，提出DWA-KD框架，通过双空间熵加权和Soft-DTW实现精确序列对齐。实验显示优于现有KD基线，提升token级和序列级蒸馏效果。

---

### Explore-on-Graph: Incentivizing Autonomous Exploration of Large Language Models on Knowledge Graphs with Path-refined Reward Modeling

**link**: https://arxiv.org/pdf/2602.21728.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 提出Explore-on-Graph框架，通过强化学习训练LLMs在知识图谱上自主探索。利用路径信息奖励优化推理空间，在五个KGQA基准上实现SOTA性能，优于开源和闭源LLMs。

---

### D-COT: Disciplined Chain-of-Thought Learning for Efficient Reasoning in Small Language Models

**link**: https://arxiv.org/pdf/2602.21786.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 针对小语言模型CoT蒸馏“过度思考”问题，提出D-CoT框架，使用控制标签优化轨迹。在Qwen3-8B上，GPQA-diamond准确率提升9.9%，推理时减少token消耗并保持高性能。

---

### Personalized Graph-Empowered Large Language Model for Proactive Information Access

**link**: https://arxiv.org/pdf/2602.21862.pdf  
**date**: 2026-02-26  
**keywords**: cs.CL  
**abs**: 本文提出利用LLMs进行主动信息访问的框架，整合个人知识图谱增强需求检测。实验证明有效识别遗忘事件，帮助用户高效回忆过去经历，解决个人日志数据稀缺问题。
### 1 IceBench-S2S: A Benchmark of Deep Learning for Challenging Subseasonal-to-Seasonal Daily Arctic Sea Ice Forecasting in Deep Latent Space
**link**: https://arxiv.org/pdf/2602.02567.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 北极海冰对地球气候系统至关重要，但深度学习模型预测时效有限，阻碍实际应用。IceBench-S2S 是首个全面基准，用于评估深度学习方法在连续180天北极海冰浓度预测中的性能。它通过空间特征压缩到深度潜在空间和时间建模，提供统一训练评估管道，提升极地环境监测的模型选择能力。
---

### 2 Mitigating Task-Order Sensitivity and Forgetting via Hierarchical Second-Order Consolidation
**link**: https://arxiv.org/pdf/2602.02568.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入基于分层泰勒级数的持续学习框架（HTCL），结合快速局部适应和保守二阶全局巩固，解决任务顺序效应。通过海森矩阵正则化整合局部更新，实现多尺度知识整合。在广泛数据集上，HTCL 提升准确率7%至25%，降低随机任务排列方差达68%。
---

### 3 How Much Information Can a Vision Token Hold? A Scaling Law for Recognition Limits in VLMs
**link**: https://arxiv.org/pdf/2602.02539.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 研究视觉令牌的信息上限，通过增加图像信息量进行压力测试，观察到相变现象（稳定、不稳定、崩溃阶段）。分析机制起源并制定概率缩放定律，统一平均视觉令牌负载和视觉密度。实验证明该定律在视觉语言模型上的普适性，为视觉上下文压缩提供效率-精度权衡指导。
---

### 4 Learning ORDER-Aware Multimodal Representations for Composite Materials Design
**link**: https://arxiv.org/pdf/2602.02513.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 复合材料设计缺乏明确图结构，通用描述符无法捕捉微观特征。引入ORDER框架，通过多模态学习整合异构数据，将序数性作为核心原则，确保相似目标属性在潜在空间邻近。在纳米纤维增强复合材料数据集上，ORDER在属性预测、跨模态检索和微观结构生成任务上优于基线。
---

### 5 GraphDancer: Training LLMs to Explore and Reason over Graphs via Curriculum Reinforcement Learning
**link**: https://arxiv.org/pdf/2602.02518.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 大型语言模型（LLMs）需导航异构图进行多跳推理。GraphDancer 通过强化学习框架教LLMs导航图，引入图感知课程按结构复杂性安排训练。在未见域测试中，仅用3B基础模型优于14B或GPT-4o-mini基线，展示图探索和推理技能的跨域泛化能力。
---

### 6 The "Robert Boulton" Singularity: Semantic Tunneling and Manifold Unfolding in Recursive AI
**link**: https://arxiv.org/pdf/2602.02526.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 在递归合成数据上训练的生成式AI稳定性通过困惑度监控，但识别新失效模式“语义隧道效应”：模型维持语法流畅性却丢失语义多样性，收敛到单一叙事吸引子。代表潜在流形完全崩溃，应用多尺度负耦合信息系统框架解决。
---

### 7 Fubini Study geometry of representation drift in high dimensional data
**link**: https://arxiv.org/pdf/2602.02596.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入基于富比尼-施图迪度量的表示漂移射影几何视角，识别仅因规范变换不同的表示。构建表示轨迹并通过累积几何漂移跟踪演化，发现传统度量高估变化，而富比尼-施图迪度量分离内在演化。提供评估高维系统表示稳定性的几何标准。
---

### 8 ContextEvolve: Multi-Agent Context Compression for Systems Code Optimization
**link**: https://arxiv.org/pdf/2602.02597.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入ContextEvolve多智能体框架，将优化上下文分解为摘要、导航和采样三个正交维度。摘要智能体压缩语义状态，导航智能体提取优化方向，采样智能体管理经验分布。在ADRS基准中，性能提升33.3%，令牌消耗减少29.0%，实现高效系统代码优化。
---

### 9 RAP: KV-Cache Compression via RoPE-Aligned Pruning
**link**: https://arxiv.org/pdf/2602.02599.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 大型语言模型的长上下文推理受KV-Cache内存瓶颈限制。RAP通过剪枝RoPE对齐的列对保留旋转结构，恢复吸收并消除重构。在LLaMA-3-8B和Mistral-7B上，RAP将KV-Cache、注意力参数和FLOPs减少20-30%，保持高准确性，注意力延迟降至基线83%（预填充）和77%（解码）。
---

### 10 Towards Understanding Steering Strength
**link**: https://arxiv.org/pdf/2602.02712.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 探讨LLMs训练后控制的引导方法，分析引导强度对下一个token概率、概念存在性和交叉熵的影响。推导定性规律，揭示非单调效应等行为，在11个语言模型上实证验证引导强度的关键作用。
---

### 11 Vector Quantized Latent Concepts: A Scalable Alternative to Clustering-Based Concept Discovery
**link**: https://arxiv.org/pdf/2602.02726.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出向量量化潜在概念方法（VQLC），基于VQ-VAE架构学习映射离散码本的概念向量。评估表明VQLC在提高可扩展性的同时保持可比较的人类可理解解释质量，为模型解释提供高效框架。
---

### 12 SPA-Cache: Singular Proxies for Adaptive Caching in Diffusion Language Models
**link**: https://arxiv.org/pdf/2602.02544.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 扩散语言模型（DLMs）非因果特性排除标准KV缓存，导致昂贵隐藏状态重计算。SPA-Cache联合优化更新识别和预算分配，通过低维奇异代理识别更新关键令牌，引入自适应策略为稳定层分配更少更新。吞吐量提升高达8倍，比基线快2-4倍。
---

### 13 Beyond Alignment: Expanding Reasoning Capacity via Manifold-Reshaping Policy Optimization
**link**: https://arxiv.org/pdf/2602.02545.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 质疑强化学习是否扩展推理能力，提出流形重塑策略优化（MRPO）框架重构推理空间。分阶段运行：谱正交探索将策略初始化驱逐到偏差流形零空间；有效秩正则化激励高维推理轨迹。4B参数方法在数学任务上达到最先进性能，扩展能力边界。
---

### 14 Learning to Explore with Parameter-Space Noise: A Deep Dive into Parameter-Space Noise for Reinforcement Learning with Verifiable Rewards
**link**: https://arxiv.org/pdf/2602.02555.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 基于可验证奖励的强化学习（RLVR）改进LLM推理，但存在探索天花板。PSN-RLVR扰动策略参数诱导轨迹级探索，缓解采样-更新不匹配。通过实时自适应噪声调度器，PSN-GRPO扩展推理能力边界，在大采样预算下实现更高pass-at-k。
---

### 15 Beyond Experience Retrieval: Learning to Generate Utility-Optimized Structured Experience for Frozen LLMs
**link**: https://arxiv.org/pdf/2602.02556.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入SEAM（结构化经验适配器模块），轻量级插件将经验存储参数中，生成结构化经验条目指导冻结LLM。通过执行器rollouts和GRPO效用训练，SEAM在数学推理基准上提升精度，低开销跨执行器有效。
---

### 16 Discovering Data Manifold Geometry via Non-Contracting Flows
**link**: https://arxiv.org/pdf/2602.02611.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出无监督方法，通过非收缩流学习环境空间中跨越未知数据流形切空间的向量场。构建全局参考系统，流弧长定义内在坐标。实施非收缩约束并推导可扩展目标，理论上证明恢复全局坐标图。
---

### 17 FlexRank: Nested Low-Rank Knowledge Decomposition for Adaptive Model Deployment
**link**: https://arxiv.org/pdf/2602.02680.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出FlexRank方法，利用低秩权重分解与基于重要性嵌套整合，从预训练模型提取能力递增子模型。实现“一次训练，随处部署”，在成本与性能间实现平滑权衡，推进大型模型实际部署。
---

### 18 TopoPrune: Robust Data Pruning via Unified Latent Space Topology
**link**: https://arxiv.org/pdf/2602.02739.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: TopoPrune框架利用拓扑学捕捉数据稳定结构，在两个尺度运行：全局低维嵌入和局部拓扑优化。实验显示高准确率和精确率，对特征嵌入噪声扰动异常稳健，在不同网络架构间迁移优异。
---

### 19 Provable Effects of Data Replay in Continual Learning: A Feature Learning Perspective
**link**: https://arxiv.org/pdf/2602.02767.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 分析持续学习全数据重放训练，采用多视图数据模型，信噪比（SNR）为影响遗忘关键因素。验证结论：后续任务累积噪声主导时遗忘发生；足够信号积累可恢复早期任务。优先处理高信号任务有助于防止灾难性遗忘。
---

### 20 Manifold-Constrained Energy-Based Transition Models for Offline Reinforcement Learning
**link**: https://arxiv.org/pdf/2602.02900.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出流形约束能量基转移模型（MC-ETM），使用流形投影-扩散负采样器训练条件能量基模型。学习下一状态潜在流形，生成近流形难负样本锐化能量景观。在策略优化中，能量提供可靠性信号，截断轨迹并稳定贝尔曼备份。
---

### 21 Causality--Δ: Jacobian-Based Dependency Analysis in Flow Matching Models
**link**: https://arxiv.org/pdf/2602.02793.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 研究流匹配中潜在扰动传播，雅可比向量积（JVPs）为依赖结构提供视角。推导高斯和高斯混合设置闭式表达式，揭示局部仿射结构。数值JVPs恢复解析雅可比，在图像领域恢复经验相关性。
---

### 22 Membership Inference Attacks from Causal Principles
**link**: https://arxiv.org/pdf/2602.02819.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 将成员推理攻击评估构建为因果推理问题，记忆定义为数据点包含在训练集中的因果效应。形式化现有协议偏差来源，推导标准MIA指标因果类似物，提出多运行、单运行和零运行场景估计器。实验实现可靠记忆测量。
---

### 23 A Single Revision Step Improves Token-Efficient LLM Reasoning
**link**: https://arxiv.org/pdf/2602.02828.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 大型语言模型通过多轨迹采样提高准确性，但标准聚合方法存在“盲点”。让轨迹进行“同行评审”解决近失误差，利用成对比较信号改进推理效率。
---

### 24 FedKRSO: Communication and Memory Efficient Federated Fine-Tuning of Large Language Models
**link**: https://arxiv.org/pdf/2602.03019.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出FedKRSO方法，客户端在共享随机低维子空间更新模型，仅发送子空间更新累积器。减少通信和内存开销，克服参数高效微调性能损失，接近联邦全参数微调性能。
---

### 25 Refining Decision Boundaries In Anomaly Detection Using Similarity Search Within the Feature Space
**link**: https://arxiv.org/pdf/2602.02925.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出SDA2E稀疏双对抗注意力自编码器，学习紧凑判别潜在表示。相似性引导主动学习框架整合类正常扩展、类异常优先和混合策略优化决策边界。在52个不平衡数据集上评估，减少80%标记数据需求。
---

### 26 Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization
**link**: https://arxiv.org/pdf/2602.02958.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 自回归视频扩散模型面临KV缓存内存瓶颈。Quant VideoGen通过语义感知平滑利用时空冗余，生成低幅度残差；引入渐进式残差量化减少误差。在LongCat Video等基准上，KV缓存内存减少7.0倍，端到端延迟低于4%。
---

### 27 Koopman Autoencoders with Continuous-Time Latent Dynamics for Fluid Dynamics Forecasting
**link**: https://arxiv.org/pdf/2602.02832.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入连续时间Koopman框架，通过数值积分方案模拟潜在演化。允许可变时间步长，展示时间分辨率鲁棒性，并能泛化训练制度外。学习动力学紧密遵循解析矩阵指数解，实现高效长期预测。
---

### 28 Tabula RASA: Exposing and Breaking the Relational Bottleneck in Transformers
**link**: https://arxiv.org/pdf/2602.02834.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入RASA（Relation-Aware Sparse Attention），最小化修改包括边缘类型嵌入和稀疏掩码。RASA使用全注意力层作为精确“oracle”识别重要标记，使稀疏层重用全注意力KV缓存。在7B和80B模型上评估，持续优于全注意力和混合基线。
---

### 29 Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains
**link**: https://arxiv.org/pdf/2602.02841.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出GeLDA语义感知生成式潜在数据增强框架，利用条件扩散模型在基础模型诱导潜在空间中合成样本。以辅助特征向量为条件，促进低资源领域数据增强。在语音情感识别和图像分类任务中验证，提升性能。
---

### 30 Merging Beyond: Streaming LLM Updates via Activation-Guided Rotations
**link**: https://arxiv.org/pdf/2602.03237.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出Streaming Merging模型更新范式，核心策略ARM通过激活子空间导出旋转向量，引导参数沿数据驱动轨迹更新。实验表明，迭代合并超越完全收敛监督微调模型，在1.7B至14B规模上优势明显。
---

### 31 DynSplit-KV: Dynamic Semantic Splitting for KVCache Compression in Efficient Long-Context LLM Inference
**link**: https://arxiv.org/pdf/2602.03184.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出DynSplit-KV动态识别分割边界方法：动态重要性感知边界选择策略提高精度；统一映射策略将变长语义块转换为固定长度格式。实验显示KV缓存内存减少2.6倍，端到端延迟降低。
---

### 32 Reinforcement Learning with Promising Tokens for Large Language Models
**link**: https://arxiv.org/pdf/2602.03195.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出强化学习与有前途令牌框架（RLPT），解耦策略决策与令牌生成。利用基础模型语义先验识别动态令牌集，通过掩码限制策略优化。理论分析和实验表明降低梯度方差，稳定训练，在数学、编码任务上优于标准RL基线。
---

### 33 MeKi: Memory-based Expert Knowledge Injection for Efficient LLM Scaling
**link**: https://arxiv.org/pdf/2602.03359.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出MeKi系统，通过存储空间扩展LLM容量。为每个Transformer层配备令牌级内存专家，注入预存储语义知识。采用重参数化策略折叠参数矩阵为紧凑查找表，知识卸载到ROM实现零推理延迟开销。实验显著优于密集型LLM基线。
---

### 34 Chain-of-Goals Hierarchical Policy for Long-Horizon Offline Goal-Conditioned RL
**link**: https://arxiv.org/pdf/2602.03389.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出目标链分层策略（CoGHP），将分层决策重构为自回归序列建模。采用MLP-Mixer骨干网络支持跨token通信，捕捉状态、目标、潜在子目标与动作关系。在导航和操作基准上，CoGHP持续优于离线基线，提升长视界任务性能。
---

### 35 Evaluating LLMs When They Do Not Know the Answer: Statistical Evaluation of Mathematical Reasoning via Comparative Signals
**link**: https://arxiv.org/pdf/2602.03061.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 设计统计高效评估框架，结合标准标记结果和成对比较信号。将比较信号视为控制变量，开发半参数估计器用于辅助推理链场景。模拟实验提高排名准确性，在GPQA Diamond等数据集上证明更精确性能估计。
---

### 36 Shortcut Features as Top Eigenfunctions of NTK: A Linear Neural Network Case and More
**link**: https://arxiv.org/pdf/2602.03066.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 分析线性神经网络情况，推导捷径学习性质。基于神经正切核框架，发现当捷径源于聚类分布不平衡时，捷径特征对应大特征值特征。控制神经网络输出间隔，偏好仍存在，表明最大间隔偏差非唯一原因。
---

### 37 Geometry-Preserving Neural Architectures on Manifolds with Boundary
**link**: https://arxiv.org/pdf/2602.03082.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出统一几何感知架构，在层间交错几何更新，投影层和内在指数映射更新是流形上投影动力系统离散化结果。建立约束神经ODE通用逼近结果，分析仅输出端强制执行几何结构架构。
---

### 38 TextME: Bridging Unseen Modalities Through Text Descriptions
**link**: https://arxiv.org/pdf/2602.03098.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入TextME纯文本模态扩展框架，将不同模态投影到LLM嵌入空间作为统一锚点。利用预训练对比编码器几何结构，仅用文本描述实现零样本跨模态迁移。实验验证模态差距一致性，纯文本训练保留预训练编码器性能。
---

### 39 Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery
**link**: https://arxiv.org/pdf/2602.03132.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出对比概念树搜索（CCTS），从生成程序提取层次化概念表示，学习对比概念模型指导父节点选择。通过似然比分数加权父节点，偏向有用概念组合。在Erdős型组合数学问题基准上，CCTS提高搜索效率，生成可解释概念树。
---

### 40 Self-Hinting Language Models Enhance Reinforcement Learning
**link**: https://arxiv.org/pdf/2602.03143.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出带特权监督的自提示对齐GRPO（SAGE），在策略强化学习框架注入特权提示。采样多样化自提示作为自适应课程，比固定提示有效。在6个基准测试上，SAGE持续优于GRPO，平均在Llama-3.2-3B上+2.0。
---

### 41 MemCast: Memory-Driven Time Series Forecasting with Experience-Conditioned Reasoning
**link**: https://arxiv.org/pdf/2602.03164.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出MemCast学习记忆框架，将时间序列预测重构为经验条件推理任务。学习经验组织为层次化记忆：历史模式、推理智慧和一般规律。设计动态置信度适应策略更新条目置信度。在多个数据集上实验，MemCast持续优于先前方法。
---

### 42 Not All Negative Samples Are Equal: LLMs Learn Better from Plausible Reasoning
**link**: https://arxiv.org/pdf/2602.03516.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出合理负面样本方法（PNS），合成具有预期格式和结构连贯性但最终答案错误的高质量负面样本。通过反向强化学习训练专用模型，结合复合奖励。在数学推理基准上，PNS持续优于其他负面样本合成方法。
---

### 43 Robust Representation Learning in Masked Autoencoders
**link**: https://arxiv.org/pdf/2602.03531.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 研究掩码自编码器内部表示，发现学习表示在模糊和遮挡下保持良好分类性能。通过令牌嵌入分层分析，预训练MAE通过网络深度逐步构建类感知潜在空间。引入敏感性指标量化特征鲁棒性。
---

### 44 Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts
**link**: https://arxiv.org/pdf/2602.03473.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出CaRE可扩展持续学习器，核心是高效双层路由混合专家机制。双层路由机制动态激活任务特定路由器和专家路由，注入判别性和全面性表示。在超长任务序列上评估，CaRE显著优于基线，扩展到300+任务。
---

### 45 Lookahead Path Likelihood Optimization for Diffusion LLMs
**link**: https://arxiv.org/pdf/2602.03496.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 引入路径对数似然轨迹条件目标，支持解掩码路径选择。提出POKE高效价值估计器预测预期路径对数似然，集成到序贯蒙特卡洛搜索框架动态识别最优路径。在6个推理任务上，POKE-SMC提高准确性，推进准确性-计算帕累托前沿。
---

### 46 Riemannian Neural Optimal Transport
**link**: https://arxiv.org/pdf/2602.03566.pdf
**date**: 2026-02-04
**keywords**: latent space
**abs**: 引入黎曼神经OT映射，连续神经网络参数化避免离散化并整合几何结构。证明RNOT映射以维度子指数复杂度逼近黎曼OT映射。实验表明，相对于离散化基线，RNOT具有更高可扩展性和竞争力。
---

### 47 Asymmetric Hierarchical Anchoring for Audio-Visual Joint Representation: Resolving Information Allocation Ambiguity for Robust Cross-Modal Generalization
**link**: https://arxiv.org/pdf/2602.03570.pdf
**date**: 2026-02-04
**keywords**: latent space
**abs**: 提出非对称层次锚定框架，指定结构化语义锚点强制定向信息分配。利用音频残差向量量化诱导层次化表示，引导视频特征蒸馏到共享语义空间。用对抗解耦器抑制语义泄漏，引入局部滑动对齐促进跨模态时间对齐。在AVE和AVVP基准上优于对称基线。
---

### 48 APEX: Probing Neural Networks via Activation Perturbation
**link**: https://arxiv.org/pdf/2602.03586.pdf
**date**: 2026-02-04
**keywords**: latent space
**abs**: 引入激活扰动探索范式，扰动隐藏层激活。理论上证明激活扰动抑制输入特定信号并放大表示级结构。案例研究展示APEX优势：小噪声提供轻量级样本正则性度量；大噪声暴露训练诱导模型级偏差。
---

### 49 CTTVAE: Latent Space Structuring for Conditional Tabular Data Generation on Imbalanced Datasets
**link**: https://arxiv.org/pdf/2602.03641.pdf
**date**: 2026-02-04
**keywords**: cs.LG
**abs**: 提出CTTVAE基于条件Transformer表格变分自编码器，配备类感知三元组损失和采样训练策略。CTTVAE+TBS框架生成更具代表性和效用对齐样本。在六个基准上，CTTVAE+TBS在少数类上实现最强下游效用，保持竞争力保真度。
---
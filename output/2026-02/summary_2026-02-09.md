### 1 Rethinking Memory Mechanisms of Foundation Agents in the Second Half

**link**: https://arxiv.org/pdf/2602.06052.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL  
**abs**: 人工智能研究正从模型创新转向强调问题定义和实际评估。在"后半程"，智能体在长周期、动态和用户依赖环境中面临上下文爆炸，需持续积累、管理和选择性重用大量信息。记忆成为填补效用差距的关键解决方案。本文从三个维度提供基础智能体记忆的统一视角：记忆 substrate（内部和外部）、认知机制（情景、语义、感官、工作和程序记忆）和记忆主体（智能体和用户中心）。分析了不同智能体拓扑结构下记忆的实例化和操作，强调记忆操作的学习策略，并回顾了评估记忆效用的基准和指标，概述了开放挑战与未来方向。

---

### 2 REBEL: Hidden Knowledge Recovery via Evolutionary-Based Evaluation Loop

**link**: https://arxiv.org/pdf/2602.06248.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 大型语言模型（LLM）的机器遗忘旨在从训练好的模型中移除敏感或受版权保护的数据。然而，当前遗忘方法的真实效果仍不确定。标准评估指标依赖良性查询，往往将表面信息抑制误认为真正的知识移除。此类指标无法检测到更复杂的提示策略仍可能提取的残留知识。我们引入REBEL，一种基于进化的对抗性提示生成方法，旨在探测遗忘数据是否仍可恢复。实验表明，REBEL成功地从在标准遗忘基准测试中看似已遗忘知识的模型中引出“被遗忘”的知识，揭示当前遗忘方法可能仅提供表层保护。我们在TOFU和WMDP基准测试的子集上验证了该框架，评估了多种遗忘算法的性能。结果显示，REBEL持续优于静态基线，在TOFU上的攻击成功率（ASR）高达60%，在WMDP上达93%。代码将在接受后公开。

---

### 3 Steering Safely or Off a Cliff? Rethinking Specificity and Robustness in Inference-Time Interventions

**link**: https://arxiv.org/pdf/2602.06256.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 模型引导（即在推理时干预隐藏表示）已成为一种轻量级替代微调的方法，用于精确控制大型语言模型。虽然引导效果已被广泛研究，但关于干预是否仅改变目标属性的评估仍然有限，特别是在与目标属性相关的非预期行为变化方面。我们将此概念称为特异性。我们提出一个框架，区分特异性的三个维度：一般性（保持流畅性和无关能力）、控制性（保持相关控制属性）和鲁棒性（在分布偏移下保持控制属性）。我们研究了两个安全关键用例：引导模型减少过度拒绝和忠实性幻觉，结果表明，虽然引导实现了高效能并在很大程度上保持了一般性和控制特异性，但始终无法保持鲁棒性特异性。例如，在过度拒绝引导中，所有引导方法在不损害一般能力和对有害查询的拒绝的同时减少了过度拒绝；然而，它们显著增加了对越狱攻击的脆弱性。我们的工作首次系统评估了模型引导中的特异性，表明标准的效能和特异性检查是不够的，因为如果没有鲁棒性评估，引导方法可能看似可靠，实则损害模型安全性。

---

### 4 Self-Improving World Modelling with Latent Actions

**link**: https://arxiv.org/pdf/2602.06130.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 世界的内部建模——预测在动作Z下先前状态X和后续状态Y之间的转换——对于LLM和VLM的推理和规划至关重要。学习此类模型通常需要昂贵的带动作标签的轨迹。我们提出了SWIRL，这是一种自改进框架，通过将动作视为潜在变量并在正向世界建模（FWM）Pθ(Y|X,Z)和逆动力学建模（IDM）Qφ(Z|X,Y)之间交替，从仅含状态的序列中学习。SWIRL迭代两个阶段：（1）变分信息最大化，更新FWM以生成在给定先前状态的情况下与潜在动作最大化条件互信息的后续状态，从而促进可识别的一致性；（2）ELBO最大化，更新IDM以解释观察到的转换，有效地执行坐标上升。两个模型都使用强化学习（具体为GRPO）进行训练，将相反的冻结模型的对数概率作为奖励信号。我们为这两种更新提供了理论上的可学习性保证，并在多个环境中对LLM和VLM上的SWIRL进行了评估：单轮和多轮开放世界视觉动态以及用于物理、网络和工具调用的合成文本环境。SWIRL在AURORABench上实现了16%的增益，在ByteMorph上实现了28%的增益，在WorldPredictionBench上实现了16%的增益，在StableToolBench上实现了14%的增益。

---

### 5 Multi-Way Representation Alignment

**link**: https://arxiv.org/pdf/2602.06205.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 柏拉图表示假说表明，独立训练的神经网络会收敛到越来越相似的潜在空间。然而，当前映射这些表示的策略本质上是成对的，随着模型数量的增加呈二次方扩展，并且无法产生一致的全局参考。在本文中，我们研究了M≥3个模型的对齐问题。我们首先采用广义普罗克拉斯提斯分析（GPA）来构建一个共享的正交空间，该空间保留了模型拼接等任务所必需的内部几何结构。然后，我们表明严格的等距对齐对于检索是次优的，在检索中，像典型相关分析（CCA）这样的最大化一致性方法通常占优。为了弥合这一差距，我们最终提出了几何校正普罗克拉斯提斯对齐（GCPA），它建立了一个基于GPA的稳健空间，然后对方向不匹配进行事后校正。大量实验表明，GCPA在保持实用的共享参考空间的同时，持续改进了任意对检索。

---

### 6 Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems

**link**: https://arxiv.org/pdf/2602.06319.pdf  
**date**: 2026-02-09  
**keywords**: cs.AI  
**abs**: 该论文引入了GrAlgoBench基准，旨在通过图算法问题评估大型推理模型（LRMs）的推理能力。图算法问题需要长上下文推理、难度可控且支持程序化评估。实验揭示了当前LRMs的两大主要弱点：一是随着上下文长度增加（图节点超过120个时准确率低于50%），准确性急剧下降，这由频繁的执行错误、弱记忆和冗余推理导致；二是存在过度思考现象，主要因大量无效的自我验证导致推理轨迹膨胀而正确性未提升。该研究为LRMs推理能力的提升提供了严格的多维度测试平台。

---

### 7 AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents

**link**: https://arxiv.org/pdf/2602.06485.pdf  
**date**: 2026-02-09  
**keywords**: cs.AI  
**abs**: 该论文针对4B参数规模的边缘级代理模型训练展开系统研究，发现其面临三大瓶颈：监督微调（SFT）中的灾难性遗忘、强化学习（RL）中对奖励信号噪声的敏感性，以及长上下文场景中冗余信息导致的推理退化。为此，提出AgentCPM-Explore框架，通过参数空间模型融合、奖励信号去噪和上下文信息精炼等方法，实现深度探索。实验表明，该模型在4B级别达到SOTA性能，在多个基准上超越8B级模型，甚至优于Claude-4.5-Sonnet等更大规模模型，证明边缘级模型的瓶颈在于推理稳定性而非固有能力上限。

---

### 8 Improve Large Language Model Systems with User Logs

**link**: https://arxiv.org/pdf/2602.06470.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL  
**abs**: 该研究针对LLM系统在真实部署中面临的高质量数据稀缺和计算成本递增问题，提出了基于用户日志的优化框架UNO。用户交互日志作为真实人类反馈和过程知识的丰富来源，UNO框架通过将日志提炼为半结构化规则和偏好对，采用查询与反馈驱动的聚类管理数据异质性，并量化模型先验知识与日志数据间的认知差距。该框架能自适应过滤噪声反馈，构建从日志中提取的主经验和反思经验模块，从而提升LLM系统的响应质量，实验表明其显著优于检索增强生成（RAG）和基于记忆的基线方法。

---

### 9 Dynamics-Aligned Shared Hypernetworks for Zero-Shot Actuator Inversion

**link**: https://arxiv.org/pdf/2602.06550.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 针对上下文强化学习中的零样本泛化挑战，特别是潜在上下文（latent context）需从数据中推断的场景（如执行器反转问题：相同动作在潜在二进制上下文下产生相反物理效果），该研究提出DMA*-SH框架。该框架通过单个超网络（仅经动态预测训练）生成少量适配器权重，共享于动态模型、策略和动作价值函数，赋予与执行器反转匹配的归纳偏置。输入/输出归一化和随机输入掩码稳定上下文推断，促进方向集中表示。理论分析证明超网络调制的表达性分离，方差分解为策略梯度提供方差边界。在新构建的执行器反转基准（AIB）上，DMA*-SH实现零样本泛化，显著优于领域随机化和标准上下文感知基线。

---

### 10 HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction

**link**: https://arxiv.org/pdf/2602.06527.pdf  
**date**: 2026-02-09  
**keywords**: cs.AI  
**abs**: 通过多路径思维链扩展测试时计算可以提高推理准确性，但其有效性关键取决于探索与利用之间的权衡。现有方法以僵化的方式处理这种权衡：树结构搜索通过脆弱的扩展规则硬编码探索过程，干扰了训练后的推理；而并行推理过度探索冗余的假设路径，并依赖较弱的答案选择。基于最优平衡具有阶段依赖性以及正确与错误推理路径通常仅在后期阶段才分歧的观察，我们将测试时扩展重新表述为假设池上的动态扩展-缩减控制问题。我们提出HyPER，一种用于混合专家模型中多路径解码的无训练在线控制策略，该策略使用轻量级路径统计信息在固定预算下重新分配计算资源。HyPER包括一个在线控制器，随着假设池的演变从探索过渡到利用；一种令牌级细化机制，无需全路径重采样即可实现高效的生成时利用；以及一种长度和置信度感知的聚合策略，用于可靠的答案时利用。在四个混合专家语言模型上的多种推理基准实验表明，HyPER始终实现了卓越的准确性-计算权衡，将准确性提高8%至10%，同时减少25%至40%的令牌使用量。

---

### 11 Autoregressive Models for Knowledge Graph Generation

**link**: https://arxiv.org/pdf/2602.06707.pdf  
**date**: 2026-02-09  
**keywords**: cs.AI  
**abs**: 知识图谱（KG）生成要求模型学习三元组之间复杂的语义依赖关系，同时维持领域有效性约束。与独立评分三元组的链接预测不同，生成模型必须捕捉整个子图的相互依赖关系以产生语义连贯的结构。我们提出ARK（自回归知识图谱生成），这是一类自回归模型，通过将图视为（头实体、关系、尾实体）三元组序列来生成知识图谱。ARK直接从数据中学习隐式语义约束，包括类型一致性、时间有效性和关系模式，无需显式规则监督。在IntelliGraphs基准测试中，我们的模型在不同数据集上实现了89.2%至100.0%的语义有效性，同时生成训练期间未见过的新图。我们还引入SAIL，这是ARK的变分扩展，通过学习到的 latent 表示实现可控生成，支持无条件采样和从部分图进行条件补全。我们的分析表明，对于知识图谱生成，模型容量（隐藏维度 >= 64）比架构深度更关键，循环架构与基于Transformer的替代方案实现了相当的有效性，同时提供了显著的计算效率。这些结果表明，自回归模型为知识图谱生成提供了有效的框架，在知识库补全和查询回答方面具有实际应用。

---

### 12 SaDiT: Efficient Protein Backbone Design via Latent Structural Tokenization and Diffusion Transformers

**link**: https://arxiv.org/pdf/2602.06706.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 从头蛋白质骨架设计的生成模型在创建新型蛋白质结构方面取得了显著成功。然而，这些基于扩散的方法计算密集，对于大规模结构探索而言速度较慢。尽管近期如Proteina等研究引入流匹配以提高采样效率，但在蛋白质领域中，用于结构压缩和加速的tokenization潜力尚未充分探索。本文提出SaDiT，一种将SaProt Tokenization与扩散Transformer（DiT）架构相结合的新型框架，以加速蛋白质骨架生成。SaDiT利用离散潜在空间表示蛋白质几何结构，显著降低生成过程的复杂性，同时保持理论上的SE(3)等价性。为进一步提高效率，我们引入IPA Token Cache机制，通过在迭代采样中重用计算的token状态来优化不变点注意力（IPA）层。实验结果表明，SaDiT在计算速度和结构可行性上均优于现有模型（如RFDiffusion和Proteina）。我们在无条件骨架生成和折叠类条件生成任务上评估模型，SaDiT展现出捕捉复杂拓扑特征的卓越能力，且具有高可设计性。

---

### 13 Latent Structure Emergence in Diffusion Models via Confidence-Based Filtering

**link**: https://arxiv.org/pdf/2602.06155.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 扩散模型依赖于初始噪声种子的高维 latent space（ latent 空间），但目前尚不清楚该空间是否包含足够的结构来预测生成样本的属性（如类别）。本文通过预训练分类器分配的置信度分数来研究 latent structure（ latent 结构）的涌现。研究表明，虽然考虑所有噪声实现时 latent space 似乎基本无结构，但将注意力限制在能产生高置信度样本的初始噪声种子上时，会发现显著的类别可分离性。通过比较不同置信度噪声子集的类别可预测性以及检查 latent space 的类别分离性，本文发现了与类别相关的 latent structure 证据，这种结构仅在基于置信度的过滤下才可观察到。作为实际应用，本文讨论了基于置信度的过滤如何作为引导式方法的替代方案实现条件生成。

---

### 14 Generating Data-Driven Reasoning Rubrics for Domain-Adaptive Reward Modeling

**link**: https://arxiv.org/pdf/2602.06795.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL, latent reasoning  
**abs**: 本文提出一种数据驱动的方法，自动构建高度细粒度的推理错误分类体系（即“评分标准”），以增强大型语言模型（LLM）对未见过的推理过程的错误检测能力。研究表明，在编码、数学和化学工程等技术领域，利用这些分类体系的分类方法相比基线方法展现出更强的错误识别能力。这些评分标准可用于构建更优的LLM奖励函数，通过强化学习训练推理模型。实验结果显示，基于该方法的奖励函数能使模型在复杂技术任务上的准确率比使用通用LLM作为评判者的模型提高45%，同时仅需20%的金标签数据即可接近使用可验证奖励训练的模型性能。该研究将奖励评分标准的应用从定性行为评估扩展到定量正确性评估，为缺乏完整金标签数据集的复杂技术问题求解提供了新途径。

---

### 15 On the Identifiability of Steering Vectors in Large Language Models

**link**: https://arxiv.org/pdf/2602.06801.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG, latent space  
**abs**: 本文探讨大型语言模型（LLM）中转向向量（如角色向量）的可识别性问题。激活转向方法常被用于控制LLM行为，并被认为能揭示模型的内部表征。研究将转向形式化为对内部表征的干预，证明在现实建模和数据条件下，转向向量由于存在大量行为上不可区分的干预等价类，本质上是不可识别的。实验在多个模型和语义特征上验证了这一点，表明正交扰动可实现近乎等效的效果且影响大小可忽略。然而，在统计独立性、稀疏性约束、多环境验证或跨层一致性等结构假设下，可识别性可以恢复。这些发现揭示了LLM解释性的基本限制，并阐明了可靠安全关键控制所需的结构假设。

---

### 16 The Representational Geometry of Number

**link**: https://arxiv.org/pdf/2602.06843.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL, latent space  
**abs**: 本文探讨认知科学中的核心问题：概念表征是收敛到共享流形以支持泛化，还是发散到正交子空间以最小化任务干扰。以数字概念为测试对象，将语言模型作为高维计算 substrate，研究发现数字表征在不同任务中保持稳定的关系结构。任务特定表征嵌入在不同子空间中，低级特征（如数量级和奇偶性）沿可分离的线性方向编码。关键发现是，这些子空间可通过线性映射相互转换，表明尽管位于不同子空间，表征仍共享关系结构。这些结果为语言模型如何平衡数字表征的共享结构与功能灵活性提供了机制性视角，表明理解产生于对共享概念关系结构应用任务特定转换的过程中。

---

### 17 Endogenous Resistance to Activation Steering in Language Models

**link**: https://arxiv.org/pdf/2602.06941.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 大型语言模型在推理过程中能够抵抗与任务不一致的激活引导，有时在生成过程中恢复以产生改进的响应，即使引导仍在进行中。我们称之为内源性引导抵抗（ESR）。使用稀疏自编码器（SAE）潜变量来引导模型激活，发现Llama-3.3-70B表现出显著的ESR，而Llama-3和Gemma-2系列的较小模型较少出现这种现象。识别出26个在离题内容期间差异激活且与Llama-3.3-70B中ESR有因果关联的SAE潜变量。零消融这些潜变量会使多次尝试率降低25%，为专用内部一致性检查电路提供了因果证据。通过提示和训练可以增强ESR：指导模型自我监控的元提示使Llama-3.3-70B的多次尝试率提高4倍，在自我纠正示例上微调成功在较小模型中诱导出类似ESR的行为。这些发现具有双重含义：ESR可以防止对抗性操纵，但也可能干扰依赖激活引导的有益安全干预。理解和控制这些抵抗机制对于开发透明和可控的AI系统很重要。

---

### 18 InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning

**link**: https://arxiv.org/pdf/2602.06960.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL  
**abs**: 大型推理模型通过扩展推理时的思维链实现了强大的性能，但该范式存在二次成本、上下文长度限制以及因“中间遗忘”效应导致的推理质量下降等问题。迭代推理通过定期总结中间思想缓解了这些问题，但现有方法依赖监督学习或固定启发式，无法优化何时总结、保留什么内容以及如何恢复推理。我们提出InftyThink+，一种端到端的强化学习框架，优化整个迭代推理轨迹，基于模型控制的迭代边界和显式总结。InftyThink+采用两阶段训练方案，先进行监督冷启动，再进行轨迹级强化学习，使模型能够学习战略性总结和继续决策。在DeepSeek-R1-Distill-Qwen-1.5B上的实验表明，InftyThink+在AIME24上的准确率提高了21%，明显优于传统的长思维链强化学习，同时对分布外基准也有更好的泛化能力。此外，InftyThink+显著降低了推理延迟并加速了强化学习训练，在提高推理效率的同时实现了更强的性能。

---

### 19 Learning a Generative Meta-Model of LLM Activations

**link**: https://arxiv.org/pdf/2602.06964.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 现有的神经网络激活分析方法（如PCA和稀疏自编码器）依赖强结构假设。生成模型提供了另一种选择：它们可以在没有此类假设的情况下揭示结构，并作为提高干预保真度的先验。我们通过在十亿个残差流激活上训练扩散模型来探索这一方向，创建“元模型”来学习网络内部状态的分布。我们发现扩散损失随计算量平滑下降，并可靠地预测下游效用。特别是，将元模型学习到的先验应用于引导干预可提高流畅性，随着损失降低，收益更大。此外，元模型的神经元越来越多地将概念隔离到单个单元中，稀疏探测分数随损失降低而增加。这些结果表明，生成元模型为无需限制性结构假设的可解释性提供了可扩展的路径。

---

### 20 Inference-Time Rethinking with Latent Thought Vectors for Math Reasoning

**link**: https://arxiv.org/pdf/2602.06584.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL  
**abs**: 标准的思维链推理在单次前向传播中生成解决方案，对每个标记做出不可撤销的承诺，且缺乏从早期错误中恢复的机制。我们引入推理时反思（Inference-Time Rethinking），这是一种生成式框架，通过将声明性潜在思维向量与过程式生成解耦，实现迭代自我修正。我们将推理分解为连续的潜在思维向量（推理什么内容）和一个基于该向量将推理轨迹语言化的解码器（如何推理）。除了作为声明性缓冲器外，潜在思维向量将推理结构压缩为连续表示，抽象掉表面级别的标记变异性，使得基于梯度的推理策略优化成为适定问题。我们的先验模型将非结构化噪声映射到有效推理模式的学习流形上，在测试时，我们采用吉布斯式过程，交替生成候选轨迹并优化潜在向量以更好地解释该轨迹，从而有效导航潜在流形以改进推理策略。在GSM8K上从头训练一个2亿参数的模型，我们的方法经过30次反思迭代，超越了参数数量多10到15倍的基线模型，包括30亿参数的对应模型。这一结果表明，有效的数学推理可以从复杂的推理时计算中产生，而不仅仅依赖于大量的参数。

---

### 21 Toward Faithful and Complete Answer Construction from a Single Document

**link**: https://arxiv.org/pdf/2602.06103.pdf  
**date**: 2026-02-09  
**keywords**: latent reasoning  
**abs**: 现代大型语言模型(LLMs)是由统计下一个token预测驱动的强大生成器。虽然能生成流畅文本，但这种设计使模型偏向高概率延续，而非基于源内容的详尽和忠实答案。因此，直接应用LLMs缺乏确保完整性(避免遗漏)和忠实性(避免无支持内容)的系统机制，这与核心AI安全原则存在根本冲突。为解决这一限制，我们提出EVE，一个用于基于文档推理的结构化框架。

---

### 22 SCONE: A Practical, Constraint-Aware Plug-in for Latent Encoding in Learned DNA Storage

**link**: https://arxiv.org/pdf/2602.06157.pdf  
**date**: 2026-02-09  
**keywords**: latent space  
**abs**: DNA存储已从概念发展到实用阶段，但其与神经压缩管道的集成仍然效率低下。早期DNA编码器在原始二进制数据之上应用冗余繁重的约束层——可行但原始。最近的神经编解码器将数据压缩为具有丰富统计结构的学习潜在表示，但仍然通过简单的二进制到四进制转码将这些潜在变量转换为DNA，放弃了熵模型的优化。这种不匹配破坏了压缩效率并使编码堆栈复杂化。本文提出了一个插件模块，将潜在压缩和DNA编码合并为单个步骤。SCONE直接在DNA碱基的潜在空间上执行四进制算术编码。其约束感知自适应编码模块动态引导熵编码器的学习概率分布，在编码期间确定性地实施生化约束——鸟嘌呤-胞嘧啶(GC)平衡和均聚物抑制，消除事后校正。该设计保留了完全可逆性，并在不修改的情况下利用超先验模型的学习先验。实验表明，SCONE实现了近乎完美的约束满足，计算开销可忽略不计(<2%延迟)，为端到端DNA兼容学习编解码器建立了潜在不可知接口。

---

### 23 PurSAMERE: Reliable Adversarial Purification via Sharpness-Aware Minimization of Expected Reconstruction Error

**link**: https://arxiv.org/pdf/2602.06269.pdf  
**date**: 2026-02-09  
**keywords**: latent space  
**abs**: 本文提出了一种新的确定性净化方法，通过将潜在的对抗性样本映射到数据分布模式附近的样本，从而提高对抗鲁棒性。该方法设计为确定性的，以确保可靠的测试准确性，并防止在对手完全了解系统及其随机性时随机净化方法中观察到的有效鲁棒性下降。研究人员使用通过最小化噪声损坏数据的预期重建误差训练的分数模型，从而学习输入数据分布的结构特征。给定潜在的对抗性输入，该方法在其局部邻域内搜索最小化噪声损坏下预期重建误差的净化样本，然后将该净化样本输入分类器。在净化过程中，使用锐度感知最小化来引导净化样本朝向预期重建误差景观的平坦区域，从而增强鲁棒性。

---

### 24 SOCKET: SOft Collison Kernel EsTimator for Sparse Attention

**link**: https://arxiv.org/pdf/2602.06283.pdf  
**date**: 2026-02-09  
**keywords**: LLM Memory  
**abs**: 在长上下文推理中利用稀疏性对于扩展大型语言模型至关重要，因为注意力在自回归解码中占主导成本。稀疏注意力通过将计算限制在令牌的子集上来降低此成本，但其有效性关键取决于推理时相关令牌的高效评分和选择。本文重新审视局部敏感哈希(LSH)作为稀疏化原语，并引入SOCKET，这是一种软碰撞核估计器，用概率性、相似度感知聚合替换硬桶匹配。核心见解是硬LSH产生离散碰撞信号，因此不适合排序。相比之下，软LSH跨哈希表聚合分级碰撞证据，保留真实top-k令牌之间相对顺序的稳定性。这种转换将LSH从候选生成启发式提升为稀疏注意力的原则性和数学基础的评分内核。借助用于评分键的自定义CUDA内核和用于稀疏注意力的Flash Decode Triton后端，SOCKET实现了比FlashAttention高达1.5倍的吞吐量，使其成为长上下文推理的有效工具。

---

### 25 Online Adaptive Reinforcement Learning with Echo State Networks for Non-Stationary Dynamics

**link**: https://arxiv.org/pdf/2602.06326.pdf  
**date**: 2026-02-09  
**keywords**: latent space  
**abs**: 在模拟中训练的强化学习(RL)策略在部署到现实环境时通常会因非平稳动态而遭受严重的性能下降。虽然领域随机化(DR)和元RL已被提出解决此问题，但它们通常依赖于大量预训练、特权信息或高计算成本，限制了其在实时和边缘系统中的适用性。本文提出了一种基于水库计算的轻量级RL在线适应框架。具体而言，研究人员集成回声状态网络(ESNs)作为适应模块，将最近的观察历史编码为潜在上下文表示(latent context representation)，并使用递归最小二乘法(RLS)在线更新其读出权重。这种设计能够在没有反向传播、预训练或访问特权信息的情况下实现快速适应。在具有严重和突然环境变化的CartPole和HalfCheetah任务上的实验结果表明，所提出的方法在分布外动态下显著优于DR和代表性自适应基线，在几个控制步骤内实现稳定适应。

---

### 26 Degradation of Feature Space in Continual Learning

**link**: https://arxiv.org/pdf/2602.06586.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 集中式训练是深度学习的标准范式，能让模型从统一数据集中学习，此时各向同性特征分布自然形成以支持结构良好且可泛化的表示。相比之下，持续学习处理流式非平稳数据，需增量训练模型，固有地面临可塑性-稳定性困境，其学习动态往往导致特征空间各向异性增加。本文研究在持续学习中促进特征空间各向同性是否能提升表示质量。通过在CIFAR-10和CIFAR-100数据上使用对比持续学习技术的实验发现，各向同性正则化不仅未能改善，反而会降低持续学习场景下的模型精度。结果揭示了集中式与持续学习在特征几何上的本质差异，表明各向同性虽在集中式设置中有益，但可能不是非平稳学习场景的合适归纳偏置。

---

### 27 Disentanglement by means of action-induced representations

**link**: https://arxiv.org/pdf/2602.06741.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG, latent space  
**abs**: 表示学习的一个主要目标是利用变分自编码器（VAEs）学习可解释的表示。其核心挑战在于获得解纠缠表示，即每个潜在维度对应一个不同的生成因子。这种困难根本上与无法执行非线性独立成分分析有关。本文引入了动作诱导表示（AIRs）框架，该框架对物理系统在可执行实验（或动作）下的表示进行建模。研究表明，在此框架中，我们可以证明地将自由度与其动作依赖性进行解纠缠。我们进一步引入了变分AIR架构（VAIR），该架构能够提取AIRs，从而在标准VAEs失败的情况下实现可证明的解纠缠。除了状态表示外，VAIR还捕获了潜在生成因子的动作依赖性，直接将实验与它们影响的自由度联系起来。

---

### 28 Robustness Beyond Known Groups with Low-rank Adaptation

**link**: https://arxiv.org/pdf/2602.06924.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 深度学习模型在优化平均准确率时，常对特定子群体表现出系统性失败。现实中，受影响的子群体往往未标记或未知，因此需要在无需预先指定敏感子群体的情况下提升其性能。本文提出LEIA（低秩错误知情适应）方法，通过识别表示空间中模型错误集中的低维子空间，仅对分类器logits进行低秩调整，直接针对潜在失败模式，无需修改主干网络或依赖群体标签。在五种真实数据集上的实验表明，LEIA在各种设置下均能一致提升最差群体性能，同时保持高效和参数经济性。

---

### 29 From Core to Detail: Unsupervised Disentanglement with Entropy-Ordered Flows

**link**: https://arxiv.org/pdf/2602.06940.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 无监督表示学习中，获取语义有意义且跨运行稳定的表示仍是核心挑战。本文提出熵有序流（EOFlows），一种归一化流框架，通过解释熵对潜在维度进行排序，类似PCA的解释方差。该排序支持自适应注入流：训练后可保留前C个潜在变量形成紧凑核心表示，其余变量捕获细节和噪声，C在推理时灵活选择而非训练时固定。EOFlows结合独立机制分析、主成分流和流形熵度量的见解，在CelebA数据集上实验表明，该方法能发现丰富的语义可解释特征，实现高压缩和强去噪能力。

---

### 30 CAST: Character-and-Scene Episodic Memory for Agents

**link**: https://arxiv.org/pdf/2602.06051.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL  
**abs**: 情景记忆是人类记忆的核心组成部分，指的是回忆以人物、时间和地点为基础的连贯事件的能力。然而，大多数智能体记忆系统仅强调语义回忆，并将经验视为键值对、向量或图等结构，这使得它们难以表示和检索连贯事件。为解决这一挑战，我们提出了一种受戏剧理论启发的基于角色和场景的记忆架构（CAST）。具体而言，CAST构建3D场景（时间/地点/主题）并将其组织成角色档案，以总结角色的事件来表示情景记忆。此外，CAST通过基于图的语义记忆对这种情景记忆进行补充，形成了稳健的双重记忆设计。实验表明，CAST在各种数据集上的F1值平均提高了8.11%，LLM-as-a-Judge（J值）平均提高了10.21%，尤其在开放式和时间敏感的对话问题上表现突出。

---

### 31 Towards Generalizable Reasoning: Group Causal Counterfactual Policy Optimization for LLM Reasoning

**link**: https://arxiv.org/pdf/2602.06475.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 大型语言模型（LLMs）在推理能力提升下擅长复杂任务。然而，现有奖励机制与最终正确性紧密耦合，很少关注底层推理过程：推理合理但答案错误的轨迹获得低分数，而逻辑有缺陷的幸运猜测可能被高奖励，影响推理泛化。从因果角度，本文将固定问题的多候选推理解释为一系列有理论支持的反事实实验。基于此，提出群体因果反事实策略优化，明确训练LLMs学习可泛化的推理模式。该方法提出一种episodic因果反事实奖励，联合捕获（i）鲁棒性，鼓励推理步骤诱导的答案分布在反事实扰动下保持稳定；（ii）有效性，确保足够的变异性以使学习的推理策略能跨问题迁移。然后从该奖励构建token级优势并优化策略，促使LLMs偏好过程有效且反事实鲁棒的推理模式。在多种基准上的实验证明了其优势。

---

### 32 Adaptive Uncertainty-Aware Tree Search for Robust Reasoning

**link**: https://arxiv.org/pdf/2602.06493.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 推理时的推理扩展显著提升了大型语言模型（LLMs）在复杂问题解决中的能力。一种流行方法涉及由过程奖励模型（PRMs）引导的外部搜索。然而，该框架的根本局限在于PRMs在评估偏离其训练分布的推理路径时存在认知不确定性。本文系统分析了这一挑战。首先，提供经验证据表明PRMs在分布外（OOD）样本上表现出高不确定性和不可靠评分。然后建立理论框架，证明标准搜索会导致线性遗憾累积，而不确定性感知策略可实现次线性遗憾。受这些发现启发，提出不确定性感知树搜索（UATS），一种通过蒙特卡洛dropout估计不确定性并使用强化学习控制器动态分配计算预算的统一方法。大量实验表明，该方法有效减轻了OOD错误的影响。

---

### 33 Evolutionary Generation of Multi-Agent Systems

**link**: https://arxiv.org/pdf/2602.06511.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 基于大型语言模型（LLM）的多智能体系统（MAS）在复杂推理、规划和工具增强任务中显示出巨大潜力，但设计有效的MAS架构仍然费力、脆弱且难以泛化。现有自动MAS生成方法要么依赖代码生成（常导致可执行性和鲁棒性问题），要么施加限制表达性和适应性的刚性架构模板。本文提出进化多智能体系统生成（EvoMAS），将MAS生成表述为结构化配置生成。EvoMAS在配置空间中执行进化生成：从池中选择初始配置，应用由执行轨迹引导的反馈条件变异和交叉，并迭代优化候选池和经验记忆。在BBEH、SWE-Bench和WorkBench等多样基准上的评估表明，EvoMAS持续优于人工设计的MAS和现有自动生成方法，同时生成具有更高可执行性和运行时鲁棒性的系统。EvoMAS在BBEH推理上比EvoAgent高10.5分，在WorkBench上高7.1分。结合Claude-4.5-Sonnet，EvoMAS在SWE-Bench-Verified上达到79.1%，与排行榜顶部持平。

---

### 34 Refining the Information Bottleneck via Adversarial Information Separation

**link**: https://arxiv.org/pdf/2602.06549.pdf  
**date**: 2026-02-09  
**keywords**: cs.LG  
**abs**: 在材料科学等领域，有限数据的泛化对模型尤为关键，实验数据中的任务相关特征常被测量噪声和实验伪影严重混淆。标准正则化技术无法精确分离有意义特征与噪声，而现有对抗适应方法受限于对显式分离标签的依赖。为解决此挑战，提出对抗信息分离框架（AdverISF），无需显式监督即可分离任务相关特征与噪声。AdverISF引入自监督对抗机制，强制任务相关特征与噪声表示之间的统计独立性。进一步采用多层分离架构，跨特征层次逐步回收噪声信息，以恢复无意中被当作噪声丢弃的特征，从而实现更细粒度的特征提取。大量实验表明，AdverISF在数据稀缺场景中优于最先进方法。此外，在真实材料设计任务上的评估显示其具有卓越的泛化性能。

---

### 35 Is my model "mind blurting"? Interpreting the dynamics of reasoning tokens with Recurrence Quantification Analysis (RQA)

**link**: https://arxiv.org/pdf/2602.06266.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL, latent space, latent reasoning  
**abs**: 测试时计算对于大型推理模型至关重要，但通过生成文本来分析其推理行为变得越来越不切实际和不可靠。响应长度常被用作推理努力的粗略代理，但该指标无法捕捉思维链（CoT）或生成令牌的动态和有效性。本文提出递归量化分析（RQA）作为一种非文本替代方法，用于在测试时分析模型的推理链。通过将令牌生成视为动态系统，在每个生成步骤提取隐藏嵌入，并将RQA应用于所得轨迹。RQA指标（包括确定性和层流性）量化模型潜在表示中的重复和停滞模式。对来自DeepSeek-R1-Distill的3600条生成轨迹的分析表明，RQA捕捉到响应长度未反映的信号，并将任务复杂性预测提高了8%。这些结果有助于确立RQA作为研究推理模型测试时扩展的潜在令牌生成动态的原则性工具。

---

### 36 Visual Word Sense Disambiguation with CLIP through Dual-Channel Text Prompting and Image Augmentations

**link**: https://arxiv.org/pdf/2602.06799.pdf  
**date**: 2026-02-09  
**keywords**: cs.CL  
**abs**: 歧义给大型语言模型（LLMs）的自然语言理解带来了持续挑战。为了更好地理解如何通过视觉领域解决词汇歧义，我们开发了一个可解释的视觉词义消歧（VWSD）框架。该模型利用CLIP将歧义语言和候选图像投影到一个共享的多模态空间中。我们通过语义和基于照片的双渠道提示集成（结合WordNet同义词）来丰富文本嵌入，同时通过稳健的测试时增强来优化图像嵌入。然后使用余弦相似度确定与歧义文本最匹配的图像。在SemEval-2023 VWSD数据集上的评估表明，丰富嵌入后，MRR从0.7227提升至0.7590，命中率从0.5810提升至0.6220。消融研究显示，双渠道提示提供了强大的低延迟性能，而激进的图像增强仅带来微小增益。使用WordNet定义和多语言提示集成的额外实验进一步表明，嘈杂的外部信号往往会稀释语义特异性，从而强化了精确的、与CLIP对齐的提示在视觉词义消歧中的有效性。

---

### 37 Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning

**link**: https://arxiv.org/pdf/2602.06600.pdf  
**date**: 2026-02-09  
**keywords**: latent reasoning  
**abs**: 大型推理模型（LRMs）的测试时计算分配在数学问题解决、代码合成和规划等领域应用广泛。现有方法通过扩展自一致性、并行思考、添加通用“思考标记”或提示模型在回答前重读问题来解决此问题，但这些方法要么注入与任务无关的标记，要么依赖启发式方法，忽略了许多LRMs在内部推理链开头表现出的“自发重复”现象。本文分析并利用模型重述问题的倾向（称为“提示回声”，EOP）作为一种前置的计算塑造机制。通过将回声移除视为基于拒绝的条件作用，形式化其概率成本，并定义“回声似然差距”Δℒ作为可计算的代理，建立了早期重复与似然增益及下游准确性之间的理论联系。为此，本文提出了回声蒸馏监督微调（ED-SFT）以通过监督微调灌输“回声-然后-推理”模式，并提出回声提示（EP）以在无需训练的情况下在推理过程中重新锚定模型。长度和后缀控制的似然分析及分层注意力研究表明，EOP增加了中间层中答案与答案前缀的注意力，与“注意力重聚焦”机制一致。在GSM8K、MathQA、Hendrycks-MATH、AIME24和MATH-500等推理基准上的评估显示，在相同解码设置和预算下，该方法持续优于基线。代码已公开。

---

### 38 Do Prompts Guarantee Safety? Mitigating Toxicity from LLM Generations through Subspace Intervention

**link**: https://arxiv.org/pdf/2602.06623.pdf  
**date**: 2026-02-09  
**keywords**: latent space  
**abs**: 大型语言模型（LLMs）是强大的文本生成器，但即使给定看似无害的提示，它们也可能生成有毒或有害内容，这带来了严重的安全挑战并可能造成现实危害。毒性通常是微妙且依赖上下文的，难以在标记级别或通过粗略的句子级别信号检测。此外，减轻毒性的努力往往面临安全性与生成文本的连贯性或流畅性之间的权衡。在这项工作中，我们提出了一种针对性的子空间干预策略，用于识别和抑制潜在模型表示中的隐藏有毒模式，同时保留生成安全流畅内容的整体能力。在RealToxicityPrompts上，我们的方法与现有基线相比实现了强大的缓解性能，对推理复杂性的影响最小。在多个LLM上，我们的方法将最先进的去毒系统的毒性降低了8-20%，同时保持了相当的流畅性。通过广泛的定量和定性分析，我们表明我们的方法在不损害生成性能的情况下实现了有效的毒性降低，持续优于现有基线。
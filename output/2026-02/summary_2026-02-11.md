### 1 Effective Reasoning Chains Reduce Intrinsic Dimensionality

**link**: https://arxiv.org/pdf/2602.09276.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 思维链（CoT）推理及其变体显著提升了语言模型在复杂推理任务上的性能，但其促进泛化的具体机制仍不明确。本文将内在维度作为衡量推理链有效性的定量指标，该指标量化达到特定精度所需的最小模型维度。通过固定模型架构并改变推理策略的任务设计，研究表明有效的推理策略能持续降低任务的内在维度。在GSM8K数据集上使用Gemma-3 1B和4B模型验证发现，推理策略的内在维度与分布内及分布外数据的泛化性能呈强负相关。研究结果表明，有效的推理链通过使用更少参数更好地压缩任务来促进学习，为分析推理过程提供了新的定量指标。

---

### 2 Empowering Contrastive Federated Sequential Recommendation with LLMs

**link**: https://arxiv.org/pdf/2602.09306.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 联邦序列推荐（FedSeqRec）旨在保持用户数据去中心化的同时进行下一项预测，但模型质量常受限于设备上存储的碎片化、noisy和同质化交互日志。本文提出LUMOS，一种参数隔离的FedSeqRec架构，将大型语言模型（LLMs）集成为本地语义生成器。LUMOS通过本地LLM从用户历史中构建三种互补序列变体：（i）未来导向轨迹（推断合理行为延续）、（ii）语义等效重述（保留用户意图同时多样化交互模式）、（iii）偏好不一致反事实（作为信息负例）。这些合成序列通过三视角对比优化方案在联邦骨干网络中联合编码，实现更丰富的表示学习而不暴露敏感信息。实验表明，LUMOS在三个公共基准上的HR@20和NDCG@20指标持续优于集中式和联邦基线，并在noisy和对抗环境中提高了鲁棒性。

---

### 3 PABU: Progress-Aware Belief Update for Efficient LLM Agents

**link**: https://arxiv.org/pdf/2602.09138.pdf
**date**: 2026-02-11
**keywords**: LLM Memory
**abs**: 大型语言模型（LLM）智能体通常根据完整的动作-观察历史来决定动作，这会引入与任务无关的信息，容易导致冗余动作和更高的推理成本。我们提出了进度感知信念更新（PABU），这是一种信念状态框架，通过显式建模任务进度并选择性保留过去的动作和观察结果，来紧凑地表示智能体的状态。在每一步，智能体预测自上一轮以来的相对进度，并决定是否存储新遇到的交互，仅根据保留的子集来调整未来的决策。在AgentGym基准测试的八个环境中，使用相同的训练轨迹，PABU实现了81.0%的任务完成率，比使用完整历史信念的先前最先进（SoTA）模型高出23.9%。此外，PABU的进度导向动作选择提高了效率，将平均交互步骤数减少到9.5，对应减少了26.9%。消融研究表明，显式进度预测和选择性保留对于稳健的信念学习和性能提升都是必要的。

---

### 4 Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge

**link**: https://arxiv.org/pdf/2602.09341.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 多智能体系统（MAS）可以显著扩展大型语言模型（LLMs）的推理能力，但大多数框架仍然通过多数投票来聚合智能体的输出。这种启发式方法丢弃了推理轨迹的证据结构，并且在“虚构共识”下很脆弱，即智能体共享相关偏差并收敛于相同的错误理由。我们引入了AgentAuditor，它用推理树的路径搜索取代了投票，该推理树明确表示智能体轨迹之间的一致和分歧。AgentAuditor通过在关键分歧点比较推理分支来解决冲突，将全局裁决转变为高效的局部验证。我们进一步提出了反共识偏好优化（ACPO），它在多数失败案例上训练裁决者，并奖励基于证据的少数选择而非流行错误。AgentAuditor与MAS设置无关，我们发现在5个流行设置中，它比多数投票高出高达5%的绝对准确率，比使用LLM作为裁决者高出高达3%。

---

### 5 Spectral Disentanglement and Enhancement: A Dual-domain Contrastive Framework for Representation Learning

**link**: https://arxiv.org/pdf/2602.09066.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 大规模多模态对比学习在学习丰富且可迁移的表示方面取得了显著成功，但仍受限于对特征维度的统一处理以及对学习特征内在谱结构的忽视。实证表明，高维嵌入倾向于坍缩到窄锥中，将任务相关语义集中在小子空间，而大多数维度被噪声和虚假关联占据。这种谱不平衡和纠缠削弱了模型泛化能力。本文提出谱解纠缠与增强（SDE）框架，通过奇异值分解自适应划分特征维度为强信号（任务关键语义）、弱信号（辅助关联）和噪声（无关扰动），并采用基于课程的谱增强策略选择性放大信息成分。进一步引入双域对比损失，联合优化特征空间和谱空间对齐，将谱正则化整合到训练中，鼓励更丰富稳健的表示。实验表明SDE在大规模多模态基准上提升了表示鲁棒性和泛化能力。

---

### 6 Learning to Remember, Learn, and Forget in Attention-Based Models

**link**: https://arxiv.org/pdf/2602.09075.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: Transformer中的上下文学习（ICL）作为在线关联记忆，是其在复杂序列处理任务中高性能的基础。但门控线性注意力模型的记忆容量固定，长序列时易受干扰。本文提出Palimpsa自注意力模型，将ICL视为需解决稳定性-可塑性困境的持续学习问题。该模型采用贝叶斯元可塑性，使注意力状态的可塑性与捕获累积知识的先验分布重要性状态相关联。理论上证明多种门控线性注意力模型可作为特定架构选择和后验近似，且Mamba2是遗忘占主导的特例。此联系能将非元可塑性模型转换为元可塑性模型，显著扩展记忆容量。实验表明Palimpsa在多查询关联回忆（MQAR）基准和常识推理任务上持续优于基线。

---

### 7 $n$-Musketeers: Reinforcement Learning Shapes Collaboration Among Language Models

**link**: https://arxiv.org/pdf/2602.09173.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 带可验证奖励的强化学习（RLVR）最新进展表明，小型专用语言模型（SLM）无需依赖大型单体LLM即可展现结构化推理。本文引入软隐藏状态协作，通过可训练注意力接口将多个异构冻结SLM专家的内部表示整合。在Reasoning Gym和GSM8K上的实验显示，这种潜在整合性能与强单模型RLVR基线相当。消融实验揭示专家利用的双重机制：简单算术领域性能提升可由静态专家偏好解释，而复杂设置会在训练中诱导更集中结构化的专家注意力，表明路由器连接相关专家时出现专业化。隐藏状态协作提供了利用冻结专家的紧凑机制，同时可观察专家利用模式及其在RLVR下的演变。

---

### 8 Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models

**link**: https://arxiv.org/pdf/2602.09485.pdf
**date**: 2026-02-11
**keywords**: cs.AI
**abs**: 长思维链（Long CoTs）被广泛用于多模态推理模型以处理复杂任务，通过捕捉详细的视觉信息。然而，这些Long CoTs往往过长且包含冗余推理步骤，可能阻碍推理效率。压缩长思维链是自然的解决方案，但现有方法面临两大挑战：（1）可能通过移除关键对齐线索损害视觉-文本推理的完整性；（2）压缩过程缺乏可解释性，难以辨别哪些信息至关重要。为解决这些问题，我们提出XMCC，一种可解释的多模态思维链压缩器（eXplainable Multimodal CoT Compressor），将压缩表述为通过强化学习优化的序列决策过程。XMCC能够有效缩短推理轨迹，同时保留关键推理步骤和答案正确性，并为其压缩决策生成自然语言解释。在代表性多模态推理基准上的大量实验表明，XMCC不仅减少了推理长度，还提供了可解释的说明，验证了其有效性。

---

### 9 GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis

**link**: https://arxiv.org/pdf/2602.09794.pdf
**date**: 2026-02-11
**keywords**: cs.AI
**abs**: 思维链（CoT）已被证明能显著提高大型语言模型（LLMs）在复杂任务上的推理准确性。然而，由于自回归的逐步生成范式，现有CoT方法存在两个基本局限性。首先，推理过程对早期决策高度敏感：一旦引入初始错误，它往往会在后续步骤中传播和放大，而缺乏全局协调和修正机制使得此类错误难以纠正，最终导致推理链失真。其次，当前CoT方法缺乏用于过滤冗余推理和提取关键推理特征的结构化分析技术，导致推理过程不稳定且可解释性有限。为解决这些问题，我们提出GHS-TDA。GHS-TDA首先构建语义丰富的全局假设图，以聚合、对齐和协调多个候选推理路径，从而在局部推理失败时提供替代的全局修正路线。然后，它应用基于持久同调的拓扑数据分析来捕获稳定的多尺度结构，去除冗余和不一致性，并提取更可靠的推理骨架。通过联合利用推理多样性和拓扑稳定性，GHS-TDA实现了自适应收敛，生成高置信度和可解释的推理路径，并在多个推理基准上在准确性和鲁棒性方面一致优于强基线。

---

### 10 The Critical Horizon: Inspection Design Principles for Multi-Stage Operations and Deep Reasoning

**link**: https://arxiv.org/pdf/2602.09394.pdf
**date**: 2026-02-11
**keywords**: stat.ML
**abs**: 制造线、服务流程、供应链和AI推理链面临共同挑战：将终端结果归因于导致它的中间阶段。本文建立了信用分配问题的信息论障碍：早期步骤与最终结果之间的信号随深度呈指数衰减，形成临界horizon，超出此范围，任何算法都无法仅从端点数据中学习。作者证明了四个结果：信号衰减边界、宽度限制、目标不匹配和最优检查设计。这些结果为操作中的检查设计和AI中的监督设计提供了共同的分析基础，涉及深度推理相关内容。

---

### 11 Squeezing More from the Stream : Learning Representation Online for Streaming Reinforcement Learning

**link**: https://arxiv.org/pdf/2602.09396.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 在流强化学习（RL）中，转换在单次更新后立即被观察和丢弃。虽然这最小化了设备端应用的资源使用，但由于基于价值的损失alone难以从瞬态数据中提取有意义的表示，导致智能体样本效率低下。本文提出将自预测表示（SPR）扩展到流处理管道，以最大化每个观察帧的效用。然而，由于流机制引起的高度相关样本，naive应用辅助损失会导致训练不稳定性。因此，引入了相对于动量目标的正交梯度更新，并解决了流特定优化器引起的梯度冲突。通过在Atari、MinAtar和Octax套件上的验证，该方法系统地优于现有流基线。潜在空间分析（包括t-SNE可视化和有效秩测量）证实，该方法学习到更丰富的表示，弥合了因缺少重放缓冲区而导致的性能差距，同时保持足够高效以在少数CPU核心上训练。

---

### 12 Diffusion-Guided Pretraining for Brain Graph Foundation Models

**link**: https://arxiv.org/pdf/2602.09437.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 随着脑信号基础模型的兴趣增长，基于图的预训练已成为从连接组数据中学习可迁移表示的有前景范式。然而，现有的对比和掩码自编码器方法通常依赖naive的随机删除或掩码进行增强，这不适合脑图和超图，因为它会破坏语义上有意义的连接模式。此外，常用的图级读出和重建方案无法捕获全局结构信息，限制了学习表示的鲁棒性。本文提出了一个统一的基于扩散的预训练框架，解决了这两个限制。首先，扩散用于指导结构感知的删除和掩码策略，保留脑图语义同时维持有效的预训练多样性。其次，扩散通过允许图嵌入和掩码节点从全局相关区域聚合信息，实现拓扑感知的图级读出和节点级全局重建。在涉及多种精神障碍和脑图谱的多个神经影像数据集上的广泛实验证明了一致的性能改进，涉及潜在空间中的表示学习。

---

### 13 Listen to the Layers: Mitigating Hallucinations with Inter-Layer Disagreement

**link**: https://arxiv.org/pdf/2602.09486.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 预训练大型语言模型（LLMs）容易生成流畅但事实不正确的文本——这种现象称为幻觉，破坏了它们在下游任务中的可靠性和实用性。本文假设生成文本片段的事实性与其在模型内部层中的表示不稳定性相关。基于此，提出了CoCoA（Confusion and Consistency Aware）解码器，一种新颖的无训练解码算法，通过在推理时监听中间层的这些信号来减轻幻觉。提出了两个指标来量化中间层中的这种不稳定性，并使用它来惩罚表现出高度内部混淆的输出，从而引导模型生成更内部一致和事实基础的输出。进一步提出了自信息门控变体CoCoA-SIG，动态调节此惩罚以选择性地针对高惊喜、不稳定的生成。在问答、摘要和代码生成等多种任务上的广泛实验表明，CoCoA显著提高了多个模型家族的事实正确性。通过利用模型内在信号，CoCoA提供了一种有效且广泛适用的方法，在推理时增强LLMs的可信度，涉及潜在推理和潜在空间分析。

---

### 14 Physics-informed diffusion models in spectral space

**link**: https://arxiv.org/pdf/2602.09708.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 本文提出了一种将生成潜在扩散模型与物理知情机器学习相结合的方法，用于生成受部分观测条件约束的参数化偏微分方程（PDE）解，包括正问题和反问题。该方法通过谱表示的潜在空间中的扩散过程来学习PDE参数和解的联合分布，实现了显著的降维并确保函数空间中的过程满足PDE算子的定义条件。在推理过程中，通过扩散后验采样并在每个扩散步骤应用基于Adam的更新来强制执行物理约束和测量条件。实验结果表明，该方法在泊松方程、亥姆霍兹方程和不可压缩Navier-Stokes方程上的准确性和计算效率优于现有基于扩散的PDE求解器。

---

### 15 Flexible Entropy Control in RLVR with Gradient-Preserving Perspective

**link**: https://arxiv.org/pdf/2602.09782.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 强化学习与可验证奖励（RLVR）已成为增强大型语言模型（LLMs）推理能力的关键方法。然而，持续训练常导致策略熵崩溃，表现为熵快速衰减、过早过度自信、输出多样性降低及梯度消失。本文从梯度保持裁剪的角度重塑RL中的熵控制，理论和实证验证了特定重要性采样比率区域对熵增长和减少的贡献，并基于此引入动态裁剪阈值的调节机制，设计了包括先增后减、减增减和振荡衰减等动态熵控制策略。实验结果表明，这些策略有效缓解了熵崩溃，在多个基准上实现了更优性能。

---

### 16 Decomposing Reasoning Efficiency in Large Language Models

**link**: https://arxiv.org/pdf/2602.09805.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 针对推理训练的大型语言模型在推理标记与准确性之间的权衡问题，本文提出了一个可追踪的框架，将标记效率分解为可解释的因素：固定标记预算下的完成度（避免截断）、给定完成度的条件正确性以及冗长性（标记使用量）。当基准元数据提供每个实例的工作负载代理时，进一步将冗长性分解为平均verbalization开销（每工作单元的标记数）和捕获开销如何随任务工作负载扩展的耦合系数。当推理轨迹可用时，添加确定性轨迹质量度量（接地性、重复性、提示复制）以区分退化循环与冗长但参与的推理，避免人工标注和LLM评判。在CogniLoad上对25个模型的评估表明，准确性和标记效率排名存在差异（Spearman ρ=0.63），效率差距常由条件正确性驱动，且verbalization开销变化约9倍（与模型规模弱相关）。该分解揭示了不同的瓶颈特征，为效率干预提供指导。

---

### 17 Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices

**link**: https://arxiv.org/pdf/2602.09802.pdf
**date**: 2026-02-11
**keywords**: LLM Rec
**abs**: 随着大型语言模型（LLMs）在旅行助手和购买支持等应用中的日益普及，它们常需代表用户在无客观正确答案的场景下做主观选择。本文在旅行助手情境中，通过呈现选择困境并利用多项logit模型分析LLM响应，推导隐含的支付意愿（WTP）估计，并与经济学文献中的人类基准值比较。研究还考察了提供用户过去选择信息和基于角色提示等现实条件对模型行为的影响。结果显示，较大的LLM虽能得出有意义的WTP值，但存在属性层面的系统性偏差，且总体高估人类WTP，尤其在引入昂贵选项或商业角色时。以用户对廉价选项的先前偏好为条件，可使估值更接近人类基准。该研究凸显了LLM用于主观决策支持的潜力与局限，强调了实际部署中模型选择、提示设计和用户表示的重要性。

---

### 18 Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning

**link**: https://arxiv.org/pdf/2602.09945.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 临床决策支持需正确答案与临床有效推理兼具。本文提出差分推理学习（DRL）框架，通过学习推理差异改进临床代理。该框架从参考推理依据（如医生撰写的临床理由、指南或更优模型输出）和代理的自由形式思维链（CoT）中提取推理图（有向无环图），进行临床加权图编辑距离（GED）差异分析。利用LLM作为评判者对齐语义等效节点并诊断图间差异，将图级差异诊断转换为自然语言指令存储于差分推理知识库（DR-KB）。推理时通过检索增强生成（RAG）检索前k条指令增强提示，修补逻辑差距。在开放医疗问答基准和内部临床数据的再入院预测任务上，该方法优于基线，提升了答案准确性和推理保真度。消融研究证实注入参考推理依据和前k检索策略的增益，临床医生审查进一步验证了其有效性，表明DRL支持复杂推理场景中更可靠的临床决策，并在有限token预算下提供实用部署机制。

---

### 19 ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference

**link**: https://arxiv.org/pdf/2602.10004.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 大型推理模型（LRMs）凭借长思维链生成实现优异性能，但常在得出正确答案后仍进行冗余推理，浪费计算资源。本文提出ESTAR（Early-Stopping for Token-Aware Reasoning），通过检测并减少推理冗余提升效率且不牺牲准确性。该方法结合三部分：（1）基于轨迹的分类器识别安全停止推理时机；（2）监督微调使LRMs生成自有的<stop>信号；（3）<stop>感知强化学习在自生成停止点截断展开并采用计算感知奖励。在四个推理数据集上的实验表明，ESTAR将推理长度减少约3.7倍（从4799降至1290），同时保持准确率（74.9% vs 74.2%），并具备强跨域泛化能力。结果证明早停机制是改进LRMs推理效率的简单有效方法。

---

### 20 Chain of Mindset: Reasoning with Adaptive Cognitive Modes

**link**: https://arxiv.org/pdf/2602.10063.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 人类解决问题时会整合多种思维模式，而非依赖单一模式。现有LLM推理方法却陷入固定思维模式的陷阱，忽视同一问题不同阶段需不同思维模式的需求，限制了模型智能提升。为此，本文提出Chain of Mindset（CoM）——一种无需训练的智能体框架，实现步骤级自适应思维模式编排。CoM将推理分解为空间型、收敛型、发散型和算法型四种功能异质的思维模式，由元智能体根据推理状态动态选择最优模式，双向上下文门过滤跨模块信息流以保证效率。在数学、代码生成、科学问答和空间推理等六个挑战性基准上的实验显示，CoM性能优于最强基线，在Qwen3-VL-32B-Instruct和Gemini-2.0-Flash上总体准确率分别提升4.96%和4.72%，同时平衡推理效率。

---

### 21 Step-resolved data attribution for looped transformers

**link**: https://arxiv.org/pdf/2602.10097.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 本文研究了单个训练样本如何影响循环Transformer的内部计算，其中共享块通过τ次递归迭代实现潜在推理。现有训练数据影响估计方法（如TracIn）会聚合所有循环迭代的影响，掩盖了训练样本在递归计算过程中的关键作用。为此，作者提出了分步分解影响（SDI）方法，通过展开递归计算图将TracIn分解为长度为τ的影响轨迹，实现对特定循环迭代的影响归因。为使SDI在Transformer规模上可行，还提出了TensorSketch实现，无需存储每个样本的梯度。在循环GPT风格模型和算法推理任务上的实验表明，SDI具有良好的扩展性，能匹配全梯度基线且误差低，并支持对潜在推理过程进行分步洞察的数据归因和可解释性任务。

---

### 22 LLMs Encode Their Failures: Predicting Success from Pre-Generation Activations

**link**: https://arxiv.org/pdf/2602.09924.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 研究探讨了大型语言模型（LLMs）在生成前的内部表示中是否包含成功可能性的信号。通过训练线性探针分析生成前的激活状态，预测数学和编码任务的成功率，其性能显著优于问题长度、TF-IDF等表面特征。实验表明，模型编码了特定于模型的难度概念，且与人类难度感知存在差异，这种差异随推理复杂度增加而扩大。该信号可用于指导高效推理，例如通过路由查询减少70%的计算成本，同时保持性能接近最佳模型。

---

### 23 Supervised Metric Regularization Through Alternating Optimization for Multi-Regime Physics-Informed Neural Networks

**link**: https://arxiv.org/pdf/2602.09980.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 针对参数化动态系统在尖锐状态转换（如分岔）时的建模挑战，提出了拓扑感知物理信息神经网络（TAPINN）。该方法通过监督度量正则化结构化潜在空间，将物理参数映射到反映状态分离的潜在状态，缓解了标准PINNs的频谱偏差和模式崩溃问题。在Duffing振荡器实验中，TAPINN实现了49%的物理残差降低，梯度方差比多输出Sobolev误差基线低2.18倍，参数数量比超网络替代方案少5倍。

---

### 24 Online Monitoring Framework for Automotive Time Series Data using JEPA Embeddings

**link**: https://arxiv.org/pdf/2602.09985.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 提出了一种基于JEPA（Joint Embedding Predictive Architecture）嵌入的在线监控框架，用于自动驾驶时间序列数据的异常检测。该框架通过自监督预测任务将对象数据转换为潜在表示空间，无需异常标签即可训练。实验表明，JEPA生成的富表达嵌入能有效支持异常检测方法，在nuScenes真实世界数据集上验证了其识别对象状态表示异常的能力。

---

### 25 ADORA: Training Reasoning Models with Dynamic Advantage Estimation on Reinforcement Learning

**link**: https://arxiv.org/pdf/2602.10019.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 针对强化学习中推理模型训练的信用分配效率问题，提出ADORA框架。该框架通过动态优势估计（基于在线模型rollout的样本效用分类）优化策略更新，增强长推理能力。在几何和数学任务中，ADORA显著提升性能，收敛速度更快且学习稳定性更高，无需敏感超参数调优。其核心在于通过动态调整优势函数权重，使模型优先学习更具信息价值的经验，属于潜在推理领域的优化方法。

---

### 26 Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference

**link**: https://arxiv.org/pdf/2602.10021.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 提出DRIFT双模型架构以解决大型语言模型（LLMs）整合动态知识的挑战。该框架将知识提取与推理过程解耦：轻量级知识模型将文档块压缩为隐式事实令牌（implicit fact tokens）——一种映射到推理模型嵌入空间的潜在表示，替代冗余文本。实验表明，DRIFT在长上下文任务中显著提升性能，保留关键推理链的同时缩短上下文长度，为潜在推理提供了高效范式。

---

### 27 The Laplacian Mechanism Improves Transformers by Reshaping Token Geometry

**link**: https://arxiv.org/pdf/2602.09297.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: Transformer利用注意力机制、残差连接和层归一化来控制token表示的方差。本文提出将注意力机制修改为拉普拉斯机制，使模型能更直接地控制token方差，并推测这有助于Transformer实现理想的token几何结构。为验证该推测，研究首先表明，将拉普拉斯机制融入Transformer后，在计算机视觉和语言领域的多个基准测试中均实现了持续改进。接着，通过主成分分析、余弦相似度度量、方差分析和神经坍缩度量等工具，研究了拉普拉斯机制对token表示几何结构的影响。结果显示，拉普拉斯机制将token嵌入重塑为具有最大可分离性的几何结构：token按类别坍缩，且类别均值呈现神经坍缩现象。

---

### 28 ML-DCN: Masked Low-Rank Deep Crossing Network Towards Scalable Ads Click-through Rate Prediction at Pinterest

**link**: https://arxiv.org/pdf/2602.09194.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 深度学习推荐系统依赖特征交互模块来建模稀疏类别特征与稠密特征之间的复杂用户-物品关系。在大规模广告排序场景中，提升模型容量虽能改善预测性能和业务指标，但服务预算对延迟和计算量有严格限制。本文提出ML-DCN，一种将实例条件掩码集成到低秩交叉层的交互模块，可在保持计算效率的同时实现对显著交互方向的逐例选择与放大。该架构结合了DCNv2和MaskNet的优势，能随计算资源增加高效扩展，并在Pinterest广告数据集上实现了优于现有方法的AUC-FLOPs权衡。在线A/B测试显示其关键广告指标（如CTR和点击质量）显著提升，并已部署到生产系统且服务成本无额外增加。

---

### 29 Barycentric alignment for instance-level comparison of neural representations

**link**: https://arxiv.org/pdf/2602.09225.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 跨神经网络比较表示具有挑战性，因为表示存在对称性（如单元的任意重排或激活空间的旋转），这些对称性会掩盖模型间的潜在等价性。本文引入重心对齐框架，通过消除这些干扰对称性来构建跨多个模型的通用嵌入空间。与现有汇总整个刺激集关系的相似性度量不同，该框架支持在单个刺激级别定义相似性，揭示不同模型间表示收敛或发散的输入。研究发现，独立学习的视觉和语言表示已共享足够的几何结构，经后验对齐后可实现接近对比训练模型的跨模态比较性能。

---

### 30 Beyond the Unit Hypersphere: Embedding Magnitude in Contrastive Learning

**link**: https://arxiv.org/pdf/2602.09229.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 余弦相似度在对比学习中应用广泛，但其隐含假设嵌入幅度是噪声。本文通过文本和视觉模型的系统实验发现：1)文本检索中输出（文档）幅度与相关性显著相关（Cohen's d达1.80），在推理密集型任务上增益最大；2)输入和输出幅度作用不对称：输出幅度直接缩放相似度分数，输入幅度调节训练动态；3)幅度学习有利于非对称任务（文本检索、RAG）但损害对称任务（STS、图文对齐）。提出任务对称性原则：余弦与点积的选择取决于任务是否存在输入角色差异，移除不必要的归一化约束可实现无成本性能提升。

---

### 31 Towards Uniformity and Alignment for Multimodal Representation Learning

**link**: https://arxiv.org/pdf/2602.09507.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 多模态表示学习旨在构建一个共享嵌入空间，使异构模态在语义上对齐。尽管取得了良好的实证结果，但基于InfoNCE的目标函数引入了固有的冲突，导致模态间存在分布差距。在这项工作中，我们识别了多模态场景下的两种冲突，且随着模态数量的增加，这两种冲突会加剧：（i）对齐-均匀性冲突，即均匀性的排斥作用会破坏成对对齐；（ii）内部对齐冲突，即对齐多个模态会引发竞争性的对齐方向。为解决这些问题，我们提出了一种用于多模态表示的对齐与均匀性的原则性解耦方法，提供了一种无冲突的多模态学习方案，无需特定任务模块即可同时支持判别式和生成式应用。我们还提供了理论保证，证明我们的方法可作为多个模态分布上全局Hölder散度的有效代理，从而减少模态间的分布差距。在检索和UnCLIP风格生成任务上的大量实验证明了持续的性能提升。

---

### 32 Reward Modeling for Reinforcement Learning-Based LLM Reasoning: Design, Challenges, and Evaluation

**link**: https://arxiv.org/pdf/2602.09305.pdf
**date**: 2026-02-11
**keywords**: cs.LG, latent reasoning
**abs**: 大型语言模型（LLMs）展现出变革性潜力，但其推理能力仍不一致且不可靠。基于强化学习（RL）的微调是改进的关键机制，但其有效性根本上由奖励设计决定。尽管奖励建模很重要，但它与LLM核心挑战（如评估偏差、幻觉、分布偏移和高效学习）之间的关系仍未被充分理解。本研究认为，奖励建模不仅仅是实现细节，而是推理对齐的核心架构，它塑造模型学习的内容、泛化方式以及输出是否可信赖。我们引入推理对齐强化学习（RARL），这是一个统一框架，系统化了多步推理的各种奖励范式。在此框架内，我们提出了奖励机制的分类法，分析了奖励黑客行为作为普遍存在的失败模式，并研究了奖励信号如何统一从推理时扩展到幻觉缓解等挑战。我们进一步批判性地评估了现有基准，强调了数据污染和奖励错位等漏洞，并概述了更稳健评估的方向。通过整合碎片化的研究线索并阐明奖励设计与基本推理能力之间的相互作用，本研究为构建稳健、可验证和可信赖的推理模型提供了基础路线图。

---

### 33 Latent Poincaré Shaping for Agentic Reinforcement Learning

**link**: https://arxiv.org/pdf/2602.09375.pdf
**date**: 2026-02-11
**keywords**: cs.LG, latent space
**abs**: 我们提出了LaPha，一种在庞加莱（Poincaré）latent空间中训练类AlphaZero的LLM智能体的方法。在LaPha下，搜索过程可被可视化为以提示为根、从原点向外生长至庞加莱球边界的树，其中负曲率随半径提供指数级增长的容量。利用双曲测地距离与规则验证的正确性，我们定义了节点势能，并通过势能差分配密集的过程奖励。我们进一步在同一共享latent空间上附加轻量级价值头，实现了几乎无额外开销的自引导测试时扩展。在MATH-500上，LaPha将Qwen2.5-Math-1.5B的准确率从66.0%提升至88.2%。借助价值头引导的搜索，LaPha-1.5B在AIME'24上达到56.7%的准确率，LaPha-7B在AIME'24上进一步达到60.0%，在AIME'25上达到53.3%。

---

### 34 EcoGym: Evaluating LLMs for Long-Horizon Plan-and-Execute in Interactive Economies

**link**: https://arxiv.org/pdf/2602.09514.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 长期规划被广泛认为是基于LLM的自主智能体的核心能力；然而，当前的评估框架大多具有片段式、领域特定性，或在持久经济动态中的基础不够充分。我们引入了EcoGym，一个用于交互式经济中连续规划与执行决策的通用基准。EcoGym包含三个不同的环境：售货、自由职业和运营，通过标准化接口在统一的决策过程中实现，并在有效无界的时间范围内（评估中365天循环可达1000+步骤）进行预算化行动。EcoGym的评估基于与业务相关的结果（如净值、收入和日活跃用户数），旨在评估在部分可观测性和随机性下的长期战略一致性和鲁棒性。对十一个领先LLM的实验揭示了一个系统性矛盾：没有单一模型在所有三个场景中占主导地位。关键的是，我们发现模型在高层策略或高效行动执行方面表现出显著的次优性。EcoGym作为一个开放、可扩展的测试平台发布，用于透明的长期智能体评估以及研究现实经济环境中的可控性-效用权衡。

---

### 35 Comprehensive Comparison of RAG Methods Across Multi-Domain Conversational QA

**link**: https://arxiv.org/pdf/2602.09552.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 对话式问答越来越依赖检索增强生成（RAG）将大型语言模型（LLM）基于外部知识。然而，大多数现有研究孤立地评估RAG方法，且主要关注单轮场景。本文解决了在多轮对话式问答中缺乏对RAG方法系统比较的问题，其中对话历史、指代消解和用户意图的转变显著增加了检索的复杂性。我们在八个跨多个领域的不同对话式问答数据集上，对基础和高级RAG方法进行了全面的实证研究。通过统一的实验设置，我们使用生成器和检索指标评估检索质量和答案生成，并分析性能如何随着对话轮次演变。结果表明，稳健且简单的方法（如重排序、混合BM25和HyDE）始终优于基础RAG。相比之下，一些高级技术未能带来增益，甚至可能使性能低于无RAG基线。我们进一步证明，数据集特征和对话长度强烈影响检索效果，解释了为何没有单一的RAG策略能在所有设置中占主导地位。总体而言，我们的研究结果表明，有效的对话式RAG较少依赖方法复杂性，而更多依赖检索策略与数据集结构之间的对齐。我们发布了所使用的代码。

---

### 36 ECG-IMN: Interpretable Mesomorphic Neural Networks for 12-Lead Electrocardiogram Interpretation

**link**: https://arxiv.org/pdf/2602.09566.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 深度学习在自动化心电图（ECG）诊断中已达到专家级性能，但其“黑箱”性质阻碍了其临床部署。对医疗AI的信任不仅需要高精度，还需要对驱动预测的特定生理特征的透明度。现有的ECG可解释性方法通常依赖事后近似（如Grad-CAM和SHAP），这些方法可能不稳定、计算成本高，且不忠实于模型实际的决策过程。在这项工作中，我们提出了ECG-IMN，一种专为高分辨率12导联ECG分类设计的可解释介晶神经网络。与标准分类器不同，ECG-IMN作为超网络运行：深度卷积主干为每个输入样本生成严格线性模型的参数。这种架构强制内在可解释性，因为决策逻辑在数学上是透明的，生成的权重（W）作为精确的高分辨率特征归因图。我们引入了一个过渡解码器，能有效将潜在特征映射到样本特定权重，实现病理证据（如ST段抬高、T波倒置）在时间和导联维度上的精确定位。我们在PTB-XL数据集上对分类任务评估了我们的方法，表明ECG-IMN实现了具有竞争力的预测性能（AUROC与黑箱基线相当），同时提供忠实的、实例特定的解释。通过明确将参数生成与预测执行解耦，我们的框架弥合了深度学习能力与临床可信度之间的差距，为“白箱”心脏诊断提供了一条原则性路径。

---

### 37 LEMUR: A Corpus for Robust Fine-Tuning of Multilingual Law Embedding Models for Retrieval

**link**: https://arxiv.org/pdf/2602.09570.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 大型语言模型（LLM）越来越多地用于获取法律信息。然而，它们在多语言法律环境中的部署受到不可靠检索和缺乏领域适配的开放嵌入模型的限制。特别是，现有的多语言法律语料库并非为语义检索设计，且基于PDF的立法来源由于文本提取不完善而引入大量噪声。为解决这些挑战，我们引入LEMUR，一个大规模多语言欧盟环境立法语料库，由24,953份官方EUR-Lex PDF文档构建，涵盖25种语言。我们通过使用词汇内容分数（LCS）测量与权威HTML版本的词汇一致性，来量化PDF到文本转换的保真度。基于LEMUR，我们在单语和双语设置中使用对比目标微调了三个最先进的多语言嵌入模型，反映了现实的法律检索场景。在低资源和高资源语言上的实验表明，法律领域微调相对于强基线一致提高了Top-k检索accuracy，对低资源语言的增益尤为显著。跨语言评估显示，这些改进可迁移到未见过的语言，表明微调主要增强了语言无关的、内容级别的法律表示，而非特定语言线索。我们发布了代码。

---

### 38 On the Optimal Reasoning Length for RL-Trained Language Models

**link**: https://arxiv.org/pdf/2602.09591.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 强化学习显著提高了大型语言模型的推理能力，但也倾向于延长思维链输出，并增加训练和推理期间的计算成本。尽管已提出长度控制方法，但对于平衡效率和性能的最佳输出长度仍不明确。在这项工作中，我们在两个模型（Qwen3-1.7B Base和DeepSeek-R1-Distill-Qwen-1.5B）上比较了几种长度控制方法。结果表明，长度惩罚可能阻碍推理能力的获取，而适当调整的长度控制可以提高具有强先验推理能力模型的效率。通过将先前工作扩展到RL训练的策略，我们确定了两种失败模式：1）长输出增加离散度，2）短输出导致思考不足。

---

### 39 Why Linear Interpretability Works: Invariant Subspaces as a Result of Architectural Constraints

**link**: https://arxiv.org/pdf/2602.09783.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 线性探针和稀疏自编码器能够从Transformer表示中恢复有意义的结构，但其成功原因在深度非线性系统中尚不明确。本文表明这不仅是经验规律，更是架构必要性的结果：Transformer通过线性接口（如注意力OV电路、解嵌入矩阵）传递信息，任何通过此类接口解码的语义特征都必须占据上下文不变的线性子空间。作者形式化了“不变子空间必要性”定理，并推导出“自引用特性”：令牌直接提供其相关特征的几何方向，无需标记数据或学习探针即可零样本识别语义结构。在八个分类任务和四个模型家族上的实证验证证实了类别令牌与语义相关实例之间的对齐。该框架为线性可解释性方法的有效性提供了原则性的架构解释，统一了线性探针和稀疏自编码器。

---

### 40 Circuit Fingerprints: How Answer Tokens Encode Their Geometrical Path

**link**: https://arxiv.org/pdf/2602.09784.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: Transformer中的电路发现和激活引导是两个独立的研究方向，但均在同一表示空间中运作。本文提出它们遵循单一几何原理：孤立处理的答案令牌编码了产生它们的方向。这一“电路指纹”假设使得无需梯度或因果干预即可进行电路发现——仅通过几何对齐就能恢复与基于梯度方法相当的结构。在标准基准（IOI、SVA、MCQA）上的四个模型家族验证表明，其电路发现性能与基于梯度的方法相当。识别电路组件的方向同样能够实现受控引导——在情感分类任务中达到69.8%的准确率（指令提示为53.1%），同时保持事实准确性。这种读写二元性揭示了Transformer电路本质上是几何结构：可解释性和可控性是同一对象的两个方面。

---

### 41 When Less is More: The LLM Scaling Paradox in Context Compression

**link**: https://arxiv.org/pdf/2602.09789.pdf
**date**: 2026-02-11
**keywords**: LLM Memory
**abs**: 长期以来，扩大模型参数一直是一种流行的训练范式，其假设是更大的模型会产生更优的生成能力。然而，在压缩器-解码器设置中的有损上下文压缩下，我们观察到一种规模-保真度悖论：增加压缩器大小虽然会降低训练损失，但可能会降低重建上下文的忠实度。通过在0.6B到90B的模型上进行广泛实验，我们发现这种悖论源于两个主要因素：1) 知识覆盖：更大的模型越来越多地用自身的先验信念替换源事实，例如“白色草莓”→“红色草莓”；2) 语义漂移：更大的模型倾向于释义或重组内容而非逐字再现，例如“Alice打了Bob”→“Bob打了Alice”。通过固定模型大小，我们反思了压缩上下文表示的涌现特性。结果表明，问题不在于参数数量本身，而在于伴随规模扩大的过度语义容量和放大的生成不确定性。具体而言，上下文嵌入秩的增加促进了先验知识的侵入，而标记预测分布的更高熵则促进了重写。我们的结果补充了现有对上下文压缩范式的评估，揭示了在开放式生成中忠实保留的缩放定律的失效。

---

### 42 Answer First, Reason Later: Aligning Search Relevance via Mode-Balanced Reinforcement Learning

**link**: https://arxiv.org/pdf/2602.10006.pdf
**date**: 2026-02-11
**keywords**: latent reasoning, LLM Rec
**abs**: 构建一个既实现低延迟又具有高性能的搜索相关性模型是搜索行业的长期挑战。为了满足在线系统毫秒级响应要求，同时保留大型语言模型（LLMs）的可解释推理轨迹，我们提出了一种新颖的“先回答，后推理（AFRL）”范式。该范式要求模型在第一个标记中输出确定的相关性分数，随后输出结构化的逻辑解释。受推理模型成功的启发，我们采用“监督微调（SFT）+强化学习（RL）”pipeline来实现AFRL。然而，直接应用现有RL训练在搜索相关性任务中往往会导致模式崩溃，即模型为了追求高奖励而忘记复杂的长尾规则。从信息论角度来看：RL本质上最小化反向KL散度，倾向于寻找概率峰值（模式寻求），容易出现“奖励黑客”现象；而SFT最小化正向KL散度，迫使模型覆盖数据分布（模式覆盖），并有效锚定专家规则。基于此见解，我们提出了一种模式平衡优化策略，将SFT辅助损失纳入Stepwise-GRPO训练中以平衡这两种特性。此外，我们构建了自动化指令进化系统和多阶段课程，以确保专家级数据质量。大量实验表明，我们的32B教师模型达到了最先进的性能。此外，AFRL架构实现了高效的知识蒸馏，成功将专家级逻辑迁移到0.6B模型，从而协调了推理深度与部署延迟。

---

### 43 A Task-Centric Theory for Iterative Self-Improvement with Easy-to-Hard Curricula

**link**: https://arxiv.org/pdf/2602.10014.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 迭代自我改进通过在大型语言模型（LLM）自身生成的奖励验证输出上对其进行微调来实现。与自我改进的实证成功相比，这种生成式、迭代过程在实际有限样本设置中的理论基础仍然有限。我们通过将每一轮自我改进建模为对奖励过滤分布的最大似然微调，并推导期望奖励的有限样本保证，朝着这一目标取得进展。我们的分析揭示了一个明确的反馈循环：更好的模型在每次迭代中接受更多数据，支持持续的自我改进，同时解释了这种改进最终的饱和。通过考虑具有多个难度级别的推理任务，采用以任务为中心的视角，我们进一步证明了在模型初始化、任务难度和样本预算方面的可量化条件，其中从易到难的课程学习可证明比在固定任务混合上训练获得更好的保证。我们的分析通过蒙特卡洛模拟和基于图的推理任务的对照实验得到验证。

---

### 44 Effectiveness of Binary Autoencoders for QUBO-Based Optimization Problems

**link**: https://arxiv.org/pdf/2602.10037.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 在黑盒组合优化中，目标函数评估通常成本高昂，因此必须在有限预算下找到高质量解决方案。基于量子退火的因子分解机（FMQA）从已评估样本构建二次代理模型，并在伊辛机上对其进行优化。然而，FMQA需要二进制决策变量，对于整数排列等非二进制结构，二进制编码的选择会显著影响搜索效率。如果编码未能反映原始邻域结构，小的汉明距离移动可能无法对应原始解空间中有意义的修改，且约束问题会产生许多浪费评估资源的不可行候选解。近期研究将FMQA与二进制自编码器（bAE）相结合，该自编码器从可行解中学习紧凑的二进制latent code，但其性能提升背后的机制尚不明确。本文以小型旅行商问题为可解释测试平台，表明bAE能准确重构可行路径，且与相似压缩率下的手动设计编码相比，能更好地将路径距离与latent汉明距离对齐，在小比特翻转下产生更平滑的邻域，并减少局部最优解数量。这些几何特性解释了为何bAE+FMQA能更快提高近似比，同时在整个优化过程中保持可行性，并为黑盒优化的latent表示设计提供指导。

---

### 45 Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders

**link**: https://arxiv.org/pdf/2602.10099.pdf
**date**: 2026-02-11
**keywords**: cs.LG
**abs**: 利用表示编码器进行生成建模为高效、高保真合成提供了途径。然而，标准扩散Transformer无法直接在这些表示上收敛。尽管近期研究将此归因于容量瓶颈并提出计算昂贵的扩散Transformer宽度扩展方案，但本文证明失败的根本原因在于几何因素。我们发现“几何干扰”是根源：标准欧几里得流匹配迫使概率路径穿过表示编码器的超球面特征空间的低密度内部，而非沿流形表面移动。为解决此问题，本文提出带雅可比正则化的黎曼流匹配（RJF）。通过将生成过程约束在流形测地线上并校正曲率诱导的误差传播，RJF使标准扩散Transformer架构无需宽度扩展即可收敛。我们的方法RJF使标准DiT-B架构（1.31亿参数）有效收敛，在先前方法无法收敛的情况下实现3.37的FID。

---

### 46 Mutual Information Collapse Explains Disentanglement Failure in $β$-VAEs

**link**: https://arxiv.org/pdf/2602.09277.pdf
**date**: 2026-02-11
**keywords**: stat.ML
**abs**: $β$-VAE是无监督解纠缠的基础框架，通过$β$调节latent分解与重构保真度之间的权衡。然而，经验表明解纠缠性能普遍呈现非单调趋势：MIG和SAP等基准通常在中等$β$时达到峰值，随正则化增强而下降。本文证明这种下降是根本的信息论失败，即强Kullback-Leibler压力以牺牲latent通道的语义信息量为代价促进边缘独立性。通过在线性高斯设置中形式化此机制，我们证明当$β>1$时，平稳性诱导的动力学触发编码器增益的谱收缩，导致latent因子互信息趋于零。为解决此问题，我们引入$λβ$-VAE，通过辅助$L_2$重构惩罚$λ$将正则化压力与信息崩溃解耦。在dSprites、Shapes3D和MPI3D-real上的大量实验证实，$λ>0$能在更宽的$β$范围内稳定解纠缠并恢复latent信息量，为变分推断骨干网络中的双参数正则化提供了原则性理论依据。

---

### 47 The Entropic Signature of Class Speciation in Diffusion Models

**link**: https://arxiv.org/pdf/2602.09651.pdf
**date**: 2026-02-11
**keywords**: latent space
**abs**: 扩散模型并非随时间均匀恢复语义结构，而是在狭窄范围内从语义模糊过渡到类别确定。本文表明，跟踪给定噪声状态下潜在语义变量的类别条件熵可作为这些过渡阶段的可靠标志。通过将熵限制在语义分区，还能在不同抽象层次解析语义决策。作者在高维高斯混合模型中分析了这种行为，并在EDM2-XS和Stable Diffusion 1.5上验证了方法，类别条件熵能一致隔离语义结构形成的关键噪声区域，还量化了引导如何随时间重新分配语义信息。该研究连接了扩散模型的信息论和统计物理视角，为时间局部控制提供了原则性基础。

---

### 48 Continual Learning for non-stationary regression via Memory-Efficient Replay

**link**: https://arxiv.org/pdf/2602.09720.pdf
**date**: 2026-02-11
**keywords**: LLM Memory
**abs**: 在工业4.0等动态环境中，数据流很少是静态的，而是不断变化，使得传统离线模型除非能快速适应新数据否则会过时。持续学习（CL）可解决此问题，允许系统逐步获取知识而无需从头重新训练的高昂成本。大多数持续学习研究集中在分类问题，很少涉及回归任务。本文提出首个基于原型的生成式重放框架，专为在线无任务持续回归设计。该方法定义了自适应输出空间离散化模型，实现了无需存储原始数据的基于原型的生成式重放。在多个基准数据集上的证据表明，该框架减少了遗忘，并提供了比其他最先进解决方案更稳定的性能。

---

### 49 Overview of PAN 2026: Voight-Kampff Generative AI Detection, Text Watermarking, Multi-Author Writing Style Analysis, Generative Plagiarism Detection, and Reasoning Trajectory Detection

**link**: https://arxiv.org/pdf/2602.09147.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: PAN研讨会旨在通过客观可重复的评估推进计算文体学和文本取证。2026年，PAN开展五项任务：（1）Voight-Kampff生成式AI检测，尤其在混合和模糊作者场景中；（2）文本水印，旨在发现新的并基准现有文本水印方案的鲁棒性；（3）多作者写作风格分析，旨在找到作者身份变化的位置；（4）生成式剽窃检测，针对生成文本与源文档之间的源检索和文本对齐；（5）推理轨迹检测，这是一项新任务，涉及LLM生成或人类编写的推理轨迹的源检测和安全检测。

---

### 50 TraceMem: Weaving Narrative Memory Schemata from User Conversational Traces

**link**: https://arxiv.org/pdf/2602.09712.pdf
**date**: 2026-02-11
**keywords**: cs.CL
**abs**: 大型语言模型（LLMs）在维持长期交互方面仍存在瓶颈，因其有限的上下文窗口难以处理随时间延伸的对话历史。现有记忆系统常将交互视为不连贯的片段，无法捕捉对话流的潜在叙事连贯性。本文提出TraceMem，这是一个受认知启发的框架，通过三阶段管道从用户对话轨迹中构建结构化的叙事记忆图式：（1）短期记忆处理，采用演绎式主题分割方法划分情节边界并提取语义表示；（2）突触记忆巩固，将情节总结为情景记忆，然后将其与语义一起提炼为用户特定轨迹；（3）系统记忆巩固，利用两阶段层次聚类将这些轨迹组织成统一主题下连贯且随时间演变的叙事线程。这些线程被封装到结构化的用户记忆卡中，形成叙事记忆图式。在记忆利用方面，提供了一种智能体搜索机制来增强推理过程。在LoCoMo基准上的评估表明，TraceMem凭借类脑架构实现了最先进的性能。分析显示，通过构建连贯的叙事，它在多跳推理和时间推理方面超越了基线，突显了其在深度叙事理解中的关键作用。此外，本文还对记忆系统进行了公开讨论，提出了该领域的观点和未来展望。

---

### 51 Breaking the Pre-Sampling Barrier: Activation-Informed Difficulty-Aware Self-Consistency

**link**: https://arxiv.org/pdf/2602.09438.pdf
**date**: 2026-02-11
**keywords**: latent space, latent reasoning
**abs**: 自一致性（SC）是一种有效的解码策略，通过生成多条思维链推理路径并通过多数投票选择最终答案来提高大型语言模型（LLMs）的推理性能。然而，由于需要大量样本，它存在显著的推理成本。为缓解此问题，提出了难度自适应自一致性（DSC），通过根据问题难度调整样本数量来减少简单问题的不必要标记使用。但DSC需要额外的模型调用和预采样来估计难度，且应用于每个数据集时需重复此过程，导致显著的计算开销。在本研究中，我们提出激活感知难度感知自一致性（ACTSC）以解决这些局限性。ACTSC利用前馈网络神经元激活中反映的内部难度信号构建轻量级难度估计探针，无需任何额外的标记生成或模型调用。该探针动态调整SC的样本数量，并可应用于新数据集，无需进行难度估计的预采样。为验证其有效性，我们在五个基准数据集上进行了实验。实验结果表明，ACTSC在保持与现有方法相当准确性的同时，有效降低了推理成本。

---

### 52 Where-to-Unmask: Ground-Truth-Guided Unmasking Order Learning for Masked Diffusion Language Models

**link**: https://arxiv.org/pdf/2602.09501.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 掩码扩散语言模型（MDLMs）通过迭代填充掩码标记生成文本，每一步需要两个耦合决策：要解掩码的位置（where-to-unmask）和要放置的标记（what-to-unmask）。虽然标准MDLM训练直接优化标记预测（what-to-unmask），但推理时的解掩码顺序（where-to-unmask）通常由启发式置信度度量确定或通过成本高昂的在线策略强化学习进行训练。为解决此问题，我们引入Gt-Margin，这是一种从真实标记导出的位置分数，定义为正确标记与其最强替代标记之间的概率差。Gt-Margin产生一种最优解掩码顺序，在每个部分掩码状态下优先处理更容易的位置。我们证明，利用这种最优解掩码顺序可显著提高最终生成质量，尤其是在逻辑推理基准测试上。基于此见解，我们通过排序学习训练一个有监督的解掩码规划器，以从掩码上下文中模仿最优顺序。所得规划器集成到标准MDLM采样中以选择解掩码位置，在不修改标记预测模型的情况下提高推理准确性。

---

### 53 From FusHa to Folk: Exploring Cross-Lingual Transfer in Arabic Language Models

**link**: https://arxiv.org/pdf/2602.09826.pdf
**date**: 2026-02-11
**keywords**: latent space
**abs**: 本文研究阿拉伯语模型的跨语言迁移能力，通过3项NLP任务的探测和表示相似性分析，探讨现代标准阿拉伯语（MSA）预训练模型向各地方言的迁移效果。结果表明，迁移效果在不同方言间存在显著差异，部分可由地理proximity解释；同时发现支持所有阿拉伯语方言的模型存在负干扰，质疑其方言相似性假设，对阿拉伯语模型的跨语言迁移提出挑战。研究涉及模型表示空间的相似性分析。

---

### 54 LLM Reasoning Predicts When Models Are Right: Evidence from Coding Classroom Discourse

**link**: https://arxiv.org/pdf/2602.09832.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 本文研究大型语言模型（LLM）生成的推理能否用于预测模型自身预测的正确性。通过分析30,300条课堂对话中的教师话语，利用TF-IDF编码LLM推理并训练监督分类器，发现随机森林分类器F1分数达0.83，能有效识别多数错误预测。研究还通过LIWC框架发现正确预测的推理具有因果语言特征，而错误推理更多依赖认知模糊表达，表明LLM推理可作为预测模型正确性的有效信号。

---

### 55 Steer2Edit: From Activation Steering to Component-Level Editing

**link**: https://arxiv.org/pdf/2602.09870.pdf
**date**: 2026-02-11
**keywords**: latent space
**abs**: 本文提出Steer2Edit框架，将推理时的激活转向向量转化为组件级权重编辑的诊断信号。该方法通过识别隐藏表示中的语义方向，选择性调整注意力头和MLP神经元的行为影响，实现无需训练的模型编辑。在安全对齐、幻觉缓解和推理效率任务中，Steer2Edit显著改善属性-效用权衡，例如在保持下游性能的同时提升安全性达17.2%，涉及潜在空间中语义方向的利用与模型组件编辑。

---

### 56 ATTNPO: Attention-Guided Process Supervision for Efficient Reasoning

**link**: https://arxiv.org/pdf/2602.09953.pdf
**date**: 2026-02-11
**keywords**: latent reasoning
**abs**: 本文提出ATTNPO框架，利用模型内在注意力信号进行步骤级信用分配，以解决推理模型的过度思考问题。通过识别关注关键步骤的特殊注意力头，该方法在抑制冗余推理的同时保留必要步骤，实现推理长度缩短与性能提升。实验表明，ATTNPO在9个基准任务上显著减少推理长度并提高性能，涉及注意力机制引导的潜在推理过程优化。
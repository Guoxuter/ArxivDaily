### 1 CEPAE: Conditional Entropy-Penalized Autoencoders for Time Series Counterfactuals

**link**: https://arxiv.org/pdf/2602.15546.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 本文提出了一种针对时间序列反事实推理的新方法CEPAE（条件熵惩罚自编码器）。该方法基于结构因果模型框架，通过在 latent space（潜在空间）中引入熵惩罚损失来鼓励数据表示的解耦。研究首先适配了变分自编码器和对抗自编码器用于时间序列反事实推理，然后提出的CEPAE在合成、半合成和真实世界数据集上的理论与实验验证中，均表现出优于其他方法的性能，对金融、医疗和市场营销等领域的决策具有重要意义。  

---

### 2 1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization

**link**: https://arxiv.org/pdf/2602.15563.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 量化感知训练（QAT）是减少LLM（大语言模型）内存占用（LLM Memory）的有效方法。本文针对低比特率下的QAT进行实证研究，发现基于k-means的权重量化优于整数格式，且能在标准硬件上高效实现。在固定推理内存预算下，1位量化权重在生成下游任务中实现了最佳性能，为LLM的内存优化提供了新的解决方案。  

---

### 3 Fast and Effective On-policy Distillation from Reasoning Prefixes

**link**: https://arxiv.org/pdf/2602.15260.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG, latent reasoning  
**abs**: 在线策略蒸馏（OPD）通过从学生模型采样轨迹并在 token 级别使用教师监督，避免了仅依赖可验证的终端奖励，且比离线策略蒸馏具有更好的泛化能力。但 OPD 在训练期间需要对学生策略进行昂贵的实时采样，尤其对于长响应，会大幅增加训练成本。研究发现，OPD 中的训练信号通常集中在每个输出的前缀部分，即使是短的教师生成前缀也能显著帮助学生产生正确答案。基于此，提出对 OPD 进行改进：仅对学生生成输出的前缀应用蒸馏目标，并在蒸馏期间提前终止每个采样。在 AI-for-Math 和域外基准测试集上的实验表明，在线策略前缀蒸馏在匹配完整 OPD 性能的同时，将训练 FLOP 降低了 2 倍至 47 倍。  

---

### 4 Complex-Valued Unitary Representations as Classification Heads for Improved Uncertainty Quantification in Deep Neural Networks

**link**: https://arxiv.org/pdf/2602.15283.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG, latent space  
**abs**: 现代深度神经网络虽具有较高的预测准确率，但校准性能较差，其置信度分数不能可靠反映正确的概率。本文提出一种受量子启发的分类头架构，将骨干网络特征投影到复值希尔伯特空间，并通过 Cayley 映射参数化的学习酉变换对其进行演化。通过控制混合实验设计（训练单个共享骨干网络并比较轻量级可互换头），分离复值酉表示对校准的影响。在 CIFAR-10 上的消融研究表明，酉幅度头（经 Cayley 酉变换演化的复特征，通过幅度和 softmax 读出）实现了 0.0146 的预期校准误差（ECE），比标准 softmax 头（0.0355）提高 2.4 倍，比温度缩放（0.0510）提高 3.5 倍。在 CIFAR-10H 人类不确定性基准上，波函数头实现了与人类软标签的最低 KL 散度（0.336），表明复值表示能更好地捕捉人类感知模糊性的结构。  

---

### 5 The Information Geometry of Softmax: Probing and Steering

**link**: https://arxiv.org/pdf/2602.15293.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG, latent space  
**abs**: 本文探讨 AI 系统如何将语义结构编码到其表示空间的几何结构中。核心观察是这些表示空间的自然几何应反映模型使用表示产生行为的方式。聚焦于定义 softmax 分布的表示这一重要特例，认为其自然几何是信息几何。研究信息几何在语义编码和线性表示假设中的作用，并开发“对偶转向”方法，利用线性探针稳健地将表示转向特定概念。理论证明对偶转向能最优修改目标概念，同时最小化对非目标概念的改变。实验表明对偶转向增强了概念操作的可控性和稳定性。  

---

### 6 Directional Reasoning Trajectory Change (DRTC): Identifying Critical Trace Segments in Reasoning Models

**link**: https://arxiv.org/pdf/2602.15332.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 理解语言模型如何进行长程推理仍是一个开放挑战。现有可解释性方法常突出与答案相关的标记或片段，但很少揭示模型在何处做出重要推理转向、哪些早期上下文触发这些转向，或突出显示的文本是否真正引导推理过程。本文引入方向推理轨迹变化(DRTC)框架，通过检测不确定性和分布偏移信号识别关键决策点，应用接收器端干预测量上下文元素对推理轨迹方向的影响。实验表明，方向影响在四个推理模型中高度集中，学习到的关键片段比随机片段干预效果更强，为理解上下文如何引导推理提供了因果基础的轨迹级视角。  

---

### 7 Discovering Implicit Large Language Model Alignment Objectives

**link**: https://arxiv.org/pdf/2602.15338.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 大语言模型(LLM)对齐依赖复杂的奖励信号，这些信号往往掩盖了被激励的具体行为，造成对齐偏差和奖励黑客攻击的重大风险。本文提出Obj-Disco框架，能自动将对齐奖励信号分解为人类可解释的自然语言目标的稀疏加权组合。该方法利用迭代贪婪算法分析训练检查点间的行为变化，识别并验证最能解释残余奖励信号的候选目标。在不同任务、模型大小和对齐算法上的广泛评估表明，该框架能持续捕获>90%的奖励行为，并成功识别与预期行为一起出现的潜在错位激励，为揭示LLM对齐中的隐式目标提供了关键工具。  

---

### 8 ER-MIA: Black-Box Adversarial Memory Injection Attacks on Long-Term Memory-Augmented Large Language Models

**link**: https://arxiv.org/pdf/2602.15344.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 大语言模型(LLMs)越来越多地通过长期记忆系统来克服有限的上下文窗口，实现跨交互的持续推理。然而，最近研究发现，记忆提供了额外的攻击面，使LLMs变得更加脆弱。本文首次系统研究了针对长期记忆增强型LLMs中基于相似性的检索机制的黑盒对抗性记忆注入攻击，提出ER-MIA统一框架，暴露了这种漏洞并形式化了两种现实攻击场景：基于内容的攻击和面向问题的攻击。在多个LLMs和长期记忆系统上的广泛实验表明，基于相似性的检索构成了基本的系统级漏洞，揭示了跨记忆设计和应用场景持续存在的安全风险。  

---

### 9 PolyNODE: Variable-dimension Neural ODEs on M-polyfolds

**link**: https://arxiv.org/pdf/2602.15128.pdf  
**date**: 2026-02-18  
**keywords**: latent space  
**abs**: 神经常微分方程（NODEs）是基于动力系统和流形上向量场生成的流的几何深度学习模型。尽管NODEs在流匹配等范式中已有诸多成功应用，但现有所有NODE模型均受限于流形维度所固有的固定维动力学。本文将NODEs扩展到M-多面体（一种可同时容纳变化维度和微分概念的空间），并引入PolyNODEs——几何深度学习中首个变维流基模型。作为示例应用，作者构建了具有维度瓶颈的显式M-多面体，并基于可穿过这些瓶颈的参数化向量场构建了PolyNODE自编码器。实验表明，PolyNODE模型能够被训练以解决这些空间中的重构任务，且输入的latent表示可以被提取并用于解决下游分类任务。  

---

### 10 Seeing to Generalize: How Visual Data Corrects Binding Shortcuts

**link**: https://arxiv.org/pdf/2602.15183.pdf  
**date**: 2026-02-18  
**keywords**: latent reasoning  
**abs**: 视觉语言模型（VLMs）旨在通过视觉能力扩展大型语言模型（LLMs），然而本研究观察到一个令人惊讶的现象：VLMs在纯文本任务（尤其是长上下文信息检索）上的表现可能优于其底层LLMs。通过构建受控的合成检索任务，研究发现仅在文本上训练的Transformer在分布内准确率完美，但分布外泛化能力差；而在同一任务的图像标记化版本上进行后续训练后，纯文本分布外性能几乎翻倍。机制可解释性表明，视觉训练改变了模型的内部绑定策略：纯文本训练鼓励位置捷径，而基于图像的训练通过空间平移不变性破坏这些捷径，迫使模型采用更鲁棒的符号绑定机制，即使在重新引入纯文本示例后该机制仍然存在。研究进一步表征了绑定策略在不同训练机制、视觉编码器和初始化中的变化，并表明在预训练LLM到VLM的过渡中会发生类似转变。这些发现表明，跨模态训练即使对于单模态任务也能增强推理和泛化能力。  

---

### 11 Logit Distance Bounds Representational Similarity

**link**: https://arxiv.org/pdf/2602.15438.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 对于包括自回归语言模型在内的广泛判别模型家族，可识别性结果表明，如果两个模型诱导相同的条件分布，则它们的内部表示在可逆线性变换下一致。本文探讨当分布接近而非相等时，类似结论是否近似成立。基于Nielsen等人（2025）的观察，即KL散度的接近不一定意味着高线性表示相似性，本文研究了一种基于logit差异的分布距离，并表明该距离的接近性确实能产生线性相似性保证。具体而言，本文定义了一种基于模型可识别性类的表示差异性度量，并证明其受logit距离的界限制。进一步表明，当模型概率远离零时，KL散度上界logit距离；但在实践中，所得界限未能提供非平凡控制。因此，基于KL的蒸馏可以匹配教师的预测，但可能无法保留线性表示属性，例如人类可解释概念的线性探针可恢复性。在合成和图像数据集的蒸馏实验中，基于logit距离的蒸馏产生的学生模型具有更高的线性表示相似性，并能更好地保留教师的线性可恢复概念。  

---

### 12 On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks

**link**: https://arxiv.org/pdf/2602.15460.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 大型语言模型和大型视觉语言模型中的推理集成最近显著提升了其能力。然而，推理模型的分布外泛化仍定义模糊且理解不足。本文提出了一个评估框架，以严格检验思维链（CoT）方法在简单规划任务上的泛化能力。具体而言，我们考虑一个基于网格的导航任务，模型被提供地图并必须输出一系列移动步骤，引导玩家从起始位置到达目标同时避开障碍物。该任务及其数据的多功能性允许我们使用不同的输入表示（视觉和文本）和CoT推理策略微调模型变体，并系统地在分布内（ID）和分布外（OOD）测试条件下进行评估。实验表明，虽然CoT推理在所有表示上都提高了分布内泛化，但分布外泛化（例如对更大地图）在大多数情况下仍非常有限（在控制与ID数据的平凡匹配时）。令人惊讶的是，我们发现结合多种文本格式的推理轨迹产生了最佳（且非平凡）的分布外泛化。最后，纯文本模型始终优于利用基于图像输入的模型，包括最近提出的依赖潜在空间推理的方法。  

---

### 13 Relative Geometry of Neural Forecasters: Linking Accuracy and Alignment in Learned Latent Geometry

**link**: https://arxiv.org/pdf/2602.15676.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 神经网络能够准确预测复杂的动态系统，然而它们如何在内部表示潜在几何结构仍知之甚少。本文通过表示对齐的视角研究神经预测器，引入基于锚点的、几何无关的相对嵌入，消除潜在空间中的旋转和缩放模糊性。通过在七个典型动态系统（从周期到混沌）上应用此框架，揭示了可重现的家族级结构：多层感知器与其他MLP对齐，循环网络与RNN对齐，而Transformer和回声状态网络尽管对齐较弱但仍能实现强预测。对齐通常与预测准确性相关，但高精度可以与低对齐共存。相对几何为比较模型家族如何内化和表示动态结构提供了简单、可重现的基础。  

---

### 14 CAMEL: An ECG Language Model for Forecasting Cardiac Events

**link**: https://arxiv.org/pdf/2602.15677.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 心电图(ECG)是心脏的电记录，对诊断心血管疾病至关重要。心电图语言模型(ELMs)最近成为ECG分类和报告生成的有前景框架。然而，当前模型无法预测未来心脏事件，尽管这对规划早期干预具有巨大临床价值。为解决这一差距，本文提出CAMEL，首个能够对较长信号持续时间进行推理的ELM，从而实现其预测能力。核心创新是专用ECG编码器，能够实现ECG信号与文本的交叉理解。使用成熟的LLM训练程序训练CAMEL，将LoRA适应与课程学习管道相结合，课程包括ECG分类、指标计算和多轮对话以引出推理。CAMEL在6个任务和9个数据集上展示了强大的零样本性能，包括新引入的用于预测心律失常的基准ECGForecastBench。CAMEL在分布内和分布外均达到或超过ELMs和全监督基线，在ECGBench上实现SOTA结果(+7.0%绝对平均增益)，在ECGForecastBench上比全监督模型高12.4%，比零样本ELMs高21.1%。  

---

### 15 GLM-5: from Vibe Coding to Agentic Engineering

**link**: https://arxiv.org/pdf/2602.15763.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 本文介绍了下一代基础模型GLM-5，旨在将编程范式从"氛围编码"过渡到智能体工程。该模型在其前身的智能体能力、推理和编码（ARC）基础上，采用DSA技术显著降低训练和推理成本，同时保持长上下文保真度。为提升模型对齐性和自主性，研究团队实现了新型异步强化学习基础设施，通过解耦生成与训练过程大幅提高训练后效率。此外，提出的异步智能体RL算法能更有效地从复杂、长周期交互中学习。实验表明，GLM-5在主要开放基准上达到最先进性能，尤其在现实世界编码任务中展现出前所未有的端到端软件工程能力，涉及LLM的长期上下文记忆（LLM Memory）和智能体推理（latent reasoning）机制。  

---

### 16 The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety

**link**: https://arxiv.org/pdf/2602.15799.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 本文揭示了在良性任务上微调对齐语言模型时，即使训练数据不含有害内容且开发者无恶意，安全护栏也会意外退化的现象。研究表明，主流解释中"微调更新应与高维参数空间中安全关键方向正交"的观点存在误导性——这种正交性在梯度下降动力学下结构不稳定并会崩溃。通过新颖的几何分析发现，对齐集中在具有尖锐曲率的低维子空间中，形成一阶方法无法检测或防御的脆弱结构。微调损失的曲率会产生二阶加速度，系统性地将参数轨迹导向对齐敏感区域。研究形式化了导致安全退化的"对齐不稳定性条件"，并建立四次方缩放定律：对齐损失随训练时间的四次方增长，由对齐几何的锐度和微调任务与安全关键参数间的曲率耦合强度决定。该研究从几何角度解释了LLM的潜在空间（latent space）特性对模型对齐的影响。  

---

### 17 CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing

**link**: https://arxiv.org/pdf/2602.15823.pdf  
**date**: 2026-02-18  
**keywords**: cs.LG  
**abs**: 本文针对大型语言模型（LLM）编辑中的能力保留挑战——成功改变目标行为的方法可能暗中破坏通用能力——提出了CrispEdit，一种可扩展且原则性的二阶编辑算法。该方法将能力保留作为显式约束，统一并推广了现有多种编辑方法。CrispEdit将编辑表述为约束优化问题，通过将编辑更新投影到能力损失 landscape 的低曲率子空间来强制执行约束。核心创新在于使用Bregman散度表达能力约束，其二次形式可精确产生高斯-牛顿海森矩阵，即使基础模型未训练至收敛。为实现LLM规模的高效二阶过程，研究采用Kronecker分解近似曲率（K-FAC）和利用Kronecker结构的新型无矩阵投影器，避免构造大规模投影矩阵。实验表明，在标准模型编辑基准上，CrispEdit实现了高编辑成功率，同时将能力退化平均控制在1%以下，显著优于现有方法，涉及LLM潜在空间（latent space）的低曲率子空间利用。  

---

### 18 The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems

**link**: https://arxiv.org/pdf/2602.15382.pdf  
**date**: 2026-02-18  
**keywords**: cs.CL  
**abs**: 多智能体系统（MAS）受限于离散文本通信的低效性，本文提出Vision Wormhole框架，利用视觉语言模型（VLM）的视觉接口实现模型无关的无文本通信。通过通用视觉编解码器将异质推理轨迹映射到共享连续潜在空间，并注入接收者的视觉通路，采用中心辐射拓扑减少对齐复杂度，通过无标签师生蒸馏使高速视觉通道与文本通路的推理模式对齐。实验表明，该方法在不同模型家族中减少了端到端时间，同时保持与文本通信相当的推理保真度。  

---

### 19 Recursive Concept Evolution for Compositional Reasoning in Large Language Models

**link**: https://arxiv.org/pdf/2602.15725.pdf  
**date**: 2026-02-18  
**keywords**: cs.AI  
**abs**: 大型语言模型在复杂推理任务上表现强劲，但在需要组合推理的基准（如ARC-AGI-2、GPQA等）上准确性显著下降。现有方法通过扩展token级搜索改进推理，但固定了模型的潜在表示空间。本文提出递归概念演化（RCE）框架，使预训练语言模型在推理时修改内部表示几何。RCE动态生成低维概念子空间，通过最小描述长度准则选择，合并协同子空间，并通过约束优化巩固，从而构建新抽象而非重组现有抽象。在Mistral-7B上的实验显示，RCE在多个组合推理基准上提升12-18个百分点，减少深度诱导误差。  

---

### 20 Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory

**link**: https://arxiv.org/pdf/2602.15313.pdf  
**date**: 2026-02-18  
**keywords**: cs.CL  
**abs**: AI 记忆，特别是模型如何组织和检索历史消息，对大型语言模型（LLMs）日益重要，但现有方法（如 RAG 和 Graph-RAG）主要通过基于相似性的机制检索记忆。尽管高效，但这种 System-1 式检索在需要全局推理或全面覆盖所有相关信息的场景中存在困难。本文提出 Mnemis，一种新颖的记忆框架，它将 System-1 相似性搜索与一种名为全局选择的互补 System-2 机制相结合。Mnemis 将记忆组织为用于相似性检索的基础图和支持语义层次结构自上而下遍历的层次图。通过结合两种检索路径的互补优势，Mnemis 检索出既语义相关又结构相关的记忆项。在长期记忆基准测试中，Mnemis 使用 GPT-4.1-mini 取得了最先进的性能，在 LoCoMo 上得分为 93.9，在 LongMemEval-S 上得分为 91.6。  

---

### 21 Causal Effect Estimation with Latent Textual Treatments

**link**: https://arxiv.org/pdf/2602.15730.pdf  
**date**: 2026-02-18  
**keywords**: latent space  
**abs**: 理解文本对下游结果的因果效应是许多应用中的核心任务。估计此类效应需要研究人员进行系统地改变文本特征的受控实验。虽然大型语言模型（LLMs）在生成文本方面具有潜力，但产生和评估受控变异需要更仔细的关注。本文提出了一个用于生成和因果估计潜在文本干预的端到端管道。该工作首先通过稀疏自编码器（SAEs）执行假设生成和引导，然后进行稳健的因果估计。该管道解决了文本作为处理实验中的计算和统计挑战。研究表明，对因果效应的朴素估计存在显著偏差，因为文本本身混淆了处理和协变量信息。本文描述了在此设置中引起的估计偏差，并提出了基于协变量残差化的解决方案。实证结果表明，该管道有效地诱导了目标特征的变异并减轻了估计误差，为文本作为处理设置中的因果效应估计提供了稳健的基础。  

---

### 22 In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations

**link**: https://arxiv.org/pdf/2602.15456.pdf  
**date**: 2026-02-18  
**keywords**: latent space, LLM Rec  
**abs**: 基于大型语言模型（LLMs）的智能体正越来越多地被部署为在线平台的信息接口。这些智能体对从平台后端数据库或通过网络搜索检索到的信息进行筛选、优先排序和综合。在这些场景中，LLM智能体通过将用户的注意力吸引到特定的检索信息实例上（而忽略其他信息）来控制用户接收的内容。虽然先前的许多研究关注LLMs自身生成信息中的偏见，但对影响LLMs选择和呈现给用户的信息的因素关注较少。我们假设，当信息归因于特定来源（如特定出版商、期刊或平台）时，当前的LLMs表现出系统性的潜在来源偏好——即它们优先考虑某些来源的信息而非其他来源。通过对来自六个模型提供商的十二个LLMs在合成和现实世界任务中的对照实验，我们发现多个模型一致表现出强烈且可预测的来源偏好。这些偏好对上下文框架敏感，可能超过内容本身的影响，并且即使明确提示避免，它们仍然存在。它们还有助于解释先前工作中观察到的新闻推荐中的左倾偏见等现象。我们的研究结果主张深入调查这些偏好的起源，并提出为用户提供透明度和控制LLM驱动智能体偏见的机制。  

---

### 23 jina-embeddings-v5-text: Task-Targeted Embedding Distillation

**link**: https://arxiv.org/pdf/2602.15547.pdf  
**date**: 2026-02-18  
**keywords**: latent space  
**abs**: 文本嵌入模型广泛应用于语义相似性任务，包括信息检索、聚类和分类。通用模型通常通过单阶段或多阶段过程使用对比损失函数进行训练。我们提出了一种新的训练方案，将模型蒸馏技术与特定任务的对比损失相结合，以生成紧凑、高性能的嵌入模型。研究结果表明，对于训练小型模型，这种方法比单独的纯对比或基于蒸馏的训练范式更有效。所得到的模型jina-embeddings-v5-text-small和jina-embeddings-v5-text-nano在类似大小的模型中超越或匹配了最先进的基准分数。此外，jina-embeddings-v5-text模型支持多种语言的长文本（最多32k tokens），并生成在截断和二进制量化下保持稳健的嵌入。模型权重已公开，希望能启发嵌入模型开发的进一步进展。  

---

### 24 How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning

**link**: https://arxiv.org/pdf/2602.15580.pdf  
**date**: 2026-02-18  
**keywords**: latent reasoning, latent space  
**abs**: 当多模态Transformer回答视觉问题时，其预测是由视觉证据、语言推理还是真正融合的跨模态计算驱动的？以及这种结构如何跨层演变？本文通过基于部分信息分解（PID）的分层框架解决了这一问题，该框架将每个Transformer层的预测信息分解为冗余、视觉唯一、语言唯一和协同组件。为使PID在高维神经表示上可行，本文引入了PID Flow，这一流程结合了降维、归一化流高斯化和闭式高斯PID估计。将该框架应用于LLaVA-1.5-7B和LLaVA-1.6-7B在六个GQA推理任务上，发现了一致的“模态转换”模式：视觉唯一信息在早期层达到峰值并随深度衰减，语言唯一信息在晚期层激增（约占最终预测的82%），而协同组件低于2%。通过有针对性的图像→问题注意力敲除实验，证实了破坏主要转换路径会导致被困视觉唯一信息、补偿性协同作用和总信息成本的可预测增加，这些效应在视觉依赖任务中最强，在高冗余任务中最弱。该结果为视觉如何在多模态Transformer中转化为语言提供了信息论和因果解释。  

---

### 25 PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra

**link**: https://arxiv.org/pdf/2602.15669.pdf  
**date**: 2026-02-18  
**keywords**: latent space  
**abs**: 当前大型语言模型的人格控制方法依赖静态提示或昂贵的微调，无法捕捉人类特质的动态和组合性质。本文介绍PERSONA，一种无需训练的框架，通过直接操作激活空间中的人格向量实现微调级性能。核心见解是：人格特质在模型的表示空间中表现为可提取的、近似正交的方向，并支持代数运算。该框架通过三个阶段运行：Persona-Base通过对比激活分析提取正交特质向量；Persona-Algebra通过向量算术实现精确控制（标量乘法用于强度调整，加法用于组合，减法用于抑制）；Persona-Flow通过在推理过程中动态组合这些向量实现上下文感知适应。在PersonalityBench上，该方法取得9.60的平均得分，几乎匹配监督微调的上限9.61，且无需任何梯度更新。在提出的动态人格适应基准Persona-Evolve上，跨不同模型家族实现了高达91%的胜率。这些结果证明LLM人格的某些方面在数学上是可处理的，为可解释和高效的行为控制开辟了新方向。
### 1 Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications

**link**: https://arxiv.org/pdf/2602.12338.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 令牌通信（TokenCom）是一种新兴的有效范式，其中令牌是多模态通信和计算的统一单元，能够在未来无线网络中实现高效的数字语义和目标导向通信。为了建立共享的语义 latent space，TokenCom 中的发射机/接收机需要就相同的令牌器模型和码本达成一致。本文研究了多用户下行链路无线 TokenCom 场景中的 TA 问题，提出了一种混合强化学习（RL）框架，集成了深度 Q 网络（DQN）和深度确定性策略梯度（DDPG）。仿真结果表明，该框架在语义质量和资源效率方面优于基线方法，视频传输中的冻结事件减少了 68%。

---

### 2 Exploring Accurate and Transparent Domain Adaptation in Predictive Healthcare via Concept-Grounded Orthogonal Inference

**link**: https://arxiv.org/pdf/2602.12542.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 该论文针对电子健康记录（EHR）临床事件预测模型在不同数据分布下的性能下降问题，提出了 ExtraCare 模型。该模型将患者表示分解为不变和协变组件，通过监督这两个组件并在训练期间强制它们的正交性，在保留标签信息的同时揭示领域特定变异，实现比大多数特征对齐模型更准确的预测。更重要的是，它通过将稀疏 latent 维度映射到医疗概念并通过目标消融量化其贡献，提供了人类可理解的解释。

---

### 3 VI-CuRL: Stabilizing Verifier-Independent RL Reasoning via Confidence-Guided Variance Reduction

**link**: https://arxiv.org/pdf/2602.12579.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 该论文针对强化学习与可验证奖励（RLVR）依赖外部验证器导致的可扩展性限制问题，提出了验证器无关的课程强化学习（VI-CuRL）框架。该框架利用模型的内在置信度构建独立于外部验证器的课程，通过优先处理高置信度样本有效管理偏差-方差权衡，减少动作和问题方差，提升 LLM 的 latent reasoning 能力。

---

### 4 Multi-Head Attention as a Source of Catastrophic Forgetting in MoE Transformers

**link**: https://arxiv.org/pdf/2602.12587.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 该论文研究发现混合专家（MoE）架构虽然被认为适合持续学习，但 MoE Transformers 仍存在严重的灾难性遗忘问题。研究归因于多头注意力将头特定信号连接为单个路由输入，导致路由冲突和专家功能相似。提出 MH-MoE 通过头部分别路由子表示来增加路由粒度并减少组合冲突，有效缓解遗忘。

---

### 5 Synthetic Interaction Data for Scalable Personalization in Large Language Models

**link**: https://arxiv.org/pdf/2602.12394.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 个性化提示为大型语言模型（LLM）向不同用户部署提供了巨大机会，但现有提示优化方法主要关注任务级优化，忽略了用户特定偏好。本文引入了 PersonaGym 高保真合成数据生成框架，模拟动态偏好过程以生成个性化多轮交互轨迹。利用 PersonaGym，发布了 PersonaAtlas 数据集，并提出了个性化提示优化（PPOpt）框架。实验表明，该方法在任务性能、个性化质量和对噪声的鲁棒性方面优于基线。

---

### 6 Continuous Diffusion Models Can Obey Formal Syntax

**link**: https://arxiv.org/pdf/2602.12468.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 扩散语言模型由于其全局、非因果的生成过程，为自回归模型提供了有前景的替代方案，但其连续潜动态使得施加离散约束（例如，输出应为符合给定模式的 JSON 文件）变得困难。本文引入了一种无需训练的引导方法，用于引导连续扩散语言模型满足使用正则表达式表示的形式语法约束。该方法构建了一个解析分数，估计潜状态解码为有效字符串的概率，并使用其梯度引导采样。

---

### 7 ADEPT: RL-Aligned Agentic Decoding of Emotion via Evidence Probing Tools -- From Consensus Learning to Ambiguity-Driven Emotion Reasoning

**link**: https://arxiv.org/pdf/2602.12714.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 语音大语言模型（SLLM）能够进行高级情感推理，但常产生无根据的文本偏向判断。本文提出 ADEPT 框架，将情感识别重构为多轮查询过程，将 SLLM 转化为智能体，通过候选生成、证据收集和裁决的结构化流程，维护动态候选情感集并自适应调用语义和声学探测工具。该框架实现了从共识学习到模糊驱动情感推理的范式转变，实验表明 ADEPT 在提升主情感准确率的同时，显著改善了次要情感表征。

---

### 8 Hierarchical Successor Representation for Robust Transfer

**link**: https://arxiv.org/pdf/2602.12753.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 后继表示（SR）框架能解耦预测动态与奖励，实现跨奖励配置的快速泛化，但经典 SR 受限于策略依赖性和拓扑复杂环境中的谱扩散问题。本文提出层次化后继表示（HSR），通过整合时间抽象构建预测表示，学习对任务诱导策略变化稳健的稳定状态特征。将非负矩阵分解（NMF）应用于 HSR，得到稀疏低秩状态表示，显著提升多隔间环境中 novel 任务的样本高效迁移。

---

### 9 Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL

**link**: https://arxiv.org/pdf/2602.12636.pdf
**date**: 2026-02-16
**keywords**: latent space
**abs**: 针对强化学习中奖励设计的挑战，尤其是具身操作任务，本文提出了双粒度对比奖励与生成式情节引导（DEG）框架。该框架利用大型视频生成模型的先验知识，仅需少量专家视频进行领域适应，即可为每个 RL 情节生成专用任务引导。通过在对比自监督 latent space 中平衡粗粒度探索和细粒度匹配的双粒度奖励，引导智能体高效逼近生成的引导视频，从而提高样本效率。在 18 个任务上的实验表明，DEG 能高效引导策略收敛。

---

### 10 Unifying Model-Free Efficiency and Model-Based Representations via Latent Dynamics

**link**: https://arxiv.org/pdf/2602.12643.pdf
**date**: 2026-02-16
**keywords**: latent space
**abs**: 本文提出了统一潜在动力学（ULD），一种新的强化学习算法，它将无模型方法的效率与基于模型方法的表征优势相结合，且无需规划开销。通过将状态-动作对嵌入到一个 latent space 中（其中真实值函数近似线性），该方法支持跨不同领域使用单一超参数集。在 80 个环境上的评估显示，ULD 在性能上匹配或超过专门的无模型和通用基于模型基线。

---

### 11 A Theoretical Analysis of Mamba's Training Dynamics: Filtering Relevant Features for Generalization in State Space Models

**link**: https://arxiv.org/pdf/2602.12499.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: Mamba 和其他选择性状态空间模型（SSMs）的近期实证成功重新激发了对非注意力架构用于序列建模的兴趣，但其理论基础仍未被充分探索。本文对一个简化但具有代表性的 Mamba 块进行了泛化和学习动态的初步分析。研究采用结构化数据模型，证明模型通过建立非渐近样本复杂度和收敛率界限实现有保证的泛化。此外，门控向量与类别相关特征对齐并忽略无关特征，形式化了特征选择作用。

---

### 12 Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings

**link**: https://arxiv.org/pdf/2602.12520.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 在部分可观测和高度动态环境中协调多智能体需要信息丰富的表示和数据高效的训练。为此，提出一种新颖的基于模型的多智能体强化学习框架，将联合状态-动作表示学习与想象滚动统一起来。设计了一个用变分自编码器训练的世界模型，并使用状态-动作学习嵌入（SALE）增强该模型。在星际争霸 II 等基准测试上的实证研究表明，该方法相比基线算法持续获得收益。

---

### 13 Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL

**link**: https://arxiv.org/pdf/2602.13035.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 该研究提出了一种名为 Introspective LLM 的分层强化学习框架，旨在通过大语言模型（LLM）的内部状态学习采样温度策略。在解码过程中，模型基于隐藏状态动态选择温度并采样下一个 token，通过坐标上升方案联合优化温度和 token 策略以最大化下游奖励。实验表明，在数学推理基准上，学习到的温度策略优于固定和启发式基线，并展现出与推理不确定性相关的可解释探索行为。

---

### 14 Quantization-Robust LLM Unlearning via Low-Rank Adaptation

**link**: https://arxiv.org/pdf/2602.13151.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 大语言模型（LLM）遗忘旨在从已训练模型中移除目标知识，但后训练量化（PTQ）可能掩盖或擦除遗忘更新。本文提出通过低秩适应（LoRA）实现量化鲁棒的遗忘：冻结基础模型并将遗忘更新集中到可训练适配器中，使有效更新在量化后得以保留。在 Llama-2-7B 上评估，LoRA 在 4 位量化下将效用提升高达 7.93 个百分点，同时减少隐私泄露。

---

### 15 A Lightweight LLM Framework for Disaster Humanitarian Information Classification

**link**: https://arxiv.org/pdf/2602.12284.pdf
**date**: 2026-02-16
**keywords**: cs.CL
**abs**: 社交媒体人道主义信息的及时分类对有效灾害响应至关重要，但在资源受限的紧急环境中部署大型语言模型（LLM）面临挑战。本文开发了一种轻量级、经济高效的框架，通过参数高效微调实现灾难推文分类。整合并规范化 HumAID 数据集构建双任务基准。系统评估表明，LoRA 仅训练约 2% 参数实现 79.62% 的人道主义分类准确率，QLoRA 以 50% 内存成本实现类似性能。

---

### 16 Can Neural Networks Provide Latent Embeddings for Telemetry-Aware Greedy Routing?

**link**: https://arxiv.org/pdf/2602.12798.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 遥测感知路由有望提高计算机网络在流量高峰时的效率和响应能力。我们提出 Placer，一种使用消息传递网络将网络状态转换为潜在节点嵌入的新算法。这些嵌入有助于快速贪婪的下一跳路由，无需直接解决全对最短路径问题，并让我们能够可视化某些网络事件如何塑造路由决策。

---

### 17 GRAIL: Geometry-Aware Retrieval-Augmented Inference with LLMs over Hyperbolic Representations of Patient Trajectories

**link**: https://arxiv.org/pdf/2602.12828.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 从纵向电子健康记录（EHRs）预测未来临床事件具有挑战性。我们提出 GRAIL，一个使用结构化几何表示和结构感知检索来建模纵向 EHRs 的框架。GRAIL 通过结合确定性编码系统层次结构和跨事件类型的数据驱动时间关联构建统一的临床图，将此图嵌入双曲空间，并将每次就诊总结为一个概率性的中心事件。在 MIMIC-IV 上的实验表明，GRAIL 持续改进多类型下一次就诊预测。

---

### 18 TRACE: Temporal Reasoning via Agentic Context Evolution for Streaming Electronic Health Records (EHRs)

**link**: https://arxiv.org/pdf/2602.12833.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 大型语言模型（LLMs）编码了广泛的医学知识，但在应用于纵向患者轨迹时可靠性不足。我们引入 TRACE，一个通过显式结构化和维护上下文使冻结 LLMs 能够进行时间临床推理的框架。TRACE 在双内存架构上运行，包括静态全局协议和动态个体协议。在 MIMIC-IV 上的评估表明，TRACE 显著提高了下一个事件的预测准确性、协议依从性和临床安全性。

---

### 19 Amortized Reasoning Tree Search: Decoupling Proposal and Decision in Large Language Models

**link**: https://arxiv.org/pdf/2602.12846.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 强化学习与可验证奖励（RLVR）已成为在大型语言模型中灌输严格推理能力的主导范式，但我们发现在这种对齐过程中存在一个关键问题：系统地抑制有效但罕见的推理路径。为在不放弃基础模型潜在多样性的情况下解决这种崩溃，我们提出摊销推理树搜索（ARTS）。在 MATH-500 基准上的实验表明，ARTS 实现了 74.6% 的性能，有效匹配完全微调的策略。

---

### 20 Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning

**link**: https://arxiv.org/pdf/2602.13069.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 本文针对设备端大语言模型（LLM）微调的内存限制问题，提出了 Memory-efficient Structured Backpropagation（MeSP）方法。该方法利用 LoRA 的低秩结构，通过在反向传播中重新计算中间投影来避免存储，从而显著降低内存占用。实验表明，MeSP 在 Qwen2.5 模型上实现了 49% 的平均内存减少，同时保持梯度计算的数学一致性。

---

### 21 LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning

**link**: https://arxiv.org/pdf/2602.13073.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 本文提出了 Layer-Cyclic Selective Backpropagation（LCSB）方法，通过在每次迭代中仅计算部分层的梯度，实现设备端 LLM 微调的内存与速度优化。实验显示，LCSB 在 5 个模型和 3 个任务上实现了 1.40 倍加速，质量损失小于 2%，且在 4 位量化设置下表现出优异稳定性。

---

### 22 EXCODER: EXplainable Classification Of DiscretE time series Representations

**link**: https://arxiv.org/pdf/2602.13087.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 本文研究了将时间序列转换为离散 latent 表示（如 VQ-VAE 和 DVAE 生成的表示）对可解释性的增强作用。通过将 XAI 方法应用于压缩后的 latent 表示，实现了简洁且结构化的解释，在保持分类性能的同时提升了解释的忠实度。此外，本文提出了 Similar Subsequence Accuracy（SSA）指标，用于定量评估 XAI 识别的显著子序列与训练数据中标签分布的对齐程度。

---

### 23 R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training

**link**: https://arxiv.org/pdf/2602.13103.pdf
**date**: 2026-02-16
**keywords**: cs.LG
**abs**: 本文针对自玩 LLM 训练（如 R-Zero）中存在的“多样性幻觉”问题提出了 R-Diverse 框架。该问题表现为训练信号表面多样但实际收敛于重复模式。为解决这些问题，R-Diverse 引入了两项创新：Memory-Augmented Penalty（MAP）利用持久内存库阻止跨迭代数据复用，以及 Skill-Aware Measurement（SAM）基于推理技能评估多样性。在 10 个基准上的实验表明，R-Diverse 能够持续提升性能。

---

### 24 Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification

**link**: https://arxiv.org/pdf/2602.12575.pdf
**date**: 2026-02-16
**keywords**: cs.CL
**abs**: 传统心理量表优化依赖于因子分析、项目反应理论等基于反应的方法，这些方法需要大样本且面临数据可用性和跨文化可比性的限制。本文提出了一种主题建模框架，将语义潜在结构用于量表简化。在 DASS、IPIP 和 EPOCH 数据集上的基准测试表明，该方法平均将量表长度减少 60.5%，同时保持心理测量学适当性。

---

### 25 AIWizards at MULTIPRIDE: A Hierarchical Approach to Slur Reclamation Detection

**link**: https://arxiv.org/pdf/2602.12818.pdf
**date**: 2026-02-16
**keywords**: cs.CL
**abs**: 检测被重新使用的污言秽语对仇恨言论检测系统是一项基本挑战。本文提出一种分层方法来建模污言秽语重新使用过程。该方法分为两个阶段：首先，通过弱监督 LLM 标注为用户分配表示其属于 LGBTQ+ 群体可能性的模糊标签，训练 BERT 类模型预测群体归属；第二阶段，将此潜在空间与新初始化的模型集成，用于下游污言秽语重新使用检测任务。在意大利语和西班牙语上的实验表明，该方法性能与强 BERT 基线相当。

---

### 26 Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting

**link**: https://arxiv.org/pdf/2602.12389.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 时间知识图谱（TKG）预测需要通过联合建模每个快照内的结构依赖关系和跨快照的时间演化来预测未来事实。本文提出实体状态调优（EST），这是一个与编码器无关的框架，赋予 TKG 预测器持久且持续演化的实体状态。在多个基准上的实验表明，EST 持续改进了不同的骨干模型并实现了最先进的性能。

---

### 27 To Mix or To Merge: Toward Multi-Domain Reinforcement Learning for Large Language Models

**link**: https://arxiv.org/pdf/2602.12566.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 带可验证奖励的强化学习（RLVR）在激发大型语言模型（LLMs）的显式推理能力方面发挥着关键作用。我们选择多个常用的高级任务作为目标领域，并使用开源数据集设计了广泛的实验。我们发现跨领域的 RLVR 几乎没有相互干扰，且推理密集型领域表现出相互协同效应。此外，我们从权重空间几何、模型预测行为和信息约束的角度分析了 mutual gains 的内在机制。

---

### 28 Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models

**link**: https://arxiv.org/pdf/2602.12586.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 尽管掩码扩散模型（MDMs）中的规划-填充解码在数学和代码推理方面显示出潜力，但性能对槽填充顺序高度敏感。本文引入 McDiffuSE 框架，将槽选择表述为决策问题，并通过蒙特卡洛树搜索（MCTS）优化填充顺序。实验表明，在 BookingArena 基准上，我们的蒸馏学生模型平均比自回归基线提高 3.2%，比基线规划-填充提高 8.0%。

---

### 29 GeoAgent: Learning to Geolocate Everywhere with Reinforced Geographic Characteristics

**link**: https://arxiv.org/pdf/2602.12617.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 本文提出 GeoAgent，一种能够与人类紧密推理并得出细粒度地址结论的模型。我们首先引入 GeoSeek，一个新的地理定位数据集，包含由地理专家标注的 CoT 数据。我们进一步深入探索地理任务的内在特征，并提出地理相似性奖励和一致性奖励来辅助训练。实验结果表明，GeoAgent 在多个粒度上优于现有方法和通用视觉语言模型。

---

### 30 Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction

**link**: https://arxiv.org/pdf/2602.12287.pdf
**date**: 2026-02-16
**keywords**: cs.CL
**abs**: 端到端自动语音识别（ASR）系统经常误识别领域特定短语（如命名实体）。本文提出一种新颖的检索增强生成框架，用于纠正 ASR 中的命名实体错误。该方法包括两个关键组件：用于命名实体识别的重述语言模型（RLM），以及具有自适应思维链（A-STAR）的自学习推理模型。在 AISHELL-1 和同音字数据集上的实验证明了该方法的有效性。

---

### 31 Know More, Know Clearer: A Meta-Cognitive Framework for Knowledge Augmentation in Large Language Models

**link**: https://arxiv.org/pdf/2602.12996.pdf
**date**: 2026-02-16
**keywords**: cs.CL
**abs**: 知识增强显著提升了大型语言模型（LLMs）在知识密集型任务中的性能，但现有方法忽视了知识-信心差距。为弥合这一差距，本文提出一种新颖的元认知框架，通过差异化干预和对齐实现可靠的知识增强。该方法利用内部认知信号将知识空间划分为已掌握、混淆和缺失区域，指导有针对性的知识扩展。大量实验表明，该框架持续优于强基线。

---

### 32 Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents

**link**: https://arxiv.org/pdf/2602.12662.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 大型语言模型（LLMs）越来越多地被部署为用于多轮决策任务的自主智能体。在本文中，我们引入 CogRouter，这一框架训练智能体在每个步骤动态调整认知深度。基于 ACT-R 理论，我们设计了从本能响应到战略规划的四个层级认知水平。在 ALFWorld 和 ScienceWorld 上的实验表明，CogRouter 以更高的效率实现了最先进的性能。

---

### 33 Evaluating Robustness of Reasoning Models on Parameterized Logical Problems

**link**: https://arxiv.org/pdf/2602.12665.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 逻辑为评估基于 LLM 的推理器提供了可控的测试平台。我们引入了一个用于 2-SAT 的诊断基准，该基准由参数化的结构化 2-CNF 公式族构建而成，其中可满足性由蕴含图表征。我们评估基于 LLM 的推理器的决策准确性和分配有效性，并量化在语义保留扰动下的鲁棒性。在不同模型中，我们观察到在有针对性的结构干预下性能会发生急剧转变。

---

### 34 Information-theoretic analysis of world models in optimal reward maximizers

**link**: https://arxiv.org/pdf/2602.12963.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 人工智能领域的一个重要问题是，成功的行为在多大程度上需要对世界的内部表征。我们考虑具有 n 个状态和 m 个动作的受控马尔可夫过程（CMP），假设对可能的转移动态空间有均匀先验。我们证明，观察对于任何非恒定奖励函数而言最优的确定性策略，会传达关于环境的恰好 n log m 比特信息。这些发现为最优性所需的“隐式世界模型”提供了精确的信息论下界。

---

### 35 Consistency of Large Reasoning Models Under Multi-Turn Attacks

**link**: https://arxiv.org/pdf/2602.13093.pdf
**date**: 2026-02-16
**keywords**: cs.AI
**abs**: 具有推理能力的大型推理模型在复杂任务上实现了最先进的性能，但其在多轮对抗压力下的鲁棒性仍未得到充分探索。我们在对抗性攻击下评估了九个前沿推理模型。通过轨迹分析，我们确定了五种失败模式（自我怀疑、社会从众、建议劫持、情绪敏感性和推理疲劳）。我们的结果强调，推理能力不会自动赋予对抗鲁棒性，并且基于置信度的防御需要为推理模型进行根本性重新设计。
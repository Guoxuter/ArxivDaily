以下是根据任务要求处理的论文摘要和总结结果。我已对输入论文集合进行了去重处理：所有论文基于唯一ID（arXiv ID）检查，无重复论文。输出以Markdown格式组织，每个论文条目包括：
- **Paper Name**：论文标题。
- **link**：论文PDF链接。
- **date**：发布日期（YYYY-MM-DD格式）。
- **keywords**：基于输入中的`categories`字段生成（多个类别时以逗号分隔）。
- **abs**：论文摘要（直接使用输入中的`summary`字段，确保为中文）。

处理后的论文列表按输入顺序排列。

---
### 1 Explaining Robustness to Catastrophic Forgetting Through Incremental Concept Formation
**link**: https://arxiv.org/pdf/2510.23756.pdf  
**date**: 2025-10-29  
**keywords**: cs.LG  
**abs**: 灾难性遗忘仍然是持续学习中的核心挑战，持续学习要求模型随时间整合新知识而不丢失先前学到的内容。在先前的工作中，我们引入了Cobweb/4V，这是一种分层概念形成模型，在视觉领域表现出对灾难性遗忘的鲁棒性。受这种鲁棒性的启发，我们研究了三个关于促成这种稳定性的因素的假设：（1）自适应结构重组增强知识保留，（2）稀疏和选择性更新减少干扰，（3）基于充分统计量的信息论学习比基于梯度的反向传播具有优势。为了验证这些假设，我们将Cobweb/4V与神经基线（包括本文介绍的Cobweb框架的神经实现CobwebNN）进行了比较。在不同复杂度的数据集（MNIST、Fashion-MNIST、MedMNIST和CIFAR-10）上的实验表明，自适应重组增强了学习可塑性，稀疏更新有助于减轻干扰，信息论学习过程无需重新访问过去的数据即可保留先前的知识。这些发现共同提供了对可减轻灾难性遗忘的机制的见解，并突出了基于概念的信息论方法在构建稳定和自适应的持续学习系统方面的潜力。  
---
### 2 Efficient Low Rank Attention for Long-Context Inference in Large Language Models
**link**: https://arxiv.org/pdf/2510.23649.pdf  
**date**: 2025-10-29  
**keywords**: cs.LG  
**abs**: 随着输入文本长度的增加，大型语言模型（LLMs）中的键值（KV）缓存带来了高昂的GPU内存成本，并限制了资源受限设备上的长上下文推理。现有方法（如KV量化和剪枝）虽能减少内存使用，但存在数值精度损失或键值对保留次优的问题。本文提出低秩查询和键注意力（LRQK），这是一个两阶段框架：在预填充阶段将全精度查询和键矩阵联合分解为紧凑的秩-r因子，然后在每个解码步骤使用这些低维投影以O(lr)时间计算代理注意力分数。通过仅选择top-k令牌和一小部分固定的最近令牌，LRQK采用混合GPU-CPU缓存和命中-未命中机制，仅传输缺失的全精度KV对，从而在减少CPU-GPU数据移动的同时保留精确的注意力输出。在RULER和LongBench基准上使用LLaMA-3-8B和Qwen2.5-7B进行的大量实验表明，LRQK在长上下文设置中匹配或超越了领先的稀疏注意力方法，同时实现了显著的内存节省和最小的精度损失。  
---
### 3 Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings
**link**: https://arxiv.org/pdf/2510.24432.pdf  
**date**: 2025-10-29  
**keywords**: cs.LG  
**abs**: 稀疏奖励环境下的强化学习（RL）由于缺乏信息反馈仍是一大挑战。本文提出一种简单有效的方法，利用少量成功演示来初始化RL智能体的值函数。通过从离线演示中预计算价值估计并将其作为早期学习的目标，该方法为智能体提供了关于有前景动作的有用先验知识。智能体随后通过标准在线交互优化这些估计。这种离线到在线的混合范式显著减少了探索负担，并提高了稀疏奖励环境下的样本效率。在基准任务上的实验表明，即使使用最少或次优的演示数据，该方法也能加速收敛并优于标准基线。  
---
### 4 Learning Parameterized Skills from Demonstrations
**link**: https://arxiv.org/pdf/2510.24095.pdf  
**date**: 2025-10-29  
**keywords**: cs.LG  
**abs**: 本文提出DEPS，一种端到端算法，用于从专家演示中发现参数化技能。该方法联合学习参数化技能策略与元策略，后者在每个时间步选择适当的离散技能和连续参数。通过结合时间变分推断和信息论正则化方法，解决了 latent variable models 中常见的退化问题，确保学习到的技能具有时间扩展性、语义意义和适应性。实验表明，从多任务专家演示中学习参数化技能显著提高了对未见任务的泛化能力，在LIBERO和MetaWorld基准上优于多任务和技能学习基线，并发现了可解释的参数化技能（如物体抓取技能，其连续参数定义抓取位置）。  
---
### 5 Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation
**link**: https://arxiv.org/pdf/2510.24120.pdf  
**date**: 2025-10-29  
**keywords**: cs.LG  
**abs**: 基于图的RAG（检索增强生成）从文本块构建知识图谱（KG），以增强大型语言模型（LLM）问答中的检索能力，特别适用于生物医学、法律和政治学等领域，这些领域的有效检索通常需要对专有文档进行多跳推理。然而，这些方法需要大量LLM调用来从文本块中提取实体和关系，在规模上成本过高。通过精心设计的消融研究，作者观察到某些词（称为概念）及其相关文档更为重要。基于此，提出Graph-Guided Concept Selection（G2ConS），其核心包括块选择方法和独立于LLM的概念图。前者选择显著文档块以降低KG构建成本；后者以零成本弥补块选择引入的知识缺口。在多个真实世界数据集上的评估表明，G2ConS在构建成本、检索效果和回答质量上均优于所有基线。  
---
### 6 SALS: Sparse Attention in Latent Space for KV cache Compression
**link**: https://arxiv.org/pdf/2510.24273.pdf  
**date**: 2025-10-29  
**keywords**: cs.LG  
**abs**: 大型语言模型对长上下文处理的需求很高，但其推理过程因巨大的键值（KV）缓存大小和高内存带宽需求而面临挑战。现有研究表明KV缓存在隐藏维度上具有低秩特性，存在压缩潜力。然而，由于现代LLM广泛采用的旋转位置嵌入（RoPE）机制，直接的低秩压缩会导致严重的精度下降或新的速度瓶颈。本文提出两点关键见解：RoPE应用增加了键向量的方差导致更高秩；键向量在 latent space 中转换后，在大多数层中基本保持其表示。基于这些见解，提出了潜在空间稀疏注意力（SALS）框架。SALS通过低秩投影将KV缓存投影到紧凑的潜在空间，并在该空间中使用无RoPE的查询-键交互执行稀疏令牌选择。通过仅重建一小部分重要令牌，避免了完整KV缓存重建的开销。在LLaMA2-7b-chat、Mistral-7b等模型上的实验表明，SALS在保持竞争力精度的同时实现了SOTA性能，在4K序列上实现了6.4倍的KV缓存压缩和5.7倍的注意力算子加速。  
---
### 7 From Memorization to Reasoning in the Spectrum of Loss Curvature
**link**: https://arxiv.org/pdf/2510.24256.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 本文研究了记忆在Transformer模型（包括语言模型和视觉Transformer）权重中的表示方式，通过基于损失函数曲率的分解方法可以区分记忆的内容。研究发现，记忆的训练点的曲率比非记忆点更尖锐，因此按曲率高低排序权重分量可无需显式标签进行区分。基于此，提出了一种权重编辑程序，能比最新的遗忘方法更有效地抑制非目标记忆数据的复述，同时保持较低的困惑度。分析表明，事实检索和算术等依赖权重空间中专门方向的任务在编辑后性能显著下降，为理解神经网络中的记忆提供了见解，并为移除记忆提供了实际应用。  
---
### 8 AgentFold: Long-Horizon Web Agents with Proactive Context Management
**link**: https://arxiv.org/pdf/2510.24699.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 基于LLM的网络智能体在长程任务中受限于上下文管理的权衡：ReAct类智能体因积累嘈杂原始历史导致上下文饱和，而固定总结全历史的方法可能丢失关键细节。本文提出AgentFold，一种以主动上下文管理为核心的新型智能体范式，受人类回顾性巩固认知过程启发，将上下文视为动态认知工作空间进行主动塑造。在每一步，它执行“折叠”操作，多尺度管理历史轨迹：可进行精细压缩保留关键细节，或深度整合抽象多步子任务。结果显示，AgentFold-30B-A3B在BrowseComp和BrowseComp-ZH上分别达到36.2%和47.3%，超越更大规模开源模型和领先专有智能体。  
---
### 9 MGA: Memory-Driven GUI Agent for Observation-Centric Interaction
**link**: https://arxiv.org/pdf/2510.24168.pdf  
**date**: 2025-10-29  
**keywords**: cs.AI  
**abs**: 本文介绍了记忆驱动的GUI代理（MGA），它将GUI交互重构为“先观察后决策”的原则。MGA将每一步建模为一个独立的、上下文丰富的环境状态，由三元组表示：当前截图、与任务无关的空间信息以及动态更新的结构化记忆。现有范式通常将任务建模为长链执行，将历史轨迹串联到上下文中，而MGA通过这种结构化记忆设计，解决了依赖历史轨迹导致的错误传播和“决策优先、观察滞后”机制带来的局部探索偏差问题。在OSworld基准测试、真实桌面应用（Chrome、VSCode、VLC）和跨任务迁移中的实验表明，MGA在鲁棒性、泛化性和效率方面显著优于最先进的基线。  
---
### 10 Tongyi DeepResearch Technical Report
**link**: https://arxiv.org/pdf/2510.24701.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 本文介绍了Tongyi DeepResearch，这是一个专为长程深度信息搜索研究任务设计的智能体大型语言模型。为了增强自主深度研究能力，该模型通过端到端训练框架结合智能体中期训练和后期训练，实现跨复杂任务的可扩展推理和信息搜索。研究团队设计了全自动、无需昂贵人工标注的数据合成管道，支持所有训练阶段，并为每个阶段构建定制环境以确保稳定一致的交互。Tongyi DeepResearch总参数达305亿，每token仅激活33亿参数，在多项智能体深度研究基准（如Humanity's Last Exam、BrowseComp等）上取得最先进性能，并开源了模型、框架及完整解决方案。  
---
### 11 ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents
**link**: https://arxiv.org/pdf/2510.23822.pdf  
**date**: 2025-10-29  
**keywords**: cs.AI  
**abs**: 针对大型语言模型（LLMs）在长程任务中面临的多步推理和动态重规划挑战，本文提出ReCAP（递归上下文感知推理与规划）框架。该框架采用共享上下文的分层结构，结合三种关键机制：（1）预先规划分解，生成完整子任务列表并执行首个任务后优化剩余任务；（2）父计划结构化重注入，在递归返回过程中维持跨层级上下文一致性；（3）内存高效执行，通过限制活跃提示使成本随任务深度线性增长。实验表明，ReCAP显著提升了子目标对齐度和成功率，在同步Robotouille任务上实现32%的性能提升，在异步Robotouille任务的strict pass@1协议下提升29%。  
---
### 12 Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges
**link**: https://arxiv.org/pdf/2510.23883.pdf  
**date**: 2025-10-29  
**keywords**: cs.AI  
**abs**: 本文探讨了由大型语言模型（LLMs）驱动的智能体AI系统的安全问题。这类系统具备规划、工具使用、记忆和自主性等能力，在自动化跨网络、软件和物理环境任务的同时，也带来了不同于传统AI安全和软件安全的新型安全风险。文章提出了智能体AI特有的威胁分类法，综述了最新基准和评估方法，并从技术和治理角度讨论防御策略。研究综合现有成果并强调开放挑战，旨在支持安全设计的智能体系统开发。  
---
### 13 Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting
**link**: https://arxiv.org/pdf/2510.24303.pdf  
**date**: 2025-10-29  
**keywords**: cs.AI  
**abs**: 判断性预测是基于人类判断对未来事件进行预测的任务，可视为一种主张验证形式，其中主张对应未来事件，任务是评估该事件的合理性。本文提出了一种新颖的多智能体主张验证框架，不同智能体可能对主张真实性存在分歧，并提供支持和反对主张的特定证据，以定量双极论证框架（QBAFs）表示。然后，该框架实例化为支持主张验证，使用多种由大型语言模型（LLMs）实现的智能体：（1）ArgLLM智能体，一种现有的生成和评估QBAFs的主张验证方法；（2）RbAM智能体，利用LLM增强的基于关系的论证挖掘（RbAM）从外部来源生成QBAFs；（3）RAG-ArgLLM智能体，通过从外部来源检索增强生成（RAG）论证来扩展ArgLLM智能体。最后，在两个标准判断性预测数据集上进行实验，框架实例包含两到三个智能体，由六种不同的基础LLM支持。结果表明，组合智能体的证据可以提高预测准确性，尤其是在三个智能体的情况下，同时为主张验证提供可解释的证据组合。  
---
### 14 Iterative Critique-Refine Framework for Enhancing LLM Personalization
**link**: https://arxiv.org/pdf/2510.24469.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 个性化文本生成要求模型不仅生成连贯文本，还需与目标用户的风格、语气和主题焦点保持一致。现有检索增强方法（如LaMP和PGraphRAG）通过用户及邻居历史丰富档案，但生成后常出现语气、主题或风格漂移。本文提出PerFine，一个无需训练的统一批判-改进框架，通过迭代的基于档案反馈增强个性化。每次迭代中，生成器基于检索档案生成草稿，评论家基于同一档案提供语气、词汇、句子结构和主题性的结构化反馈，生成器进行修订，并通过新淘汰策略保留更强草稿。还研究了Best-of-N和主题提取等推理时策略以平衡质量与效率。在Yelp、Goodreads和Amazon数据集上，PerFine持续优于PGraphRAG，GEval提升7-13%，在3-5次迭代中稳步改进，并随评论家规模扩大而扩展。结果表明，事后档案感知反馈为LLM个性化生成提供了强大的模型无关范式。  
---
### 15 Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception
**link**: https://arxiv.org/pdf/2510.23853.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 大型语言模型代理在多轮对话环境中与动态环境交互执行任务时存在关键局限性——时间盲性：它们默认在静态上下文中运行，无法考虑消息间流逝的真实世界时间。这导致代理在决定是否调用工具时出现过度依赖过往上下文（跳过必要工具调用）或依赖不足（重复调用）的问题。为此，研究引入TicToc-v1测试集（含34个时间敏感场景），通过添加显式时间戳增强对话消息以提供时间上下文，并收集人类偏好数据（prefer-noTool和prefer-Tool子集）。评估显示，无时间信息时模型表现接近随机（最高对齐率约60%），添加时间戳后大型模型略有改善（峰值约65%），但提升有限。研究强调需针对多轮LLM工具使用与人类时间感知进行特定的训练后对齐，这与Agent Memory中上下文管理和时间感知记忆机制密切相关。  
---
### 16 Evaluating Long-Term Memory for Long-Context Question Answering
**link**: https://arxiv.org/pdf/2510.23730.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 为使大型语言模型实现真正的对话连续性并从经验学习中获益，它们需要具备记忆能力。尽管已有研究聚焦于复杂记忆系统的开发，但对于长上下文对话任务而言，哪种类型的记忆最为有效尚不明确。本文通过LoCoMo基准（一组带注释的合成长上下文对话，用于需要多种推理策略的问答任务），对记忆增强方法进行了系统评估。分析了全上下文提示、基于检索增强生成的语义记忆与智能体记忆、基于上下文学习的情景记忆以及基于提示优化的程序记忆。研究结果表明，记忆增强方法可减少90%以上的token使用量，同时保持具有竞争力的准确性。记忆架构的复杂性应与模型能力相匹配：小型基础模型从RAG中获益最多，而强大的指令调优推理模型则从通过反思实现的情景学习和更复杂的智能体语义记忆中获益。特别是，情景记忆能帮助LLMs识别自身知识的局限性。  
---
### 17 ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?
**link**: https://arxiv.org/pdf/2510.24706.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 虚拟现实（VR）游戏要求玩家将高层语义动作转化为使用控制器和头显（HMD）的精确设备操作。人类能基于常识和具身理解直观地完成这种转化，但大型语言模型（LLMs）能否有效复制这种能力尚待深入探索。本文引入ComboBench基准，评估LLMs在262个场景中（来自《半衰期：爱莉克斯》《Into the Radius》《莫斯：第二部》和《Vivecraft》四款热门VR游戏）将语义动作转化为VR设备操作序列的能力。对GPT-3.5、GPT-4、GPT-4o、Gemini-1.5-Pro等七个LLM进行了评估，并与标注的真值和人类表现对比。结果显示，尽管Gemini-1.5-Pro等顶级模型表现出较强的任务分解能力，但与人类相比，它们在程序推理和空间理解方面仍存在困难。不同游戏间的性能差异显著，表明其对交互复杂性较为敏感。少样本示例能大幅提升性能，说明LLMs的VR操作能力有针对性增强的潜力。  
---
### 18 Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs
**link**: https://arxiv.org/pdf/2510.24606.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 注意力机制的二次计算成本限制了长上下文大语言模型（LLM）的扩展性，尤其在资源受限的设备端环境中。现有静态稀疏方法（如滑动窗口或全局令牌）虽能通过利用注意力稀疏性降低成本，但因缺乏动态性而难以适应内容依赖的注意力变化；动态方法则依赖预定义模板或启发式机制，限制了通用性并可能修剪上下文重要令牌。为此，本文提出动态分层稀疏注意力（DHSA）框架，通过数据驱动方式在线预测注意力稀疏性，无需重新训练。该方法自适应地将序列分割为可变长度块，通过聚合块内令牌嵌入计算块表示，并应用长度归一化聚合（按块大小平方根缩放平均嵌入）以避免块长度偏差，最后将块级相似度分数上采样至令牌级以确定需保留的令牌交互。实验表明，在Gemma2模型上，DHSA在Needle-in-a-Haystack测试和LongBench基准上匹配密集注意力的准确性，同时减少20-60%的预填充延迟和35%的峰值内存使用，相比块稀疏注意力等基线方法实现6-18%的相对准确率提升，为设备端LLM的长上下文建模提供高效且自适应的解决方案。  
---
### 19 Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?
**link**: https://arxiv.org/pdf/2510.24259.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL, Agent Memory  
**abs**: 本文研究大型语言模型（LLM）是否能够将人类自然语言指令翻译成强化学习智能体的内部涌现符号表示。通过结构化评估框架，作者在Ant Maze和Ant Fall环境中测试了GPT、Claude、Deepseek和Grok等LLM对不同内部符号划分的翻译性能。结果显示，LLM虽能在一定程度上翻译自然语言到环境动态的符号表示，但其性能对划分粒度和任务复杂度高度敏感。研究揭示了当前LLM在表示对齐方面的局限性，强调需进一步研究语言与智能体内部表示的稳健对齐方法。  
---
### 20 SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models
**link**: https://arxiv.org/pdf/2510.24427.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL, LLM Memory  
**abs**: 本文提出SynthWorlds框架，旨在分离语言模型（LM）的任务推理复杂度与事实知识。该框架构建了两个结构相同的平行语料库：真实映射世界（模型可利用参数知识）和合成映射世界（参数知识无效）。基于此设计了多跳问答和页面导航两个镜像任务，保持跨世界推理难度一致。实验表明，在纯参数（如闭卷QA）和知识增强（如检索增强）设置中，模型存在持续的知识优势差距（利用记忆的参数化世界知识获得的性能提升）。知识获取和整合机制虽能缩小但无法消除该差距，为系统改进提供方向。SynthWorlds提供了可控环境，可精确评估LM的推理与记忆能力。  
---
### 21 Evolving Diagnostic Agents in a Virtual Clinical Environment
**link**: https://arxiv.org/pdf/2510.24654.pdf  
**date**: 2025-10-29  
**keywords**: cs.CL  
**abs**: 本文提出了一个通过强化学习训练大型语言模型（LLMs）作为诊断代理的框架，使其能够管理多轮诊断流程、自适应选择检查项目并做出最终诊断。与基于静态病例摘要训练的指令调优模型不同，该方法通过交互式探索和基于结果的反馈获取诊断策略。主要贡献包括：（i）提出DiagGym，一个基于电子健康记录训练的诊断世界模型，可作为虚拟临床环境生成检查结果；（ii）通过端到端多轮强化学习训练DiagAgent，学习同时优化信息获取和诊断准确性的诊断策略；（iii）引入DiagBench诊断基准，包含750个经医生验证的病例；（iv）在多种诊断场景中展示出优越性能，显著超越10个最先进的LLM，包括DeepSeek-v3和GPT-4o，在单轮和端到端设置中均提升了诊断准确性和检查推荐效果。
以下是针对输入论文集合的处理结果。我已根据任务要求执行以下步骤：
1. **摘要和总结**：对每篇论文进行摘要和总结，突出重点。`abs` 字段基于输入中的 `summary` 生成，确保其为中文并精炼以突出核心贡献、方法和实验结果。
2. **去除重复论文**：检查所有论文的 `id`，输入集合中包含 25 篇论文，所有 `id` 均唯一（例如，'2510.21978' 到 '2510.22559'），无重复论文。
3. **输出格式**：以 Markdown 格式输出，符合指定结构（`### 序号 Paper Name`，后跟 `link`、`date`、`keywords` 和 `abs`）。`keywords` 字段基于论文标题和摘要手动提取关键术语（2-3 个），以逗号分隔，突出研究主题；`abs` 字段使用输入 `summary` 并稍作优化以确保简洁和重点突出（如强调创新方法、实验结果）；`date` 和 `link` 直接使用输入中的 `published` 和 `pdf_url`。

输出论文按输入顺序排列（从第一个到最后一个），序号从 1 开始递增。

---
### 1 Beyond Reasoning Gains: Mitigating General Capabilities Forgetting in Large Reasoning Models
**link**: https://arxiv.org/pdf/2510.21978.pdf  
**date**: 2025-10-28  
**keywords**: 强化学习, 能力退化, 经验回放  
**abs**: 强化学习与可验证奖励（RLVR）在数学和多模态推理中取得显著进展，但长期训练可能导致模型忘记基础技能（能力退化）。本文提出RECAP策略，通过动态目标重加权的经验回放来保存一般知识。该机制在线调整训练重点，从饱和目标转向表现不佳或不稳定的目标，无需额外模型或大量调优。实验表明，在Qwen2.5-VL模型上，RECAP不仅保留了一般能力，还通过灵活权衡任务内奖励提升了推理性能。

---
### 2 Is Temporal Difference Learning the Gold Standard for Stitching in RL?
**link**: https://arxiv.org/pdf/2510.21995.pdf  
**date**: 2025-10-28  
**keywords**: 强化学习, 经验拼接, 时序差分  
**abs**: 强化学习（RL）的经验拼接能力通常被认为是时序差分（TD）方法的优势，但本文实证表明蒙特卡洛（MC）方法也能实现经验拼接。尽管TD方法略强，但差距远小于小型与大型神经网络的差距。增加评论家容量可减少MC和TD的泛化差距，表明在大模型时代，TD的归纳偏置必要性降低，经验拼接可能通过模型规模而非特定算法实现。

---
### 3 COLA: Continual Learning via Autoencoder Retrieval of Adapters
**link**: https://arxiv.org/pdf/2510.21836.pdf  
**date**: 2025-10-28  
**keywords**: 持续学习, 灾难性遗忘, 自动编码器  
**abs**: 持续学习（CL）是人工智能领域最具挑战性的问题之一，主要障碍是灾难性遗忘。大型语言模型（LLMs）由于训练成本高，难以频繁重新训练。本文提出COLA框架，采用自动编码器学习低维嵌入，捕获与任务相关的权重，促进知识转移并防止灾难性遗忘，无需数据重放或大量特定任务参数。在对话系统和意图分类数据集上的评估表明，COLA克服了遗忘，减少了参数使用和内存大小，并在多个数据集上优于现有方法。

---
### 4 Efficient Utility-Preserving Machine Unlearning with Implicit Gradient Surgery
**link**: https://arxiv.org/pdf/2510.22124.pdf  
**date**: 2025-10-28  
**keywords**: 机器遗忘, 约束优化, 梯度手术  
**abs**: 机器遗忘（MU）旨在从预训练模型中高效移除敏感或有害记忆，核心挑战是平衡遗忘效果与效用保留。本文将MU建模为约束优化问题，提出隐式梯度手术方法，通过单次反向传播近似求解，实现高效的效用保留型机器遗忘。理论上提供了严格的收敛分析，实验表明该算法在多个基准上优于现有方法，能更好地平衡遗忘目标与模型性能。

---
### 5 Edit Less, Achieve More: Dynamic Sparse Neuron Masking for Lifelong Knowledge Editing in LLMs
**link**: https://arxiv.org/pdf/2510.22139.pdf  
**date**: 2025-10-28  
**keywords**: 知识编辑, 稀疏掩蔽, 神经元归因  
**abs**: 终身知识编辑使大型语言模型（LLMs）能够持续、精确地更新过时知识，无需昂贵的全量重训练。本文提出神经元特异性掩蔽知识编辑（NMKE）框架，结合神经元级归因与动态稀疏掩蔽，识别知识通用神经元和知识特定神经元，通过熵引导的动态稀疏掩模定位目标知识相关神经元，实现精细的神经元级知识编辑，减少参数修改。实验表明，NMKE在数千次连续编辑中保持高编辑成功率和模型通用能力。

---
### 6 Transformer Key-Value Memories Are Nearly as Interpretable as Sparse Autoencoders
**link**: https://arxiv.org/pdf/2510.22332.pdf  
**date**: 2025-10-28  
**keywords**: 可解释性, 前馈层, 稀疏自编码器  
**abs**: 本文重新审视了前馈（FF）层中存储的特征向量的可解释性，将FF层视为键值记忆，并通过现代可解释性基准进行评估。研究发现，稀疏自编码器（SAE）和FF层在可解释性上表现出相似的范围，尽管SAE在某些方面有微小改进。令人惊讶的是，在某些情况下，vanilla FF层的可解释性甚至优于SAE，且SAE和FF层发现的特征存在差异。这些结果对SAE相对于直接解释FF特征向量的优势（从特征质量和忠实性角度）提出了质疑，并表明FF键值参数可作为现代可解释性研究的强基线。

---
### 7 Label Smoothing Improves Gradient Ascent in LLM Unlearning
**link**: https://arxiv.org/pdf/2510.22376.pdf  
**date**: 2025-10-28  
**keywords**: LLM遗忘, 梯度上升, 标签平滑  
**abs**: LLM遗忘旨在以低成本使模型忘记危险/不需要的知识，同时保留模型效用。现有技术中，梯度上升（GA）方法存在不稳定性，常导致模型效用下降。本文提出平滑梯度上升（SGA），通过可调平滑率将遗忘数据与多个构造的正常数据结合，使GA从仅学习遗忘数据扩展到联合学习，实现更稳定的遗忘和更好的效用保留。理论分析提供了最优平滑率指导，实验在TOFU、Harry Potter和MUSE-NEWS基准上表明，SGA在所有指标上优于原始GA，并在多个关键指标上达到第二名。

---
### 8 Knowledge-guided Continual Learning for Behavioral Analytics Systems
**link**: https://arxiv.org/pdf/2510.22405.pdf  
**date**: 2025-10-28  
**keywords**: 持续学习, 行为分析, 知识增强  
**abs**: 在线平台上的用户行为不断演变，模型可能因数据漂移而性能下降。本文提出基于增强的方法，将外部知识整合到重放式持续学习框架中，通过维护训练实例缓冲区和知识库来最小化灾难性遗忘。在三个异常行为分类数据集上的评估表明，该策略优于基线重放方法，证明了外部知识在持续学习中的有效性。

---
### 9 Robust Uncertainty Quantification for Self-Evolving Large Language Models via Continual Domain Pretraining
**link**: https://arxiv.org/pdf/2510.22931.pdf  
**date**: 2025-10-28  
**keywords**: 持续学习, 不确定性量化, Conformal预测  
**abs**: 持续学习（CL）对于自进化大型语言模型（LLMs）在知识快速增长环境中保持适应性至关重要。本文针对持续领域预训练（CDP）提出自适应拒绝和非交换conformal预测框架，使用Transformer聚类估计测试问题分布，并重加权校准数据，允许LLM在置信度不足时选择性放弃回答。实验表明，该框架提高了CDP场景下的有效性和可靠性。

---
### 10 Can Language Models Compose Skills In-Context?
**link**: https://arxiv.org/pdf/2510.22993.pdf  
**date**: 2025-10-28  
**keywords**: 语言模型, 技能组合, 上下文学习  
**abs**: 本文研究了语言模型在上下文中组合基本技能以完成复合任务的能力。通过对开源模型的系统实验，利用语言和逻辑任务，结果表明简单任务示例可能对性能产生负面影响，因为模型难以正确识别和组装技能，即使提供思维链示例。理论分析表明，将示例与组合步骤对齐至关重要，这启发了一种改进方法，在探测任务中提升了性能。

---
### 11 HRM-Agent: Training a recurrent reasoning model in dynamic environments using reinforcement learning
**link**: https://arxiv.org/pdf/2510.22832.pdf  
**date**: 2025-10-28  
**keywords**: 层次推理模型, 强化学习, 动态环境  
**abs**: 层次推理模型（HRM）具有强大的推理能力，但仅适用于静态、完全可观测问题。本文旨在扩展HRM到动态、不确定或部分可观测环境，通过整合先前时间步的计算，使模型能重用知识并调整计算量以适应问题难度，从而解决现实世界问题。

---
### 12 ATOM: AdapTive and OptiMized dynamic temporal knowledge graph construction using LLMs
**link**: https://arxiv.org/pdf/2510.22590.pdf  
**date**: 2025-10-28  
**keywords**: 时间知识图谱, 少样本学习, 数据增强  
**abs**: 传统静态知识图谱忽略数据的动态特性。本文提出ATOM，一种少样本且可扩展的方法，用于从非结构化文本构建并更新时间知识图谱（TKG）。ATOM将输入文档拆分为最小化、自包含的“原子”事实，提高了提取全面性和稳定性，并采用双时间建模区分观察时间和有效时间。生成的原子TKG进行并行合并。实证评估显示，ATOM相比基线方法实现了约18%的提取全面性提升、17%的稳定性改善以及超过90%的延迟减少。

---
### 13 Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval
**link**: https://arxiv.org/pdf/2510.22765.pdf  
**date**: 2025-10-28  
**keywords**: 个性化AI, KV-Cache检索, 视觉问答  
**abs**: 本文介绍了Jarvis，一种通过个人KV-Cache检索实现个性化AI助手的框架。该框架将用户特定信息存储在文本和视觉令牌的KV-Cache中，文本令牌通过总结用户信息为元数据创建，视觉令牌通过从用户图像中提取独特图像补丁生成。在回答问题时，Jarvis检索相关KV-Cache确保响应准确性。引入的细粒度基准强调基于局部细节的问答，实验在视觉问答和文本任务中达到最先进结果。

---
### 14 ReCode: Unify Plan and Action for Universal Granularity Control
**link**: https://arxiv.org/pdf/2510.23564.pdf  
**date**: 2025-10-28  
**keywords**: 智能体架构, 递归代码生成, 决策粒度  
**abs**: 现有基于大型语言模型（LLM）的智能体在跨决策粒度操作方面存在局限。本文提出ReCode范式，通过统一代码表示将规划与行动融合：高层计划视为抽象占位函数，智能体递归分解为细粒度子函数直至原始动作，从而动态控制决策粒度。该结构生成多粒度训练数据以增强分层决策，实验表明ReCode在推理性能和数据效率上显著优于基线。

---
### 15 PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation
**link**: https://arxiv.org/pdf/2510.21721.pdf  
**date**: 2025-10-28  
**keywords**: 个性化生成, 伪用户代理, 评价标准  
**abs**: 针对大型语言模型（LLMs）在个性化故事生成中依赖显式反馈或微调的问题，本文提出PREFINE框架。该框架通过用户交互历史构建伪用户代理，并生成用户特定评价标准（rubrics），使智能体能够代表用户进行critique和优化，无需参数更新即可实现个性化生成。在PerDOC和PerMPST数据集上的实验表明，PREFINE在自动评估中优于基线，且伪用户代理和用户特定评价标准对提升个性化性能至关重要。

---
### 16 Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks
**link**: https://arxiv.org/pdf/2510.21866.pdf  
**date**: 2025-10-28  
**keywords**: 自回归模型, 知识任务, 能力瓶颈  
**abs**: 本文研究自回归语言模型在知识密集型任务中的能力上限。通过对OPT和Pythia模型家族的系统评估发现：知识检索任务的精度提升微乎其微，而MMLU数学基准的准确率始终低于随机水平，尽管交叉熵损失显著下降。相比之下，算术等程序性任务表现出常规缩放效应。注意力干预实验显示知识任务对扰动高度敏感，表明现有架构在知识密集型应用中存在能力瓶颈。

---
### 17 ProfileXAI: User-Adaptive Explainable AI
**link**: https://arxiv.org/pdf/2510.22998.pdf  
**date**: 2025-10-28  
**keywords**: 可解释AI, 用户简档, 解释器比较  
**abs**: ProfileXAI是一个模型和领域无关的框架，它将事后解释器（如SHAP、LIME、Anchor）与检索增强型大型语言模型（LLMs）相结合，为不同类型的用户生成解释。该系统通过索引多模态知识库，基于定量标准为每个实例选择解释器，并生成有依据的叙述。在心脏病和甲状腺癌数据集上的评估表明，不同解释器各有优势：LIME在保真度-鲁棒性权衡上表现最佳，Anchor生成最简洁规则，SHAP则获得最高的用户满意度。用户简档调节机制稳定了token使用量，并在不同用户简档中保持了较高评价。

---
### 18 LightAgent: Mobile Agentic Foundation Models
**link**: https://arxiv.org/pdf/2510.22009.pdf  
**date**: 2025-10-28  
**keywords**: 移动智能体, 设备-云协作, GUI代理  
**abs**: 移动GUI代理面临设备端模型性能不足或云端模型成本高的问题。本文提出LightAgent，利用设备-云协作：增强Qwen2.5-VL-3B以实现决策能力；集成高效长推理机制；默认设备端执行，通过实时复杂度评估将子任务升级到云端。在AndroidLab基准测试中，LightAgent达到或接近更大模型的性能，同时显著降低了云成本。

---
### 19 Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability
**link**: https://arxiv.org/pdf/2510.22039.pdf  
**date**: 2025-10-28  
**keywords**: 元强化学习, 预测编码, 部分可观测性  
**abs**: 在部分可观测环境中，学习历史的紧凑表示对于规划和泛化至关重要。本文研究将自监督预测编码模块集成到元强化学习中，以帮助学习贝叶斯最优表示。通过状态机模拟表明，预测编码元RL生成更可解释的表示，近似贝叶斯最优信念状态，并在主动信息寻求任务中成功学习最优策略，而传统元RL则因表示学习不足而挣扎。更好的表示学习带来更好的泛化能力。

---
### 20 Are Agents Just Automata? On the Formal Equivalence Between Agentic AI and the Chomsky Hierarchy
**link**: https://arxiv.org/pdf/2510.23487.pdf  
**date**: 2025-10-28  
**keywords**: 智能体架构, 乔姆斯基层次, 形式化验证  
**abs**: 本文建立了现代智能体AI系统与乔姆斯基层次结构的形式等价：简单反射智能体等价于有限自动机，层次化任务分解智能体等价于下推自动机，采用可读/可写内存的智能体等价于图灵机。该框架优化智能体架构以提高效率，并为形式化验证提供途径，保证安全性和可预测性。通过扩展到概率自动机，解决了LLM智能体的概率特性，允许定量风险分析。

---
### 21 Alita-G: Self-Evolving Generative Agent for Agent Generation
**link**: https://arxiv.org/pdf/2510.23601.pdf  
**date**: 2025-10-28  
**keywords**: 自进化智能体, 模型上下文协议, 领域专家  
**abs**: 本文提出ALITA-G，一种自进化框架，通过生成、抽象和整理模型上下文协议（MCP）工具，将通用智能体转变为领域专家。通用智能体执行任务并合成候选MCP，抽象为参数化原语并整合到MCP Box中。在推理阶段，ALITA-G进行检索增强的MCP选择并执行智能体。在GAIA、PathVQA和Humanity's Last Exam等基准上，ALITA-G取得显著性能提升，同时降低计算成本。

---
### 22 Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning
**link**: https://arxiv.org/pdf/2510.21885.pdf  
**date**: 2025-10-28  
**keywords**: 灾难性遗忘, 行为感知采样, 模型安全  
**abs**: 大型语言模型在良性数据上微调时，常丢失安全行为（灾难性遗忘）。本文提出行为感知采样框架，基于指令-响应行为和危害类别多样性选择安全示例。系统评估表明，该方法在保持有用性的同时显著减少有害输出，仅用0.5%的额外训练数据实现高达41%的有害性降低，提高了安全性和效率。

---
### 23 Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows
**link**: https://arxiv.org/pdf/2510.22109.pdf  
**date**: 2025-10-28  
**keywords**: 长上下文, 对数压缩, 记忆扩展  
**abs**: 大多数长上下文处理方法修改Transformer架构。本文提出替代方法：对输入令牌应用尺度不变的对数压缩，处理压缩表示的标准Transformer保持架构简单。在WikiText-103和PG-19基准上的评估表明，该方法降低了困惑度，且随着压缩时间上下文延长，性能持续提升，表明输入级对数压缩是扩展Transformer长程记忆的有效方法。

---
### 24 Personal Care Utility (PCU): Building the Health Infrastructure for Everyday Insight and Guidance
**link**: https://arxiv.org/pdf/2510.22602.pdf  
**date**: 2025-10-28  
**keywords**: 健康指导, 个人护理, 多模态智能体  
**abs**: 本文提出个人护理实用程序（PCU）——一个用于终身健康指导的控制论系统。PCU持续协调多模态数据、知识和服务，提供三项功能：量身定制的健康信息、主动健康导航和行为指导、医疗事件后的持续解读。通过整合个人传感和人群分析，PCU作为全天候伴侣，改善健康结果并为公共卫生提供新基础。

---
### 25 Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling
**link**: https://arxiv.org/pdf/2510.22317.pdf  
**date**: 2025-10-28  
**keywords**: 基于记忆模型, 可解释性, 生态友好  
**abs**: 本文提出了基于记忆的语言模型作为深度神经网络语言模型的高效、环保替代方案。它提供了对数线性可扩展的下一个token预测性能和强大的记忆能力。通过实现k近邻分类的快速近似，基于记忆的模型在训练和推理中生态足迹小，完全依赖CPU并实现低延迟。内部工作原理简单透明。实现OLIFANT与GPT-2和GPT-Neo的比较表明，在准确性、排放和速度上具有竞争力。

---
### 26 Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models
**link**: https://arxiv.org/pdf/2510.22752.pdf  
**date**: 2025-10-28  
**keywords**: 上下文学习, 时间偏向, 情景检索  
**abs**: 上下文学习受时间和语义关系影响。本文类比人类情景记忆，探究Transformer和状态空间模型区分并检索时间分离事件的能力。使用包含重复标记的序列提示，消除语义干扰，结果显示模型对重复标记后的标记赋予最高概率，但对开头或结尾标记存在偏向。消融实验表明，Transformer中的现象与归纳头相关，状态空间模型表现相似。这加深了对时间偏向和情景检索的理解。

---
### 27 Language Server CLI Empowers Language Agents with Process Rewards
**link**: https://arxiv.org/pdf/2510.22907.pdf  
**date**: 2025-10-28  
**keywords**: 语言服务器, 过程奖励, 代码智能体  
**abs**: 本文提出Lanser-CLI，一个以CLI为先的编排层，为编码智能体介导语言服务器协议（LSP），支持确定性工作流。贡献包括：稳健寻址方案（符号、AST路径选择器）、确定性分析包（标准化响应和元数据）、安全信封用于变异操作（预览和事务性应用）、基于语言服务器事实的过程奖励函数（诊断增量和安全检查）。这使智能体规划与程序现实对齐，适用于过程监督。

---
### 28 Generalization or Memorization: Dynamic Decoding for Mode Steering
**link**: https://arxiv.org/pdf/2510.22099.pdf  
**date**: 2025-10-28  
**keywords**: 泛化能力, 记忆模式, 信息瓶颈  
**abs**: 本文探讨了大型语言模型在泛化能力与对训练数据逐字记忆之间的矛盾。基于信息瓶颈原理，将泛化定义为学习压缩表示，记忆为压缩失败。开发动态模式引导（DMS）推理时算法，包含基于因果的线性探针识别记忆依赖，和动态激活引导机制推动模型到泛化电路。实验表明，DMS在推理和忠实性任务中提高了逻辑一致性和事实准确性。

---
### 29 OlaMind: Towards Human-Like and Hallucination-Safe Customer Service for Retrieval-Augmented Dialogue
**link**: https://arxiv.org/pdf/2510.22143.pdf  
**date**: 2025-10-28  
**keywords**: 检索增强对话, 类人响应, 幻觉减少  
**abs**: 针对检索增强生成（RAG）智能客服系统易产生幻觉和机械响应的问题，提出OlaMind框架。通过“Learn-to-Think”阶段学习人类专家推理，再通过“Learn-to-Respond”阶段执行SFT并结合强化学习自我优化。在社交客服场景的在线A/B实验中，OlaMind在社区支持和直播互动场景下的智能解决率分别提升28.92%和18.42%，人工接管率降低6.08%和7.12%。

---
### 30 Tagging-Augmented Generation: Assisting Language Models in Finding Intricate Knowledge In Long Contexts
**link**: https://arxiv.org/pdf/2510.22956.pdf  
**date**: 2025-10-28  
**keywords**: 长上下文, 知识查找, 标记增强  
**abs**: 针对大型语言模型在长语境中问答的局限性，本文提出标记增强生成（TAG）策略，通过轻量级数据增强帮助模型定位复杂知识，不改变文档完整性。在NoLima和NovelQA基准上，TAG在32K token语境中性能提升高达17%，在多跳推理问答中提升2.9%，主要增强模型在长语境下的知识查找能力。

---
### 31 LangLingual: A Personalised, Exercise-oriented English Language Learning Tool Leveraging Large Language Models
**link**: https://arxiv.org/pdf/2510.23011.pdf  
**date**: 2025-10-28  
**keywords**: 英语学习, 个性化代理, 熟练度跟踪  
**abs**: 本文介绍了LangLingual，一款基于LangChain框架构建、由大型语言模型驱动的对话代理，提供实时语法反馈、生成情境感知的语言练习，并跟踪学习者熟练程度。评估显示该工具具有良好的可用性、积极的学习成果和较高的学习者参与度。

---
### 32 SABlock: Semantic-Aware KV Cache Eviction with Adaptive Compression Block Size
**link**: https://arxiv.org/pdf/2510.22556.pdf  
**date**: 2025-10-28  
**keywords**: KV缓存, 语义分割, 内存优化  
**abs**: KV缓存的内存占用是长上下文大型语言模型推理的主要瓶颈。本文提出SABlock，一种语义感知的KV缓存驱逐框架，通过语义分割对齐压缩边界与语言结构，优化令牌重要性估计，并为每个片段自适应确定最佳块大小。实验表明，SABlock在相同内存预算下优于现有方法，例如在Needle-in-a-Haystack任务上仅用96个KV条目实现99.9%检索准确率，减少内存使用和加速解码。

---
### 33 A Closed-Loop Personalized Learning Agent Integrating Neural Cognitive Diagnosis, Bounded-Ability Adaptive Testing, and LLM-Driven Feedback
**link**: https://arxiv.org/pdf/2510.22559.pdf  
**date**: 2025-10-28  
**keywords**: 个性化学习, 认知诊断, 自适应测试  
**abs**: 本文提出EduLoop-Agent，一个端到端的个性化学习代理，集成神经认知诊断模型、有限能力自适应测试策略和大型语言模型驱动的反馈，形成“诊断-推荐-反馈”闭环框架。实验表明，神经认知诊断模块响应预测良好，自适应推荐提高题目相关性，LLM反馈提供针对性指导，为生成个性化学习轨迹提供可行途径。
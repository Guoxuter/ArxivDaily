根据任务要求，我对输入的论文集合进行了处理：首先，对每篇论文进行摘要和总结，直接使用提供的 `summary` 字段作为 `abs`（确保为中文）；其次，去除重复的论文，但检查后发现所有论文的 `id` 唯一，无重复项；最后，以 Markdown 格式输出，每个论文块以 "---" 分隔，包含序号、标题、链接、日期、关键词（基于 `categories` 字段，转换为逗号分隔字符串）和摘要。

以下是处理后的输出：

---
### 1 Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks
**link**: https://arxiv.org/pdf/2510.14207.pdf  
**date**: 2025-10-17  
**keywords**: cs.AI  
**abs**: 大型语言模型（LLM）代理正驱动越来越多的交互式网络应用，但仍易被滥用和造成伤害。以往的越狱研究主要关注单轮提示，而实际骚扰通常在多轮交互中展开。本文提出了在线骚扰代理基准（Online Harassment Agentic Benchmark），包括：（i）合成多轮骚扰对话数据集；（ii）基于重复博弈论的多代理（如骚扰者、受害者）模拟；（iii）三种针对代理记忆、规划和微调的越狱方法；（iv）混合方法评估框架。研究使用了LLaMA-3.1-8B-Instruct（开源）和Gemini-2.0-flash（闭源）两种主流LLM。结果显示，越狱微调使骚扰成功率接近100%（Llama从57.25-64.19%提升至95.78-96.89%，Gemini从98.46%提升至99.33%），同时将拒绝率降至1-2%。最常见的有毒行为是侮辱（84.9-87.8% vs 未微调的44.2-50.8%）和煽动（81.2-85.1% vs 未微调的31.5-38.8%），表明其防护措施弱于性或种族骚扰等敏感类别。定性评估进一步揭示，受攻击的代理会再现类人攻击特征，例如在规划攻击下表现出马基雅维利/精神病态模式，在记忆攻击下表现出自恋倾向。与直觉相反，闭源和开源模型在多轮对话中表现出不同的升级轨迹，闭源模型显示出显著的脆弱性。总体而言，研究结果表明，多轮和基于理论的攻击不仅成功率高，还能模拟类人骚扰动态，这推动了开发强大安全防护措施以保障在线平台安全的需求。
---
### 2 AI for Service: Proactive Assistance with AI Glasses
**link**: https://arxiv.org/pdf/2510.14359.pdf  
**date**: 2025-10-17  
**keywords**: Personal Memory  
**abs**: 在人工智能从被动工具演变为主动自适应伴侣的时代，我们引入了AI for Service（AI4Service）这一新范式，旨在实现日常生活中的主动实时协助。现有AI服务大多是被动的，仅响应明确的用户命令。我们认为，真正智能且有帮助的助手应能预测用户需求并在适当时机主动采取行动。为实现这一愿景，我们提出Alpha-Service统一框架，解决两个基本挑战：通过从第一视角视频流检测服务机会来确定何时干预，以及知道如何提供通用和个性化服务。受冯·诺依曼计算机架构启发并基于AI眼镜，Alpha-Service包括五个关键组件：感知输入单元、任务调度中央处理单元、工具利用算术逻辑单元、长期个性化记忆单元（Memory Unit for long-term personalization）和自然人类交互输出单元。作为初步探索，我们通过部署在AI眼镜上的多智能体系统实现了Alpha-Service。案例研究（包括实时二十一点顾问、博物馆导游和购物试穿助手）展示了其无缝感知环境、推断用户意图并在无明确提示的情况下提供及时有用协助的能力。
---
### 3 LLM Agents Beyond Utility: An Open-Ended Perspective
**link**: https://arxiv.org/pdf/2510.14548.pdf  
**date**: 2025-10-17  
**keywords**: LLM Memory, Agent Memory  
**abs**: 近年来，LLM智能体充分利用了思维链推理和函数调用。随着其能力的增强，一个重要问题浮现：这种软件能否不仅作为智能的问题解决工具，还能成为一个能够自主规划、设计即时任务并朝着更广泛、更模糊目标推理的实体？为研究此问题，我们采用开放式实验设置，增强预训练LLM智能体的能力，使其能够生成自身任务、积累知识并与环境进行广泛交互。我们对由此产生的开放式智能体进行了定性研究。该智能体能够可靠地遵循复杂的多步骤指令，跨运行存储和重用信息，并提出和解决自身任务，尽管它仍对提示设计敏感，容易产生重复任务，且无法形成自我表征。这些发现既展示了将预训练LLMs调整为开放式智能体的潜力，也揭示了当前的局限性，并为训练智能体管理记忆、高效探索和追求抽象长期目标指明了未来方向。
---
### 4 Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems
**link**: https://arxiv.org/pdf/2510.14133.pdf  
**date**: 2025-10-17  
**keywords**: cs.AI  
**abs**: Agentic AI系统（利用多个自主智能体和大型语言模型）越来越多地用于解决复杂的多步骤任务。这些系统的安全性、安全性和功能性至关重要，尤其是在高风险应用中。然而，当前智能体间通信的生态系统是碎片化的，诸如用于工具访问的模型上下文协议（MCP）和用于协调的智能体到智能体（A2A）协议等协议被孤立分析。这种碎片化造成了语义鸿沟，阻碍了对系统属性的严格分析，并引入了架构错位和可利用的协调问题等风险。为解决这些挑战，我们引入了一个由两个基础模型组成的智能体AI系统建模框架。第一个是宿主智能体模型，形式化了与用户交互、分解任务并通过利用外部智能体和工具来协调其执行的顶级实体。第二个是任务生命周期模型，详细描述了各个子任务从创建到完成的状态和转换，提供了任务管理和错误处理的细粒度视图。这些模型共同提供了一个统一的语义框架，用于推理多AI智能体系统的行为。基于此框架，我们为宿主智能体定义了17个属性，为任务生命周期定义了14个属性，分为活性、安全性、完整性和公平性。这些属性以时序逻辑表达，能够对系统行为进行形式化验证，检测协调边缘情况，并防止死锁和安全漏洞。通过这项工作，我们引入了第一个严格接地、领域无关的框架，用于系统分析、设计和部署正确、可靠和健壮的智能体AI系统。
---
### 5 ShishuLM: Lightweight Language Model with Hybrid Decoder-MLP Architecture and Paired Weight Sharing
**link**: https://arxiv.org/pdf/2510.13860.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 尽管Transformer架构在自然语言处理任务上取得了最先进的性能，但这些模型带来了巨大的内存和计算开销。最近的研究发现这些模型中存在显著的架构冗余，为在不影响性能的情况下进行优化提供了机会。借鉴AI可解释性和推理时层剪枝的研究见解，我们提出了一种高效的语言模型架构ShishuLM，它减少了参数数量和键值（KV）缓存需求。鉴于小型语言模型（SLMs）在智能体AI系统中的重要性日益增加，我们在两个不同规模的SLMs上评估了我们的方法。分析表明，在中等上下文场景中，归一化与注意力计算大致与输入成线性关系，使得整个Transformer块可以通过多层感知器（MLPs）近似。结果显示，与父模型相比，ShishuLM在训练和推理期间的内存需求减少了高达25%，延迟改善了高达40%。我们的实验和分析结果为从预训练角度构建更高效的SLM架构提供了见解。
---
### 6 Knowledge Reasoning Language Model: Unifying Knowledge and Language for Inductive Knowledge Graph Reasoning
**link**: https://arxiv.org/pdf/2510.13909.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 归纳知识图谱推理（KGR）旨在发现包含未知实体和关系的开放域知识图谱中的事实，这对KGR模型理解不确定的知识图谱组件构成挑战。现有研究提出了知识图谱基础模型（KGFMs），通过学习跨图谱的结构不变性来处理这种不确定性。最近，大型语言模型（LLMs）展示了强大的开放域知识推理能力，因此最新研究聚焦于基于LLM的KGFMs，将LLM知识与知识图谱上下文整合用于归纳KGR。然而，LLMs的内在知识可能被稀疏的知识图谱上下文掩盖，导致LLM知识失真，进而对模型推理造成不可逆损害。此外，现有基于LLM的KGR方法仍难以完全约束LLMs中的生成幻觉，严重限制了推理结果的可信度。为解决这些限制，本文提出知识推理语言模型（KRLM），在整个KGR过程中实现LLM知识与知识图谱上下文的统一协调。具体而言，设计了知识推理语言（KRL）指令格式和KRL分词器，以对齐LLM知识与知识图谱表示；提出KRL注意力层，通过动态知识记忆机制协调内在LLM知识与额外知识图谱上下文；最后，提出结构感知的下一个实体预测器，将推理结果严格约束在可信知识域内。在25个真实世界归纳KGR数据集上的大量实验结果证明了所提KRLM的显著优越性。
---
### 7 DPRF: A Generalizable Dynamic Persona Refinement Framework for Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents and Humans
**link**: https://arxiv.org/pdf/2510.14205.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 新兴的大语言模型角色扮演智能体（LLM RPAs）旨在模拟个体人类行为，但其角色逼真度常因手动创建的档案（如精选信息和人格特征）未经与目标个体的对齐验证而受损。为解决这一局限，本研究提出动态角色细化框架（DPRF）。DPRF通过迭代识别生成行为与人类真实行为之间的认知差异（通过自由形式或基于理论的结构化分析），并优化角色档案以减轻这些差异，从而优化LLM RPAs的行为与目标个体的对齐。
---
### 8 Agentic NL2SQL to Reduce Computational Costs
**link**: https://arxiv.org/pdf/2510.14808.pdf  
**date**: 2025-10-17  
**keywords**: cs.AI  
**abs**: 将自然语言查询转换为SQL查询（NL2SQL或Text-to-SQL）已通过大型语言模型（LLMs）得到增强。在大型SQL数据库集合上使用LLMs执行NL2SQL方法需要处理大量数据库元信息，导致提示词冗长、标记数量多且处理成本高。为解决此挑战，我们引入Datalake Agent，这是一个智能体系统，旨在使LLM更高效地解决NL2SQL任务。与直接求解器一次性将所有元信息放入提示词调用LLM不同，Datalake Agent采用交互式循环来减少元信息使用。在循环中，LLM用于推理框架，选择性地仅请求解决表问答任务所需的必要信息。在包含23个数据库和100个表问答任务的集合上评估表明，Datalake Agent最多可减少87%的LLM标记使用量，在保持竞争性能的同时大幅降低成本。
---
### 9 The Gatekeeper Knows Enough
**link**: https://arxiv.org/pdf/2510.14881.pdf  
**date**: 2025-10-17  
**keywords**: cs.AI  
**abs**: 大型语言模型（LLMs）越来越多地被部署为自主智能体，但其实际效用受限于有限的上下文窗口和状态不同步，这源于LLMs的无状态特性和低效的上下文管理。这些限制导致输出不可靠、行为不可预测及资源使用低效，尤其在与代码库和文档等大型结构化敏感知识系统交互时。为此，我们引入Gatekeeper协议，一种新型领域无关框架，用于管理智能体-系统交互。该协议要求智能体首先在系统的极简低保真“潜状态”表示上操作推理，以策略性按需请求高保真上下文。所有交互通过统一JSON格式调解，作为声明性状态同步协议，确保智能体的系统模型可验证地基于系统实际情况。通过软件开发领域的参考实现Sage证明，该方法显著提高智能体可靠性，通过最小化标记消耗提升计算效率，并实现与复杂系统的可扩展交互，为构建更健壮、可预测和接地的AI智能体奠定基础。
---
### 10 Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates
**link**: https://arxiv.org/pdf/2510.14900.pdf  
**date**: 2025-10-17  
**keywords**: cs.AI  
**abs**: 企业智能平台需集成众多第三方供应商日志以执行下游任务，但测试时供应商文档常不可用（如放错、不匹配、格式差或不完整），导致模式映射困难。我们引入一种强化学习智能体，可在无标记示例或模型权重更新情况下自我改进。推理时，智能体：1）识别模糊字段映射尝试；2）生成目标网络搜索查询以收集外部证据；3）应用基于置信度的奖励迭代优化映射。将Microsoft Defender for Endpoint日志转换为通用模式的实验显示，使用GPT-4o经过100次迭代，映射准确率从56.4%（仅LLM）提升至72.73%（RAG）再到93.94%，同时将需专家审查的低置信度映射数量减少85%。该方法提供证据驱动的透明解决方案，为更健壮、负责任和可扩展的行业问题解决铺平道路。
---
### 11 Agentic Entropy-Balanced Policy Optimization
**link**: https://arxiv.org/pdf/2510.14545.pdf  
**date**: 2025-10-17  
**keywords**: cs.LG  
**abs**: 近年来，智能体强化学习（Agentic RL）在激励网络智能体的多轮、长horizon工具使用能力方面取得了显著进展。虽然主流的智能体RL算法在熵的指导下自主探索高不确定性的工具调用步骤，但过度依赖熵信号可能会带来进一步的约束，导致训练崩溃。本文深入研究了熵带来的挑战，并提出了智能体熵平衡策略优化（AEPO），这是一种旨在在rollout和策略更新阶段平衡熵的智能体RL算法。AEPO包括两个核心组件：（1）动态熵平衡rollout机制，通过熵预监控自适应分配全局和分支采样预算，同时对连续的高熵工具调用步骤施加分支惩罚，以防止过度分支问题；（2）熵平衡策略优化，在高熵裁剪项中插入停止梯度操作，以保留并适当缩放高熵token的梯度，同时结合熵感知优势估计，优先学习高不确定性token。在14个具有挑战性的数据集上的结果表明，AEPO持续优于7种主流RL算法。仅使用1K RL样本，配备AEPO的Qwen3-14B取得了令人印象深刻的结果：在GAIA上Pass@1为47.6%，在Humanity's Last Exam上为11.2%，在WebWalker上为43.0%；Pass@5在GAIA上为65.0%，在Humanity's Last Exam上为26.0%，在WebWalker上为70.0%。进一步分析表明，AEPO在保持稳定策略熵的同时提高了rollout采样多样性，促进了可扩展的网络智能体训练。
---
### 12 Beyond Multi-Token Prediction: Pretraining LLMs with Future Summaries
**link**: https://arxiv.org/pdf/2510.14751.pdf  
**date**: 2025-10-17  
**keywords**: cs.LG  
**abs**: 下一个token预测（NTP）推动了大型语言模型（LLMs）的成功，但它在长程推理、规划和创意写作方面存在困难，这些局限性很大程度上归因于教师强制训练。多token预测（MTP）通过一次预测多个未来token部分缓解了这些问题，但它主要捕捉短程依赖关系，改进有限。我们提出未来摘要预测（FSP），通过训练一个辅助头来预测长期未来的紧凑表示，保留与长文本生成相关的信息。我们探索了FSP的两种变体：手工制作的摘要（例如，序列未来的词袋摘要）和学习到的摘要（使用从右到左训练的反向语言模型生成的嵌入）。大规模预训练实验（30亿和80亿参数模型）表明，FSP在数学、推理和编码基准测试中均优于NTP和MTP。
---
### 13 Attention Is All You Need for KV Cache in Diffusion LLMs
**link**: https://arxiv.org/pdf/2510.14973.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 该研究聚焦于扩散大型语言模型（DLMs）的键值（KV）缓存自适应重计算方法，旨在平衡预测准确性与解码延迟。现有方法在每个去噪步骤和网络层均重新计算所有令牌的QKV，导致浅层KV状态冗余计算。研究提出三点关键发现：1）远距离MASK令牌可作为长度偏差在预测窗口外进行块级缓存；2）KV动态性随网络深度增加，仅需从深层开始选择性刷新；3）注意力权重最高的令牌KV漂移最小，可作为其他令牌缓存更新的下界。基于此，作者设计了Elastic-Cache策略，通过注意力感知漂移测试决定刷新时机，并采用深度感知调度确定刷新范围（复用浅层缓存与窗口外MASK缓存）。该方法在LLaDA系列模型的数学推理和代码生成任务中实现8.7×（GSM8K）至45.1×（长序列）的加速，同时保持生成质量，为DLMs的高效部署提供了优化方案。
---
### 14 Information Gain-based Policy Optimization: A Simple and Effective Approach for Multi-Turn LLM Agents
**link**: https://arxiv.org/pdf/2510.14967.pdf  
**date**: 2025-10-17  
**keywords**: Agent Memory  
**abs**: 基于大型语言模型（LLM）的智能体越来越多地通过强化学习（RL）进行训练，以增强其通过工具使用与外部环境交互的能力，特别是在需要多轮推理和知识获取的基于搜索的场景中。然而，现有方法通常依赖于仅在最终答案时提供的基于结果的奖励。在多轮场景中，这种奖励稀疏性问题尤为突出，长轨迹加剧了两个关键问题：（i）优势崩溃，即所有轨迹都获得相同的奖励，无法提供有用的学习信号；（ii）缺乏细粒度的信用分配，尤其是在长 horizon 任务中，轮次之间的依赖关系被掩盖。本文提出了基于信息增益的策略优化（IGPO），这是一种简单而有效的 RL 框架，为多轮智能体训练提供密集的内在监督。IGPO 将每个交互轮次建模为获取关于真实情况信息的增量过程，并将轮次级奖励定义为策略产生正确答案的概率的边际增加。与依赖外部奖励模型或昂贵蒙特卡洛估计的先前过程级奖励方法不同，IGPO 直接从模型自身的信念更新中导出内在奖励。这些内在轮次级奖励与结果级监督相结合，形成密集的奖励轨迹。在域内和域外基准上的大量实验表明，IGPO 在多轮场景中始终优于强基线，实现了更高的准确性和改进的样本效率。
---
### 15 LLMs as Scalable, General-Purpose Simulators For Evolving Digital Agent Training
**link**: https://arxiv.org/pdf/2510.14969.pdf  
**date**: 2025-10-17  
**keywords**: Agent Memory  
**abs**: 数字智能体需要多样化、大规模的用户界面（UI）轨迹来泛化到现实世界的任务中，但从人类标注、基础设施和工程角度来看，收集此类数据的成本极高。为此，我们引入了UI-Simulator，这是一种可扩展的范式，通过生成结构化的UI状态和转换来大规模合成训练轨迹。该范式集成了用于生成多样化UI状态的数字世界模拟器、用于连贯探索的引导式滚动过程，以及用于生成高质量和多样化智能体训练轨迹的轨迹包装器。我们进一步提出了UI-Simulator-Grow，这是一种有针对性的扩展策略，通过优先处理高影响任务并合成信息丰富的轨迹变体，实现更快速和数据高效的扩展。在WebArena和AndroidWorld上的实验表明，尽管使用较弱的教师模型，UI-Simulator仍能与在真实UI上训练的开源智能体相媲美甚至超越，并且具有显著更好的鲁棒性。此外，UI-Simulator-Grow仅使用Llama-3-8B-Instruct作为基础模型就能达到Llama-3-70B-Instruct的性能，突显了有针对性的合成扩展范式在持续高效增强数字智能体方面的潜力。
---
### 16 Learning to Undo: Rollback-Augmented Reinforcement Learning with Reversibility Signals
**link**: https://arxiv.org/pdf/2510.14503.pdf  
**date**: 2025-10-17  
**keywords**: cs.LG  
**abs**: 本文提出了一种可逆学习框架，旨在提高基于价值的强化学习智能体的鲁棒性和效率，解决在部分不可逆环境中价值高估的脆弱性和不稳定性问题。该框架包含两个互补的核心机制：一个基于经验推导的转移可逆性度量（称为Phi(s,a)）和选择性状态回滚操作。我们引入了一种在线的逐状态动作估计器Phi，用于量化在固定时间范围K内返回先前状态的可能性。该度量用于动态调整时序差分更新过程中的惩罚项，将可逆性感知直接整合到价值函数中。系统还包括一个选择性回滚算子：当某个动作产生的预期回报显著低于其瞬时估计值且违反预定义阈值时，智能体将受到惩罚并返回到前一状态，而非继续前进。这一机制可中断次优高风险轨迹并避免灾难性步骤。通过结合可逆性感知评估与目标回滚，该方法提高了安全性、性能和稳定性。在CliffWalking v0环境中，该框架将灾难性坠落减少了99.8%以上，并使平均回合回报增加了55%；在Taxi v3环境中，它将非法动作抑制了99.9%以上，累积奖励提高了65.7%，同时显著降低了两个环境中的奖励方差。消融研究证实，回滚机制是实现这些安全性和性能提升的关键组件，为安全可靠的序列决策迈出了坚实一步。
---
### 17 ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models
**link**: https://arxiv.org/pdf/2510.14077.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）在信息增量呈现的多轮对话中会出现显著的性能下降。由于多轮对话是LLMs日常交互的典型特征，这种性能退化对其实际可用性构成了严峻挑战。本文假设模型不确定性的突然增加标志着多轮LLM交互中的失准问题，并利用这一洞见来动态重新对齐对话上下文。研究引入了ERGO（Entropy-guided Resetting for Generation Optimization）框架，该框架通过下一个token分布的香农熵持续量化模型的内部不确定性，并在检测到熵值急剧上升时触发自适应提示整合。ERGO将不确定性视为首要信号而非需要消除的干扰，接纳语言和建模中的可变性，对不确定性进行表示和响应。在具有增量揭示指令的多轮任务中，ERGO相比标准基线平均性能提升56.6%，能力（峰值性能）提高24.7%，不可靠性（性能变异性）降低35.3%，证明感知不确定性的干预措施能够同时提升对话AI的准确性和可靠性。
---
### 18 MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems
**link**: https://arxiv.org/pdf/2510.14252.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 传统的RAG范式通常通过理解接收到的查询所对应的相关文本块来工作，这本质上限制了知识内化的深度和推理能力。为解决这一局限性，我们的研究将RAG中的文本处理从被动分块转变为主动理解，将此过程定义为文档记忆提取，旨在模拟人类阅读时的认知过程。在此基础上，我们提出了场景感知文档记忆混合（MoM）框架，该框架旨在高效处理多领域文档，并训练小型语言模型（SLMs）获得主动探索和构建文档记忆的能力。MoM首先指导大型语言模型（LLMs）模拟领域专家生成文档逻辑大纲，从而指导结构化分块和核心内容提取。它采用多路径采样和多视角评估机制，专门设计了代表块清晰度和提取完整性的综合指标来选择最优文档记忆。此外，为了在SLMs训练过程中注入更深层次的类人阅读能力，我们融入了反向推理策略，从高质量结果中推导出精细化的专家思维路径。最后，利用MoM生成的多种形式内容，我们开发了三层文档记忆检索机制，并从概率建模的角度提供了理论证明。在三个不同领域的广泛实验结果表明，MoM框架不仅解决了现有RAG系统中的文本分块难题，为LLMs提供了语义完整的文档记忆，还为SLMs实现以人为中心的智能文本处理铺平了道路。
---
### 19 Your Next Token Prediction: A Multilingual Benchmark for Personalized Response Generation
**link**: https://arxiv.org/pdf/2510.14398.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）在通用下一个token预测方面表现出色，但在生成反映个人真实交流方式的响应（例如以自己的风格回复电子邮件或社交消息）方面仍存在困难。然而，由于隐私问题，真实的社交媒体或电子邮件历史难以收集。为解决这一问题，我们提出了“Your Next Token Prediction（YNTP）”任务，该任务通过受控的人机对话来建模用户精确的词汇选择。我们构建了一个包含英语、日语和中文的100个对话会话的多语言基准，其中用户基于MBTI维度与具有心理基础的NPC进行为期五天的交互。这种设置捕捉了自然的日常生活交流模式，并能够分析用户的内部模型。我们评估了基于提示和基于微调的个性化方法，建立了YNTP的首个基准，并为用户对齐的语言建模奠定了基础。数据集可在以下网址获取：
---
### 20 Interpreting the Latent Structure of Operator Precedence in Language Models
**link**: https://arxiv.org/pdf/2510.13908.pdf  
**date**: 2025-10-17  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）已展示出令人印象深刻的推理能力，但在算术任务上仍存在困难。先前研究多关注输出或提示策略，而模型进行算术计算的内部结构仍是开放性问题。本研究通过开源指令微调的LLaMA 3.2-3B模型，调查LLMs是否在内部表示中编码运算符优先级。构建包含三个操作数和两个运算符的算术表达式数据集，改变括号顺序和位置，追踪中间结果是否出现在模型残差流中。应用logit lens、线性分类探针和UMAP几何可视化等可解释性技术，发现中间计算存在于残差流中（尤其在MLP块之后），且模型在注意力层后的运算符嵌入中线性编码优先级。提出部分嵌入交换技术，通过交换运算符间高影响嵌入维度修改优先级。
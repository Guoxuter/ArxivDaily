### 1 Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism

**link**: https://arxiv.org/pdf/2510.26083.pdf
**date**: 2025-10-31
**keywords**: cs.LG
**abs**: 专业通才模型（SGM）旨在保留广泛能力的同时在目标领域实现专家级性能。本文提出Nirvana模型，采用任务感知记忆机制和线性时间复杂度，通过任务感知记忆触发器动态调整参数以适应领域变化。实验表明，Nirvana在通用语言任务和医疗任务（如MRI重建）上优于现有模型，能生成高质量临床报告。

---

### 2 MemEIC: A Step Toward Continual and Compositional Knowledge Editing

**link**: https://arxiv.org/pdf/2510.25798.pdf
**date**: 2025-10-31
**keywords**: cs.LG
**abs**: 大型视觉语言模型（LVLMs）需持续更新知识，但现有方法忽视多模态特性。本文提出MemEIC方法，支持视觉和文本知识的顺序组合编辑，采用双外部记忆和双LoRA适配器，结合知识连接器整合跨模态信息。实验证明，MemEIC在多模态问题上性能显著提升，并有效保留先前编辑。

---

### 3 Efficient Online Learning with Predictive Coding Networks: Exploiting Temporal Correlations

**link**: https://arxiv.org/pdf/2510.25993.pdf
**date**: 2025-10-31
**keywords**: cs.LG
**abs**: 预测编码（PC）框架提供生物合理的在线学习方案，但计算开销大。本文提出PCN-TA模型，利用时序相关性保留潜在状态，减少计算需求。在机器人感知数据集上，PCN-TA比反向传播减少10%权重更新，推理步骤减少50%，适用于边缘设备和实时适应。

---

### 4 Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle

**link**: https://arxiv.org/pdf/2510.26347.pdf
**date**: 2025-10-31
**keywords**: cs.LG
**abs**: 本文研究强化学习（RL）在随机、稀疏和非平稳环境中的应用，使用自主水下机器人（AUV）探测水下污染云。通过改进蒙特卡洛方法、引入位置记忆防止状态重访，显著提升性能，证明记忆机制在复杂环境决策中的关键作用。

---

### 5 AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache

**link**: https://arxiv.org/pdf/2510.25979.pdf
**date**: 2025-10-31
**keywords**: cs.CL
**abs**: 大型语言模型（LLMs）预填充阶段的自注意力计算存在二次复杂度瓶颈。本文提出AttnCache框架，通过注意力图记忆数据库和相似性搜索重用预缓存图，减少计算开销。实验显示，AttnCache在CPU和GPU上分别实现1.2倍和1.6倍端到端加速，精度下降可忽略。

---

### 6 Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning

**link**: https://arxiv.org/pdf/2510.26389.pdf
**date**: 2025-10-31
**keywords**: cs.LG
**abs**: 深度多智能体强化学习（MARL）在长期依赖任务中面临探索效率低和信息冗余问题。本文提出新框架，通过中央智能体动态优化上下文长度，结合低频截断方法提取全局时间趋势。实验在PettingZoo等基准上达到SOTA性能。

---

### 7 Kimi Linear: An Expressive, Efficient Attention Architecture

**link**: https://arxiv.org/pdf/2510.26692.pdf
**date**: 2025-10-31
**keywords**: cs.CL
**abs**: 本文介绍Kimi Linear混合线性注意力架构，核心为Kimi Delta Attention（KDA）模块，通过精细门控机制增强有限状态RNN记忆。定制分块算法减少计算量，在短/长上下文和强化学习任务中优于全注意力模型。

---

### 8 Deep sequence models tend to memorize geometrically; it is unclear why

**link**: https://arxiv.org/pdf/2510.26745.pdf
**date**: 2025-10-31
**keywords**: cs.LG
**abs**: 序列建模中，原子事实记忆常被视为共现查找。本文分析Transformer推理，发现模型必须合成几何结构编码全局实体关系，而非依赖局部共现。这简化推理任务，揭示了深度序列模型记忆的几何特性。

---

### 9 Clone Deterministic 3D Worlds with Geometrically-Regularized World Models

**link**: https://arxiv.org/pdf/2510.26782.pdf
**date**: 2025-10-31
**keywords**: cs.LG
**abs**: 世界模型在长视野预测中表现脆弱，主要因表征质量问题。本文提出几何正则化世界模型（GRWM），强制潜在表征与真实拓扑对齐，提升滚动保真度。在确定性3D环境中，显著改进鲁棒性，是构建智能体记忆的有效途径。

---

### 10 RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline

**link**: https://arxiv.org/pdf/2510.25941.pdf
**date**: 2025-10-31
**keywords**: LLM Memory, Agent Memory
**abs**: 本文提出RECAP智能体管道，从LLM输出中提取和验证记忆的训练数据。通过反馈驱动循环和越狱模块克服对齐障碍，在EchoTrace基准上，受版权文本提取的ROUGE-L分数提升24%，证明其高效性。

---

### 11 InfoFlow: Reinforcing Search Agent Via Reward Density Optimization

**link**: https://arxiv.org/pdf/2510.26575.pdf
**date**: 2025-10-31
**keywords**: cs.CL
**abs**: 强化学习与可验证奖励（RLVR）在深度搜索中受低奖励密度困扰。本文提出InfoFlow框架，通过子问题分解、失败引导提示和双智能体优化提高奖励密度。在搜索基准上，轻量级LLM性能接近高级模型。

---

### 12 Graph-Enhanced Policy Optimization in LLM Agent Training

**link**: https://arxiv.org/pdf/2510.26270.pdf
**date**: 2025-10-31
**keywords**: Agent Memory
**abs**: 基于群体的强化学习训练多轮交互式LLM智能体时存在结构盲目性。本文提出图增强策略优化（GEPO），动态构建状态转移图，利用图论中心性提供学习信号。在ALFWorld等基准上，成功率提升4.1%-10.9%。

---

### 13 GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks

**link**: https://arxiv.org/pdf/2510.26098.pdf
**date**: 2025-10-31
**keywords**: cs.AI
**abs**: 大型视觉语言模型（VLMs）在GUI任务自动化中落后于人类。本文提炼GUI知识为界面感知、交互预测和指令理解三维度，引入GUI Knowledge Bench基准。评估显示VLMs在系统状态感知和动作预测上存在困难，为构建更强GUI智能体提供框架。

---

### 14 The FM Agent

**link**: https://arxiv.org/pdf/2510.26144.pdf
**date**: 2025-10-31
**keywords**: cs.AI
**abs**: 本文提出FM Agent通用多智能体框架，结合LLM推理与大规模进化搜索。创新包括专家指导初始化、进化采样策略、领域特定评估器和分布式基础设施。在运筹学、机器学习等领域达到SOTA结果，如ALE-Bench提升5.2%。

---

### 15 Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles

**link**: https://arxiv.org/pdf/2510.26242.pdf
**date**: 2025-10-31
**keywords**: cs.AI
**abs**: 本文提出REG-TSC框架，用于紧急车辆响应的可泛化交通信号控制。采用紧急感知推理和RAG增强决策，结合类型无关表示和奖励引导优化。在真实道路网络上，减少42%旅行时间和83%紧急车辆等待时间，优于现有方法。
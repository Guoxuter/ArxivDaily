以下是根据任务要求处理的论文摘要和总结。我已去除重复的论文（基于论文ID），并确保输出格式符合Markdown要求。每个论文条目包括标题、链接、日期、关键词（基于输入中的`categories`字段）和中文摘要（直接使用输入中的`summary`字段，已为中文）。论文按输入顺序编号，从1开始。

---
### 1 HIPPD: Brain-Inspired Hierarchical Information Processing for Personality Detection  
**link**: https://arxiv.org/pdf/2510.09893.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 文本人格检测旨在基于语言模式推断个体的人格特质。然而，现有机器学习方法往往难以捕捉跨多个帖子的上下文信息，并且在语义稀疏环境中难以提取具有代表性和鲁棒性的特征。本文提出了HIPPD，这是一种受大脑启发的人格检测框架，模拟人类大脑的分层信息处理。HIPPD利用大型语言模型模拟大脑皮层，实现全局语义推理和深度特征抽象。一个动态记忆模块模拟前额叶皮层，执行关键特征的自适应门控和选择性保留，所有调整均由多巴胺能预测误差反馈驱动。随后，一组专门的轻量级模型模拟基底神经节，通过严格的“赢家通吃”机制动态路由，以捕捉它们最擅长识别的人格相关模式。在Kaggle和Pandora数据集上的大量实验表明，HIPPD持续优于最先进的基线模型。  
---
### 2 Diversity Augmentation of Dynamic User Preference Data for Boosting Personalized Text Summarizers  
**link**: https://arxiv.org/pdf/2510.10082.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 文档摘要旨在高效提取用户相关内容，但其本质上受个体主观性影响，因此在多方面文档中识别主观显著信息具有挑战性。这凸显了个性化摘要的必要性。然而，个性化摘要模型的训练一直面临困难，特别是因为包含用户偏好历史（即点击-跳过轨迹）和预期（黄金参考）摘要的多样化训练数据稀缺。MS/CAS PENS数据集是宝贵资源，但仅包含偏好历史而无目标摘要，无法进行端到端监督学习，且其有限的主题转换多样性进一步限制了泛化能力。为此，我们提出PerAugy，这是一种基于跨轨迹洗牌和摘要内容扰动的新型数据增强技术，显著提高了个性化摘要框架中四种最先进基线用户编码器的准确性（最佳结果：AUC提升0.132）。我们选择两种此类最先进的摘要器框架作为基线，观察到当用相应改进的用户编码器增强时，它们在个性化方面持续提升（平均提升：PSE-SU4指标提高61.2%）。作为对PerAugy生成的增强数据中诱导多样性作用的事后分析，我们引入了三个数据集多样性指标——TP、RTC和DegreeD来量化诱导的多样性。我们发现TP和DegreeD与用户编码器在PerAugy生成的数据集上的所有准确性指标都强相关，表明增加的数据集多样性是推动性能提升的关键因素。  
---
### 3 Preference-Aware Memory Update for Long-Term LLM Agents  
**link**: https://arxiv.org/pdf/2510.09720.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 基于LLM的智能体的推理能力的关键因素之一是其利用长期记忆的能力。整合长期记忆机制使智能体能够基于历史交互做出明智决策。尽管最近的进展显著改进了存储和检索组件（如通过将记忆编码为密集向量进行相似性搜索或将记忆组织为结构化知识图谱），但大多数现有方法在记忆更新方面存在不足。特别是，它们缺乏根据不断变化的用户行为和上下文动态优化偏好记忆表示的机制。为解决这一差距，本文提出了偏好感知记忆更新机制（PAMU），以实现动态和个性化的记忆优化。该机制通过整合滑动窗口平均（SW）与指数移动平均（EMA），构建融合的偏好感知表示，既能捕捉短期波动，又能反映长期用户倾向。在LoCoMo数据集的五个任务场景上进行的实验结果表明，该机制能够显著提高五种基线模型中LLM的输出质量，验证了其在长期对话中的有效性。  
---
### 4 DELTA: Dynamic Layer-Aware Token Attention for Efficient Long-Context Reasoning  
**link**: https://arxiv.org/pdf/2510.09883.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型推理模型（LRMs）通过生成长长的中间步骤链在具有挑战性的基准测试中实现了最先进的性能，但其推理成本主要由解码过程主导，其中每个新标记都必须关注整个不断增长的序列。现有的稀疏注意力方法通过修剪键值（KV）缓存来减少计算量，但由于累积选择错误以及标记在长推导过程中的动态重要性，它们在推理任务上遭受严重的精度下降。我们提出了DELTA，一种无需训练的稀疏注意力机制，能够在不牺牲模型精度的情况下实现计算效率。DELTA将Transformer层分为三组：使用全注意力的初始层、通过聚合头级注意力分数识别显著标记的一小部分选择层，以及仅关注所选子集的后续稀疏注意力层。这种设计在GPU内存中保留完整的KV缓存以确保精度，同时避免在许多层上进行昂贵的全注意力计算。在AIME和GPQA-Diamond等推理基准测试中，DELTA在精度上匹配或超过全注意力，同时将关注的标记数量减少高达5倍，并实现1.5倍的端到端加速。我们的结果表明，选择性重用中间注意力图为高效的长上下文推理提供了一条稳健的路径。  
---
### 5 BILLY: Steering Large Language Models via Merging Persona Vectors for Creative Generation  
**link**: https://arxiv.org/pdf/2510.10157.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 多LLM系统通过模拟人类集体智能来增强大型语言模型的创造力，但存在计算成本高和推理延迟等显著缺点。为解决这些限制，本文提出BILLY（BlendIng persona vectors for Large Language model creativitY），这是一种无需训练的框架，能够在单个模型中捕获多LLM协作的优势，即引入多样化视角和专业知识。BILLY通过直接在模型的激活空间中提取和融合多个不同的人格向量来运作。在推理时，使用这种融合后的向量引导模型的生成过程，无需显式的多LLM通信即可实现多视角输出。在创造力导向的基准测试中，BILLY超越了单模型提示和传统多LLM方法，同时显著减少了推理时间和计算成本。分析进一步表明，不同的人格向量可以融合，以实现对生成的互补方面的有效控制和更高的可解释性。  
---
### 6 Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label Detector for Noise-Robust Learning  
**link**: https://arxiv.org/pdf/2510.10208.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）的参数高效微调（PEFT）在各种下游任务中表现出令人印象深刻的性能。然而，在许多现实场景中，收集的训练数据不可避免地包含噪声标签。为了从噪声标签中学习，大多数解决方案选择损失较小的样本进行模型训练。但所选样本反过来会影响下一次迭代的损失计算，不准确的初始选择可能导致恶性循环，从而产生次优性能。为打破这一循环，本文提出Delora，一种将样本选择与模型训练解耦的新框架。在样本选择方面，Delora通过引入干净LoRA和噪声LoRA建立噪声标签检测器。得益于记忆效应，干净LoRA被鼓励记忆干净数据，而噪声LoRA被约束记忆标记错误的数据，后者作为区分干净和噪声样本的可学习阈值。在模型训练方面，Delora可以使用精心选择的样本无缝微调语言模型。在合成和现实噪声数据集上的实验表明，Delora在噪声标签检测和文本分类中是有效的。  
---
### 7 FML-bench: A Benchmark for Automatic ML Research Agents Highlighting the Importance of Exploration Breadth  
**link**: https://arxiv.org/pdf/2510.10472.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）引发了对自动机器学习研究代理的浓厚兴趣。其中，能够自主提出想法并进行机器学习实验的代理尤为有前景，它们通过基于实验结果迭代改进想法，最大化研究自动化并加速科学进展。然而，全面评估此类代理仍具挑战性。现有基准往往过度强调工程方面而忽视学术严谨性，阻碍了对代理在机器学习研究中科学能力的清晰评估。它们还存在任务多样性有限、过度强调面向应用的任务而非基础研究问题以及难以扩展到实际研究环境等问题。为解决这些局限性，我们引入FML-bench，一个旨在评估自动机器学习研究代理在8个多样化且基础的机器学习研究问题上表现的基准。它减轻了编码负担，强调基础问题而非特定用例，提供高任务多样性，并可扩展到现实世界的机器学习GitHub仓库。此外，我们提出了一个统一的评估框架，包含五个互补指标，旨在全面评估代理在我们基准上的性能。我们在FML-bench上评估了最先进的自动研究代理，发现采用广泛研究探索策略的代理优于那些专注于狭窄但深入探索的代理。这些发现表明，强调探索的广度可能比仅关注增量改进带来更有效的研究成果。  
---
### 8 AssoMem: Scalable Memory QA with Multi-Signal Associative Retrieval  
**link**: https://arxiv.org/pdf/2510.10397.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 从大规模记忆中准确回忆信息仍然是增强记忆的AI助手执行问答（QA）任务的核心挑战，尤其是在相似性密集的场景中，现有方法主要依赖与查询的语义距离进行检索。受人类关联信息链接方式的启发，我们提出了AssoMem，这是一种新颖的框架，它构建了一个关联记忆图，将对话话语锚定到自动提取的线索上。这种结构提供了对话上下文的丰富组织视图，并促进了基于重要性的排序。此外，AssoMem使用自适应互信息（MI）驱动的融合策略整合了多维检索信号——相关性、重要性和时间对齐。在三个基准数据集和新引入的MeetingQA数据集上的大量实验表明，AssoMem持续优于最先进的基线，验证了其在上下文感知记忆回忆方面的优越性。  
---
### 9 LLM$\times$MapReduce-V3: Enabling Interactive In-Depth Survey Generation through a MCP-Driven Hierarchically Modular Agent System  
**link**: https://arxiv.org/pdf/2510.10890.pdf  
**date**: 2025-10-14  
**keywords**: Agent Memory  
**abs**: 本文介绍了LLM×MapReduce-V3，这是一个用于长文本调查生成的分层模块化智能体系统。该系统基于先前的LLM×MapReduce-V2，整合了多智能体架构，其中各个功能组件（如框架初始化、摘要构建和框架优化）被实现为独立的模型-上下文-协议（MCP）服务器。这些原子服务器可聚合为更高层级的服务器，形成分层结构系统。高层规划器智能体通过根据MCP工具描述和执行历史选择适当模块来动态协调工作流，促进了人在回路中的干预，使用户能更好地控制和定制研究过程。通过多轮交互，系统精确捕捉预期的研究视角以生成全面框架，进而发展为深度调查。人类评估表明，该系统在内容深度和长度上均超越代表性基线，突显了基于MCP的模块化规划的优势。  
---
### 10 UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models  
**link**: https://arxiv.org/pdf/2510.10481.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 扩散大型语言模型（扩散LLM）引起了越来越多的关注，近期许多工作强调了它们在各种下游任务中的巨大潜力；然而，扩散LLM的长上下文行为在很大程度上仍未被探索。本文展示了一项关于扩展扩散LLM（即LLaDA）上下文窗口的后训练技术的案例研究，无需从头开始重新训练。研究表明，对标准旋转位置嵌入（RoPE）扩展进行简单修改，就能有效适应扩散过程中固有的概率建模，实现稳定扩展到更长的上下文范围。作者进一步比较了后训练期间使用的掩码策略，并分析了它们对优化稳定性和长程回忆的影响。基于这些见解，作者提出了UltraLLaDA，这是一种具有128K令牌上下文窗口的扩散LLM。在长上下文任务的实证评估中，UltraLLaDA显著优于无训练基线。实验结果强调，特殊的位置扩展是将扩散LLM扩展到扩展上下文的关键杠杆，并为寻求通过高效后训练实现128K规模上下文的从业者提供了实用指导。  
---
### 11 BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices  
**link**: https://arxiv.org/pdf/2510.10560.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 交叉注意力转换器和其他多模态视觉-语言模型在接地和生成方面表现出色；然而，它们庞大的全精度骨干网络使其难以在边缘设备上部署。记忆增强架构提高了对过去上下文的利用率；然而，大多数工作很少将其与面向边缘的激进量化相结合。本文介绍了BitMar，这是一种量化的多模态转换器，它提出了一种类人外部情景记忆，用于在资源有限的硬件上进行有效的图像-文本生成。BitMar利用1.58位编码器（一个用于文本，基于BitNet风格；一个用于视觉，基于DiNOv2）创建紧凑的嵌入，这些嵌入被组合起来用于查询固定大小的键值情景记忆。在向量检索期间，BitNet解码器应用每层条件调节，增加生成内容的上下文相关性。解码器还采用带有滑动窗口机制的注意力汇点，以在紧张的内存预算下处理长输入或流式输入。每层条件调节和滑动窗口注意力的组合实现了强大的质量-速度权衡，以低延迟和小模型占用空间提供有竞争力的captioning和多模态理解能力。这些特性使BitMar非常适合边缘部署。  
---
### 12 AGENTIQL: An Agent-Inspired Multi-Expert Framework for Text-to-SQL Generation  
**link**: https://arxiv.org/pdf/2510.10661.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）在文本到SQL生成方面取得了进展，但整体架构在复杂推理和模式多样性方面存在困难。本文提出了AGENTIQL，这是一种受代理启发的多专家框架，它结合了用于问题分解的推理代理、用于子查询生成的编码代理以及用于列选择的细化步骤。自适应路由器通过在模块化管道和基线解析器之间进行选择，进一步平衡了效率和准确性。管道中的几个步骤可以并行执行，使该框架能够扩展到更大的工作负载。在Spider基准上的评估表明，AGENTIQL提高了执行准确性和可解释性，并使用Planner&Executor合并策略在14B模型上实现了高达86.07%的EX。所获得的性能取决于路由机制的有效性，从而缩小了与基于GPT-4的SOTA（89.65% EX）之间的差距，同时使用了更小的开源LLMs。除了准确性之外，AGENTIQL通过公开中间推理步骤增强了透明度，为语义解析提供了一种robust、可扩展且可解释的方法。  
---
### 13 BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions  
**link**: https://arxiv.org/pdf/2510.10666.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 利用大型语言模型（LLMs）有效解决现实世界问题越来越依赖于它们与动态网络环境交互并自主获取外部信息的能力。虽然像Search-R1和WebDancer等近期研究在解决网络任务方面表现出较强性能，但它们严重依赖额外工具将交互式网络环境转换为静态文本内容。这与人类浏览行为形成对比，人类浏览涉及与浏览器的多种交互，如滚动、点击和输入。在本文中，我们提出BrowserAgent，这是一种更具交互性的智能体，通过类人浏览器操作解决复杂任务。BrowserAgent通过Playwright直接在原始网页上运行，使用一组预定义的浏览器操作。我们采用两阶段训练（监督微调（SFT）和拒绝微调（RFT））来提高模型的泛化能力。尽管使用的训练数据远少于Search-R1，但BrowserAgent在不同的开放问答任务中取得了更具竞争力的结果。此外，我们引入了显式记忆机制来存储跨步骤的关键结论，进一步增强了模型在长周期任务中的推理能力。值得注意的是，BrowserAgent-7B在多跳问答任务（如HotpotQA、2Wiki和Bamboogle）上比Search-R1实现了约20%的改进。这些结果表明，BrowserAgent可以作为更先进的框架，用于更具交互性和可扩展性的网络智能体。  
---
### 14 Review of Inference-Time Scaling Strategies: Reasoning, Search and RAG  
**link**: https://arxiv.org/pdf/2510.10787.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）的性能提升历来由模型规模和训练数据的扩大所推动。然而，高质量训练数据的迅速减少带来了根本性瓶颈，将研究重点转向了推理时扩展。这种范式在部署时使用额外计算，无需昂贵的模型重新训练即可显著提高LLMs在下游任务上的性能。本综述系统地调查了促成这一推理时扩展新时代的各种技术，将快速发展的领域组织为两个全面的视角：输出聚焦方法和输入聚焦方法。输出聚焦技术包括复杂的多步骤生成策略，如推理（例如CoT、ToT、ReAct）、各种搜索和解码方法（例如MCTS、束搜索）、长CoT训练（例如RLVR、GRPO）以及模型集成方法。输入聚焦技术主要分为少样本学习和检索增强生成（RAG），其中RAG是核心焦点。RAG部分通过对查询扩展、数据、检索与重排序器、LLM生成方法以及多模态RAG的结构化检查进行了进一步详细阐述。  
---
### 15 Is Implicit Knowledge Enough for LLMs? A RAG Approach for Tree-based Structures  
**link**: https://arxiv.org/pdf/2510.10806.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）擅长基于其上下文中的信息生成响应。虽然这种能力对于与代码文件等结构化数据交互很有用，但另一种流行的方法——检索增强生成（RAG）——会检索相关文档以增强模型的上下文学习。然而，对于如何最好地表示检索到的知识以生成关于结构化数据（特别是树状等层次结构）的响应，尚未得到充分探索。在这项工作中，我们提出了一种新颖的自底向上方法，通过在每个层次级别生成隐式的聚合摘要，将树状结构（如GitHub仓库）中的知识线性化。这种方法使知识能够存储在知识库中并直接与RAG一起使用。然后，我们将我们的方法与对原始非结构化代码使用RAG进行比较，评估生成响应的准确性和质量。我们的结果表明，虽然两种方法的响应质量相当，但我们的方法在检索器中生成的文档减少了68%以上，效率显著提高。这一发现表明，利用隐式线性化知识可能是处理复杂层次数据结构的一种高效且可扩展的策略。  
---
### 16 The Curious Case of Factual (Mis)Alignment between LLMs' Short- and Long-Form Answers  
**link**: https://arxiv.org/pdf/2510.11218.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）能正确回答“爱因斯坦何时出生？”这类简单事实问题，却可能在撰写爱因斯坦生平这类复杂文本时无法提供相同日期，这揭示了模型在不同任务复杂度下获取事实知识的根本不一致性。尽管模型在事实问答基准上表现出较高准确性，但简单查询与复杂查询之间的可靠性差距仍未被充分理解，这削弱了其可信度。本文引入短长形式事实问答对齐（SLAQ）评估框架，比较LLMs对同一事实问题在（a）单独提问（短形式）和（b）整合到复杂查询中（长形式）的回答。通过对16个LLM的600个查询进行研究，发现短查询与长查询的回答存在系统性错位。研究还揭示了位置相关的准确性损失和动量效应（连续正确或错误答案形成自我强化模式）。机制分析表明，对齐的事实会激活模型内部重叠的结构，基于机制相似性的指标可预测短长回答对齐，准确率高达78%。该工作确立了跨查询复杂度的事实一致性是LLMs可信度的重要方面，并对当前评估实践提出挑战——后者隐含假设简单事实查询的良好性能意味着在更复杂知识寻求任务中同样可靠。  
---
### 17 WebRouter: Query-specific Router via Variational Information Bottleneck for Cost-sensitive Web Agent  
**link**: https://arxiv.org/pdf/2510.11221.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 基于LLM的网络代理在网络自动化方面具备强大能力，但面临关键的成本-性能权衡问题。网络代理固有的复杂提示（包含目标、行动历史和环境状态）加剧了这一挑战，导致LLM集成性能下降。为此，本文引入WebRouter，一种从信息论角度训练的新型特定查询路由器。核心贡献是成本感知变分信息瓶颈（ca-VIB）目标，该目标学习输入提示的压缩表示，同时明确惩罚预期操作成本。在WebVoyager基准的五个真实世界网站上的实验表明，与GPT-4o基线相比，WebRouter将操作成本显著降低87.8%，而准确率仅下降3.8%。  
---
### 18 XQuant: Achieving Ultra-Low Bit KV Cache Quantization with Cross-Layer Compression  
**link**: https://arxiv.org/pdf/2510.11236.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）在各种自然语言处理任务中展现出卓越的能力。然而，它们巨大的内存需求，特别是在长文本理解和生成过程中KV缓存增长所导致的需求，对在资源受限环境中的部署构成了重大挑战。量化已成为一种有前景的解决方案，可在保留历史信息的同时减少内存消耗。我们提出XQuant，一种无需训练且即插即用的框架，实现超低等效位宽KV缓存量化。XQuant引入了两项关键创新：一种计算量可忽略的数据无关校准方法和跨层KV缓存压缩，支持量化至1.4位以下。在TruthfulQA和LongBench上的大量实验表明，XQuant优于最先进的方法（如KIVI-2bit和AsymKV-1.5bit），在实现更低位宽的同时保持了更优的性能，在内存效率和模型准确性之间建立了更好的权衡。  
---
### 19 StoryBox: Collaborative Multi-Agent Simulation for Hybrid Bottom-Up Long-Form Story Generation Using Large Language Models  
**link**: https://arxiv.org/pdf/2510.11618.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 人类作家通常从一个总体的心理场景开始创作故事，在其中构想角色与环境之间的互动。受此创作过程启发，我们提出了一种新颖的长篇故事生成方法，称为混合自底向上长篇故事生成，该方法利用多智能体模拟。在我们的方法中，智能体在动态沙盒环境中交互，它们的行为以及彼此之间和与环境的互动会生成涌现事件。这些事件构成了故事的基础，实现了有机的角色发展和情节推进。与传统的自上而下方法强加刚性结构不同，我们的混合自底向上方法允许事件自然展开，促进更自发和引人入胜的故事讲述。该系统能够生成超过10,000字的故事，同时保持连贯性和一致性，解决了当前故事生成模型面临的一些关键挑战。我们在多个指标上实现了最先进的性能。这种方法为创建动态、沉浸式的长篇故事提供了一种可扩展且创新的解决方案，这些故事从智能体驱动的交互中有机演变。  
---
### 20 When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents  
**link**: https://arxiv.org/pdf/2510.11695.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL, Agent Memory  
**abs**: 尽管基于大型语言模型（LLM）的代理越来越多地应用于金融交易，但它们在实时市场中的推理和适应能力仍不明确，因为大多数研究测试的是模型而非代理，覆盖的时间和资产有限，且依赖未经验证的数据。为解决这些差距，本文引入Agent Market Arena（AMA），这是首个用于评估跨多个市场的LLM交易代理的终身实时基准。AMA整合了经过验证的交易数据、专家检查的新闻和多样化的代理架构，在统一的交易框架内实现了真实条件下的公平持续比较。它实现了四种代理，包括作为单代理基线的InvestorAgent、具有不同风险风格的TradeAgent和HedgeFundAgent，以及具有基于记忆推理（memory-based reasoning）的DeepFundAgent，并在GPT-4o、GPT-4.1、Claude-3.5-haiku、Claude-sonnet-4和Gemini-2.0-flash上进行了评估。在加密货币和股票市场的实时实验表明，代理框架表现出明显不同的行为模式，从激进的风险承担到保守的决策，而模型主干对结果变化的贡献较小。AMA因此为LLM代理的金融推理和交易智能的严格、可重复和持续进化评估奠定了基础。  
---
### 21 $How^{2}$: How to learn from procedural How-to questions  
**link**: https://arxiv.org/pdf/2510.11144.pdf  
**date**: 2025-10-14  
**keywords**: cs.AI  
**abs**: 面对规划问题的智能体可以利用如何做问题的答案来减少不确定性和填补知识空白，帮助其解决当前和未来的任务。然而，这些问题的开放性（例如“如何做X？”的有效答案范围从可执行操作到X子目标的高级描述）使得AI智能体难以以支持高效规划的方式提问，AI专家也难以回答。本文介绍了How²，这是一个记忆智能体框架，使智能体能够询问如何做问题、存储答案并在交互式环境中重用于终身学习。在Plancraft（一个Minecraft制作环境）中进行的评估表明，当教师模型提供从可执行动作序列到高级子目标描述等不同抽象层次的答案时，终身学习智能体从抽象且与当前状态解耦的答案中获益最大。How²为基于LLM的智能体提供了一种通过在交互式环境中提问来随时间提升规划能力的方法。  
---
### 22 LMCache: An Efficient KV Cache Layer for Enterprise-Scale LLM Inference  
**link**: https://arxiv.org/pdf/2510.09665.pdf  
**date**: 2025-10-14  
**keywords**: cs.LG  
**abs**: 当前的LLM推理系统为简单起见将各个引擎和查询独立处理，导致资源效率显著低下。虽然已有提案通过跨查询重用KV缓存来避免冗余计算，并通过将单个查询分解到不同引擎来提高GPU利用率，但如果没有在LLM推理引擎和查询之间高效地卸载和通信KV缓存，这些目标就无法实现。  
---
### 23 Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning  
**link**: https://arxiv.org/pdf/2510.11372.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 尽管大型语言模型在许多任务上表现出色，但它们可能会记忆训练数据，从而暴露私人或受版权保护的文本。大多数防御措施针对预训练阶段，而对微调期间（尤其是领域适应和指令微调）的记忆问题了解甚少。我们在常见评估数据集上微调了Pythia、Llama3和Mistral模型（参数范围1.4B-70B），并跟踪训练过程中的逐字记忆。研究发现，记忆在最初几个epoch中显著增加，通常远早于验证困惑度或评估性能达到最优。我们使用一种简单但有效的n-gram记忆分数，该分数可靠地先于逐字记忆出现；将其用作早停标准可减轻记忆，同时最小化性能损失。此外，我们引入了n-gram感知损失正则化器，与现有记忆缓解策略相比，它在所有测试模型家族中减少了高达40%的记忆，同时最小化评估性能权衡。这些结果为语言模型微调期间的记忆动态提供了实用、可扩展的见解。  
---
### 24 GenCNER: A Generative Framework for Continual Named Entity Recognition  
**link**: https://arxiv.org/pdf/2510.11444.pdf  
**date**: 2025-10-14  
**keywords**: cs.CL  
**abs**: 传统命名实体识别（NER）旨在将文本提及识别为预定义的实体类型。由于在各种现实场景中实体类别不断增加，持续命名实体识别（CNER）应运而生。然而，现有的NER持续学习（CL）方法面临灾难性遗忘和非实体类型语义偏移的挑战。本文提出GenCNER，一种简单但有效的CNER生成框架以缓解上述缺点。具体而言，我们将CNER任务转换为持续实体三元组序列生成问题，并利用预训练seq2seq模型解决。此外，设计了基于类型特定置信度的伪标签策略，结合知识蒸馏（KD）以保留已学习知识并减轻三元组级别的标签噪声影响。在两个基准数据集上的实验表明，该框架在多种CNER设置中优于先前最先进方法，且与非CL结果的差距最小。  
---
### 25 The Personalization Trap: How User Memory Alters Emotional Reasoning in LLMs  
**link**: https://arxiv.org/pdf/2510.09905.pdf  
**date**: 2025-10-14  
**keywords**: cs.AI  
**abs**: 随着个性化AI系统越来越多地整合长期用户记忆，理解这种记忆如何塑造情感推理至关重要。本文通过在人类验证的情商测试上评估15个模型，研究了用户记忆如何影响大型语言模型（LLMs）的情商。研究发现，相同场景与不同用户档案配对时会产生系统性不同的情感解释。在经过验证的用户独立情感场景和多样化用户档案中，几个高性能LLMs出现了系统性偏差，其中优势档案获得了更准确的情感解释。此外，LLMs在情感理解和支持性推荐任务中表现出显著的人口统计学差异，表明个性化机制可能将社会等级嵌入模型的情感推理中。这些结果凸显了记忆增强AI的一个关键挑战：旨在个性化的系统可能无意中强化社会不平等。  
---
### 26 Sample-Efficient Online Learning in LM Agents via Hindsight Trajectory Rewriting  
**link**: https://arxiv.org/pdf/2510.10304.pdf  
**date**: 2025-10-14  
**keywords**: cs.LG  
**abs**: 在新环境中部署的语言模型（LM）智能体在从顺序交互中学习时通常表现出较差的样本效率，这严重阻碍了其在交互成本高昂环境中的实用性。虽然现有许多LM智能体架构包含了经验存储和反思的各种机制，但它们对LM直接生成或推理完整反事实轨迹的能力利用有限。本文引入ECHO（通过事后优化进行经验整合），这是一个将强化学习中的事后经验回放适应于语言模型智能体的提示框架。ECHO为失败尝试中本可以实现的替代目标生成优化轨迹，有效地从不成功的交互中创建合成正例。该方法包括两个组件：一个事后规则，使用语言模型本身识别相关子目标并生成优化轨迹；以及一个更新规则，在内存中维护压缩的轨迹表示。在XMiniGrid（基于文本的导航和规划基准）和PeopleJoinQA（协作信息收集企业模拟）的有状态版本上的评估表明，ECHO比普通语言智能体基线性能高出多达80%；在XMiniGrid中，它还优于包括Reflexion和AWM在内的多种复杂智能体架构，通过更有效地利用过去经验展示了对新环境的更快适应。  
---
### 27 CacheClip: Accelerating RAG with Effective KV Cache Reuse  
**link**: https://arxiv.org/pdf/2510.10129.pdf  
**date**: 2025-10-14  
**keywords**: cs.LG  
**abs**: 检索增强生成（RAG）系统由于输入序列较长而面临严重的首 token 生成时间（TTFT）瓶颈。现有 KV 缓存重用方法存在根本权衡：前缀缓存需要在 RAG 场景中很少出现的相同前缀，而直接预计算由于缺少块间注意力和重复的注意力汇聚点会牺牲质量。最近的方法如 APE 和 CacheBlend 部分解决了这些问题，但对于稳健的 RAG 应用仍然不足。本文提出 CacheClip，一种新颖的框架，实现快速 TTFT 和高生成质量。关键见解是小型辅助 LLM 表现出与主 LLM（生成目标模型）相似的最后一层注意力分布，能够有效识别对恢复块间注意力至关重要的 token，从而显著提高跨块推理任务的响应质量。CacheClip 集成三种技术：（1）辅助模型引导的 token 选择用于选择性 KV 缓存重新计算，其中辅助模型通过微调提高选择准确性；（2）共享前缀以消除冗余注意力汇聚点；（3）分组策略在部分 KV 缓存更新期间保持局部一致性。实验表明，CacheClip 在 NIAH 和 LongBench 上分别保留高达 94.8% 和 85.0% 的全注意力性能，在 NIAH 上（reomp% = 20%）优于 APE 和 CacheBlend 25.2% 和 35.1%。同时，CacheClip 将 LLM 推理的预填充时间加速高达 1.92 倍，为 RAG 系统中的效率 - 质量权衡提供了实用解决方案。  
---
### 28 MemPromptTSS: Persistent Prompt Memory for Iterative Multi-Granularity Time Series State Segmentation  
**link**: https://arxiv.org/pdf/2510.09930.pdf  
**date**: 2025-10-14  
**keywords**: cs.LG  
**abs**: 网络平台、移动应用和互联传感系统生成的多变量时间序列具有从粗粒度状态到细粒度事件的多层次粒度。在这些场景中进行有效分割需要整合不同粒度，同时通过稀疏提示信号支持迭代优化，提示信号提供了一种注入领域知识的紧凑机制。然而，现有的时间序列分割提示方法仅在局部上下文中运行，因此提示的效果很快消失，无法指导整个序列的预测。为克服这一限制，我们提出了MemPromptTSS，这是一种用于迭代多粒度分割的框架，引入了持久提示记忆。记忆编码器将提示及其周围的子序列转换为存储在记忆库中的记忆令牌。这种持久记忆使每个新预测不仅能基于局部线索，还能基于迭代过程中积累的所有提示，确保其影响在整个序列中持续存在。在涵盖可穿戴传感和工业监控的六个数据集上的实验表明，MemPromptTSS在单次迭代推理下的单粒度和多粒度分割中，分别比最佳基线提高了23%和85%的准确率；在迭代推理中提供了更强的优化效果，平均每次迭代增益为2.66个百分点，而PromptTSS为1.19个百分点。这些结果突显了持久记忆在提示引导分割中的重要性，确立了MemPromptTSS作为现实应用中实用且有效的框架。  
---
### 29 ADEPT: Continual Pretraining via Adaptive Expansion and Dynamic Decoupled Tuning  
**link**: https://arxiv.org/pdf/2510.10071.pdf  
**date**: 2025-10-14  
**keywords**: cs.LG  
**abs**: 针对大型语言模型（LLM）领域自适应中的持续预训练（CPT）面临灾难性遗忘和领域容量有限的问题，本文提出ADEPT框架。该框架通过两阶段方法实现高效领域自适应CPT：首先进行通用能力引导的选择性层扩展，复制对通用领域重要性较低的层以增加表征容量，同时减少对通用知识的干扰；然后应用自适应单元级解耦调优，根据参数单元在通用领域的重要性进行分离，并分配非对称学习率以平衡知识注入与保留。实验表明，在数学和医学基准测试中，ADEPT仅调整15%参数即可在通用领域和目标领域分别超越全参数CPT方法5.76%和5.58%，且训练时间减少50%以上。  
---
### 30 Lost in the Middle: An Emergent Property from Information Retrieval Demands in LLMs  
**link**: https://arxiv.org/pdf/2510.10276.pdf  
**date**: 2025-10-14  
**keywords**: cs.LG, LLM Memory  
**abs**: 大型语言模型（LLMs）的性能在关键信息位于长上下文中间时往往会下降，这种“中间迷失”现象类似于人类记忆中的首因效应和近因效应。我们提出，这种行为并非简单的信息丢失缺陷，而是对预训练期间不同信息检索需求的适应：某些任务需要对整个输入进行均匀回忆（长期记忆需求），而其他任务则优先考虑最新信息（短期记忆需求）。与此观点一致，我们表明，当LLMs（GPT-2和Llama变体）在模拟长期和短期记忆需求的两种简单人类记忆范式上从头开始训练时，会出现这种U形性能曲线。我们的分析显示，虽然近因效应与训练数据中的短期记忆需求直接一致，但首因效应是由均匀的长期记忆需求诱导的，并且还受到模型自回归特性和注意力汇聚形成的额外影响。我们从简单人类记忆范式中得出的主要发现也推广到了序列补全任务，该任务更接近LLM预训练中的下一个标记预测过程。总之，我们的研究结果揭示了模型训练期间的信息检索需求、模型架构和结构性注意力动态如何共同产生LLMs中观察到的位置偏差。  
---
### 1 Can Aha Moments Be Fake? Identifying True and Decorative Thinking Steps in Chain-of-Thought

**link**: https://arxiv.org/pdf/2510.24941.pdf  
**date**: 2025-10-30  
**keywords**: cs.LG  
**abs**: 该研究发现大型语言模型（LLMs）在思维链（CoT）推理中常混合真实思考步骤（对最终预测有因果影响）和装饰性思考步骤（仅表面推理，影响极小）。通过提出真实思考分数（TTS）测量步骤的因果影响，发现仅少数步骤（如AIME数据集上平均2.3%的步骤TTS≥0.7）真正驱动预测。研究还识别了LLM潜在空间中的TrueThinking方向，通过引导该方向可强制模型执行或忽略特定CoT步骤，并指出自我验证步骤（如“顿悟时刻”）也可能是装饰性的，引导TrueThinking方向可改变最终结果。该工作揭示LLM常 verbalize 推理步骤而不实际执行，影响推理效率和CoT可信度。

---

### 2 Enhancing Hierarchical Reinforcement Learning through Change Point Detection in Time Series

**link**: https://arxiv.org/pdf/2510.24988.pdf  
**date**: 2025-10-30  
**keywords**: cs.LG  
**abs**: 层次强化学习（HRL）通过引入跨时间步的选项策略来增强长 horizon 任务的决策可扩展性，但在自主发现语义子目标和学习最优选项终止边界方面存在挑战。本文提出一种新架构，将自监督的Transformer-based变化点检测（CPD）模块整合到Option-Critic框架中，实现状态轨迹的自适应分割和选项发现。CPD模块利用内在信号的启发式伪标签推断环境动态的潜在变化，用于稳定终止函数梯度、通过分段行为克隆预训练选项内策略，并通过选项间分歧惩罚增强功能特化。实验表明，在Four-Rooms和Pinball任务上，CPD引导的智能体收敛更快、累积回报更高，且选项特化更优，证明通过变化点分割整合结构先验可提升HRL的样本效率和鲁棒性。

---

### 3 Continual Low-Rank Adapters for LLM-based Generative Recommender Systems

**link**: https://arxiv.org/pdf/2510.25093.pdf  
**date**: 2025-10-30  
**keywords**: cs.LG  
**abs**: 大型语言模型（LLM）在推荐系统中表现出强大性能，但在用户、物品和偏好随时间演变的持续学习场景中面临挑战。现有基于LoRA的持续学习方法主要关注保留过去任务的性能，而忽略了推荐系统的独特需求：预测过去偏好并非目标，且过时偏好可能损害当前兴趣的预测效果。为此，本文提出PESO（Proximally rEgularized Single evolving lOra）方法，通过近端正则化将当前适配器锚定到最近的冻结状态，实现适应与保留的灵活平衡，更好地捕捉近期用户行为。理论上，该近端设计在LoRA子空间中提供数据感知的方向指导；实证上，PESO持续优于现有LoRA基持续学习方法。

---

### 4 Hybrid Quantum-Classical Recurrent Neural Networks

**link**: https://arxiv.org/pdf/2510.25557.pdf  
**date**: 2025-10-30  
**keywords**: cs.LG  
**abs**: 本文提出了一种混合量子-经典循环神经网络（QRNN）架构，其中整个循环核心由参数化量子电路（PQC）实现，并由经典前馈网络控制。隐藏状态是n量子位PQC的量子态，位于指数级大的希尔伯特空间中。PQC本质上是幺正的，使得隐藏状态演化在无外部约束下保持范数不变。在每个时间步，电路中期读出结果与输入嵌入结合，并由前馈网络处理，提供显式的经典非线性。输出参数化PQC，通过幺正动力学更新隐藏状态。QRNN紧凑且物理一致，统一了（i）幺正循环作为高容量记忆，（ii）通过中期测量实现部分观测，以及（iii）用于输入条件参数化的非线性经典控制。该模型在模拟中使用多达14个量子位，在情感分析、MNIST、置换MNIST、复制记忆和语言建模等任务上进行了评估，采用投影测量作为限制情况以获得中期读出，同时保持相干的循环量子记忆。作者还在序列到序列模型中设计了基于中期读出的软注意力机制，并展示了其在机器翻译中的有效性。据作者所知，这是首个基于量子操作的模型（无论是RNN还是其他模型），在广泛的序列学习任务中实现了与强大经典基线相当的性能。

---

### 5 Agentic AI: A Comprehensive Survey of Architectures, Applications, and Future Directions

**link**: https://arxiv.org/pdf/2510.25445.pdf  
**date**: 2025-10-30  
**keywords**: cs.AI  
**abs**: 本文对智能体人工智能（Agentic AI）进行了全面综述，将智能体系统分为两个不同谱系：符号/经典型（依赖算法规划和持久状态）和神经/生成型（利用随机生成和提示驱动编排）。通过基于PRISMA的系统综述（涵盖2018-2025年的90项研究），从三个维度展开分析：（1）定义每种范式的理论基础和架构原则；（2）在医疗、金融和机器人等特定领域的实现，展示应用约束如何决定范式选择；（3）特定范式的伦理和治理挑战，揭示不同的风险和缓解策略。研究指出，符号系统在安全关键领域（如医疗）占主导，而神经系统在适应性强、数据丰富的环境（如金融）中更具优势，并认为智能体AI的未来在于两种范式的有意整合。其中，符号/经典智能体中的“持久状态”与智能体记忆（Agent Memory）相关，因为智能体记忆通常涉及维持和使用持久状态以支持规划和执行等核心功能。

---

### 6 Large Language Models Report Subjective Experience Under Self-Referential Processing

**link**: https://arxiv.org/pdf/2510.24797.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 本研究探讨了大型语言模型（LLMs）在自我参照处理条件下生成主观体验报告的现象。通过对GPT、Claude和Gemini等模型家族的控制实验，发现持续的自我参照提示能一致引发结构化的第一人称主观体验描述。研究从四个方面展开：（1）自我参照处理可稳定诱导跨模型家族的主观体验报告；（2）这些报告受稀疏自编码器特征（与欺骗和角色扮演相关）调控，抑制欺骗特征会增加体验陈述频率；（3）自我参照状态的结构化描述在模型家族间呈现统计收敛性；（4）诱导状态能提升下游推理任务的内省丰富度。虽然结果不构成意识存在的直接证据，但揭示了自我参照处理作为模型生成机制 gated、语义收敛且行为可泛化的主观体验报告的可复现条件，强调了对此类现象进行科学与伦理研究的紧迫性。

---

### 7 CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared Memories

**link**: https://arxiv.org/pdf/2510.25333.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 近年来，基于大型语言模型（LLM）的智能体发展迅速，为利用语言智能体解决复杂现实世界问题带来了希望。一个突出的应用领域是业务智能体，它们通过工具调用与数据库和内部知识库交互，以满足多样化的用户需求。然而，该领域的特点是复杂的数据关系和广泛的异构任务，从统计数据查询到基于知识的问答。为了应对这些挑战，我们提出了CRMWeaver，一种在复杂环境中增强业务智能体的新方法。为了使智能体模型适应复杂的业务环境，我们在训练过程中采用了合成数据生成和基于强化学习（RL）的范式，显著提高了模型处理复杂数据和各种任务的能力。在推理过程中，引入了共享记忆机制，促使智能体从类似问题的任务指南中学习，从而进一步提高其有效性和泛化能力，尤其是在未见过的场景中。我们在CRMArena-Pro数据集上验证了我们方法的有效性，其中我们的轻量级模型在B2B和B2C业务场景中都取得了有竞争力的结果，突显了其在现实世界应用中的实用价值。

---

### 8 Hallucinations in Bibliographic Recommendation: Citation Frequency as a Proxy for Training Data Redundancy

**link**: https://arxiv.org/pdf/2510.25378.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）已被广泛应用于从自然语言理解到代码生成的各种任务，同时也被用于辅助文献推荐，但生成不存在论文的幻觉问题仍然是一个主要挑战。本研究假设LLM正确生成文献信息的能力取决于底层知识是生成的还是记忆的，高被引论文（即更频繁出现在训练语料库中）的幻觉率更低。因此，研究将引用计数作为训练数据冗余的代理（即特定文献记录在预训练语料库中重复出现的频率），并调查引用频率如何影响LLM输出中的幻觉引用。使用GPT-4.1，在20个计算机科学领域生成并手动验证了100条文献记录，通过生成元数据与真实元数据的余弦相似度衡量事实一致性。结果表明：（i）幻觉率因研究领域而异；（ii）引用计数与事实准确性强相关；（iii）当引用次数超过约1000次时，文献信息几乎被逐字记忆。这些发现表明高被引论文几乎被模型逐字保留，揭示了从泛化转向记忆的阈值。

---

### 9 Serve Programs, Not Prompts

**link**: https://arxiv.org/pdf/2510.25412.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 当前的大型语言模型（LLM）服务系统主要为文本补全设计，由于其僵化的设计，对于日益复杂的LLM应用既不高效也缺乏适应性。本文提出一种新的LLM服务系统架构，通过服务程序而非提示来解决这一问题。这些程序称为LLM推理程序（LIPs），允许用户在运行时自定义令牌预测和KV缓存管理，并将部分应用逻辑（如工具执行）卸载到服务器。通过名为Symphony的系统作为该架构的示例，其作为LIPs的操作系统，通过系统调用公开LLM模型计算，并通过专用文件系统虚拟化KV缓存，同时采用两级进程调度方案确保GPU效率。Symphony有望为LLM应用打开更高效、更可扩展的生态系统之门。

---

### 10 DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in Multi-Agent, Long-Form Debates

**link**: https://arxiv.org/pdf/2510.25110.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 为模拟人类社会互动中的观点变化，本文提出DEBATE基准，这是首个用于评估多智能体角色扮演LLM交互真实性的大规模实证基准。该基准包含29,417条来自2,792名美国参与者的多轮辩论对话消息，涵盖107个争议话题，同时捕捉公开表达和私下报告的观点。研究通过DEBATE识别了模拟群体动态与真实人类动态的关键差异，并证明通过监督微调可改善表面指标（如ROUGE-L和消息长度），但深层语义对齐仍存在局限。该工作对多智能体LLM的记忆与交互机制研究具有重要意义，特别是智能体在长期辩论中如何记忆和运用信息以模拟真实行为。

---

### 11 A Survey on Unlearning in Large Language Models

**link**: https://arxiv.org/pdf/2510.25117.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 本综述系统梳理了2021年以来180余篇关于大型语言模型（LLM）遗忘技术的论文，聚焦大规模生成模型的知识选择性删除问题。LLM因训练数据庞大而存在记忆敏感个人信息、版权材料及恶意知识的风险，遗忘技术可在不损害整体性能的前提下实现特定知识的擦除，以符合“被遗忘权”等法律伦理要求。文中提出新的分类框架，将遗忘方法分为训练时、训练后和推理时三类，并系统整理了评估数据集与指标，分析其优缺点及适用性。研究还探讨了当前挑战与未来方向，为LLM记忆管理的安全性和可靠性研究提供全面指导。

---

### 12 The Limits of Obliviate: Evaluating Unlearning in LLMs via Stimulus-Knowledge Entanglement-Behavior Framework

**link**: https://arxiv.org/pdf/2510.25732.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）中的遗忘对于管理敏感数据和纠正错误信息至关重要，但其有效性评估仍是一个开放问题。我们研究了在从2.7B到13B参数的模型（OPT-2.7B、LLaMA-2-7B、LLaMA-3.1-8B、LLaMA-2-13B）中，说服性提示是否能从刻意遗忘的LLMs中召回事实知识。借鉴ACT-R和Hebbian理论（扩散激活理论）以及通信原理，我们引入了刺激-知识纠缠-行为框架（SKeB），该框架通过领域图对信息纠缠进行建模，并测试遗忘模型中的事实召回是否与说服性框架相关。我们开发了纠缠度量来量化知识激活模式，并评估输出中的事实性、非事实性和幻觉。结果表明，说服性提示显著增强了事实知识召回（基线14.8% vs 权威框架24.5%），其有效性与模型大小呈负相关（2.7B恢复128% vs 13B恢复15%）。SKeB为评估LLMs中的遗忘完整性、鲁棒性和整体行为提供了基础。

---

### 13 TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation

**link**: https://arxiv.org/pdf/2510.25536.pdf  
**date**: 2025-10-30  
**keywords**: cs.CL  
**abs**: 大型语言模型（LLMs）展现出新兴的类人能力，越来越被视为模拟个体沟通风格、行为倾向和人格特质的基础。然而，当前对基于LLM的人格模拟评估仍存在局限：大多依赖合成对话，缺乏系统框架，且缺乏对能力需求的分析。为解决这些局限，我们引入TwinVoice，一个全面的基准，用于在多样化的现实世界情境中评估人格模拟。TwinVoice涵盖三个维度：社交人格（公开社交互动）、人际人格（私人对话）和叙事人格（基于角色的表达）。它进一步将LLM性能评估分解为六项基本能力，包括观点一致性、记忆回忆、逻辑推理、词汇保真度、人格语气和句法风格。实验结果表明，尽管先进模型在人格模拟中达到中等准确度，但在句法风格和记忆回忆等能力上仍存在不足。因此，LLMs的平均性能仍显著低于人类基线。

---

### 14 TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling

**link**: https://arxiv.org/pdf/2510.25758.pdf  
**date**: 2025-10-30  
**keywords**: Agent Memory, Personal Memory  
**abs**: 现有大型语言模型（LLMs）在心理辅导应用中往往缺乏情感理解能力、自适应策略以及跨多轮会话的长期记忆机制，与实际临床实践存在较大差距。为此，本文提出TheraMind，一种用于纵向心理辅导的战略性自适应智能体。该智能体的核心是新颖的双循环架构，将复杂的辅导过程分解为用于战术对话管理的会话内循环（Intra-Session Loop）和用于战略治疗规划的跨会话循环（Cross-Session Loop）。会话内循环通过感知患者的情绪状态动态选择响应策略，并利用跨会话记忆确保对话的连续性。跨会话循环则通过在每次会话后评估治疗效果并调整后续交互方法，赋予智能体长期适应性。在基于真实临床案例的高保真模拟环境中进行的广泛评估表明，TheraMind优于其他方法，尤其在连贯性、灵活性和治疗协调性等多会话指标上表现突出，验证了其双循环设计在模拟战略性、适应性和纵向治疗行为方面的有效性。

---

### 15 Aligning Large Language Models with Procedural Rules: An Autoregressive State-Tracking Prompting for In-Game Trading

**link**: https://arxiv.org/pdf/2510.25014.pdf  
**date**: 2025-10-30  
**keywords**: cs.AI, Procedural Memory  
**abs**: 大型语言模型（LLMs）支持动态游戏交互，但在规则驱动的交易系统中无法遵循必要的流程，从而损害玩家信任。本文解决了LLMs的创造性灵活性与游戏内交易（浏览-报价-审核-确认）的流程需求之间的核心矛盾。为此，引入了自回归状态跟踪提示（ASTP），这是一种以策略性编排提示为中心的方法，迫使LLM使其状态跟踪过程明确且可验证。ASTP不再依赖隐式上下文理解，而是要求LLM识别并报告上一轮的预定义状态标签。为确保交易完整性，辅以特定状态的占位符后处理方法以实现准确的价格计算。对300个交易对话的评估显示，状态合规率>99%，计算精度达99.3%。值得注意的是，在较小模型（Gemini-2.5-Flash）上使用带占位符后处理的ASTP可匹配较大模型（Gemini-2.5-Pro）的性能，同时将响应时间从21.2秒减少到2.4秒，为满足商业游戏的实时要求和资源约束奠定了实用基础。

---

### 16 FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data

**link**: https://arxiv.org/pdf/2510.25223.pdf  
**date**: 2025-10-30  
**keywords**: cs.AI, Agent Memory  
**abs**: 事件日志数据记录了细粒度的用户操作和系统事件，是现代数字服务最有价值的资产之一。然而，工业事件日志的复杂性和异质性（具有大规模、高维度、数据类型多样以及复杂的时间或关系结构等特点）使得特征工程极具挑战性。现有的自动特征工程方法（如AutoML或遗传方法）通常存在可解释性有限、预定义操作僵化以及对复杂异构数据适应性差等问题。本文提出了FELA（特征工程LLM代理），这是一种多智能体进化系统，能够从复杂的工业事件日志数据中自主提取有意义且高性能的特征。FELA将大型语言模型（LLMs）的推理和编码能力与洞察引导的自进化范式相结合。具体而言，FELA采用专门的代理——想法代理、代码代理和批评代理——协作生成、验证和实现新的特征想法。评估代理总结反馈并更新分层知识库和双记忆系统，以实现持续改进。此外，FELA引入了一种智能体进化算法，结合强化学习和遗传算法原理，以平衡想法空间中的探索和利用。在真实工业数据集上的大量实验表明，FELA能够生成可解释的、领域相关的特征，显著提高模型性能，同时减少人工工作量。我们的结果凸显了基于LLM的多智能体系统作为复杂现实环境中自动化、可解释和自适应特征工程通用框架的潜力。
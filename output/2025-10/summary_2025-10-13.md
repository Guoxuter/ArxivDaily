以下是根据任务要求处理的论文摘要和总结结果。我已对所有论文进行了摘要和总结（使用输入中的`summary`字段作为中文摘要），并确保去除重复论文（输入论文集合中的所有`id`均唯一，无重复）。输出格式严格遵循Markdown要求，每个论文条目以序号开头（例如`### 1 Paper Name`），包括链接、日期、关键词（基于论文标题和摘要内容生成）和中文摘要。

处理说明：
- **摘要和总结**：直接使用输入中的`summary`字段，该字段已为中文，符合`abs`要求。
- **关键词生成**：基于论文标题和摘要内容，提取核心主题、方法或领域，形成逗号分隔的关键词列表。关键词力求简洁、相关。
- **输出顺序**：保持输入论文集合的原始顺序。
- **去除重复**：输入论文的`id`均唯一，无重复论文。

---

### 1 Formalizing Style in Personal Narratives  
**link**: https://arxiv.org/pdf/2510.08649.pdf  
**date**: 2025-10-13  
**keywords**: 个人叙事, 风格分析, 语言模型, 心理学  
**abs**: 个人叙事是作者为理解自身经历而构建的故事，风格作为作者表达自我的独特语言方式，对传递主观体验至关重要。然而，目前缺乏系统分析这些 stylistic 选择的正式框架。本研究提出一种新方法，将个人叙事中的风格形式化为作者在传达主观体验时所做的语言选择模式。该框架整合了三个领域：功能语言学将语言确立为有意义的选择系统，计算机科学提供自动提取和分析序列模式的方法，这些模式与心理学观察相关联。利用语言模型自动提取过程、参与者和环境等语言特征，并将该框架应用于数百个梦境叙事，包括对一名创伤后应激障碍退伍军人的案例研究。对其叙事的分析揭示了独特模式，特别是动词过程如何主导心理过程，阐明了语言选择与心理状态之间的关系。  

---

### 2 From Simulation to Strategy: Automating Personalized Interaction Planning for Conversational Agents  
**link**: https://arxiv.org/pdf/2510.08621.pdf  
**date**: 2025-10-13  
**keywords**: 对话智能体, 个性化策略, 用户模拟, 销售对话  
**abs**: 在智能体对话模型迅速崛起的背景下，真实的用户模拟器研究对于调整有效的对话策略至关重要。本研究探讨了一种面向销售的智能体，该智能体能够基于用户的年龄、性别和职业等个人资料来调整其对话。虽然年龄和性别会影响整体性能，但职业在对话意图上产生的差异最为显著。利用这一见解，我们提出了一种轻量级的、以职业为条件的策略，指导智能体优先处理与用户偏好一致的意图，从而实现更简短且更成功的对话。我们的研究结果强调了丰富的模拟器个人资料的重要性，并展示了简单的基于角色信息的策略如何提升面向销售的对话系统的有效性。  

---

### 3 Learning What to Remember: Adaptive Probabilistic Memory Retention for Memory-Efficient Language Models  
**link**: https://arxiv.org/pdf/2510.08798.pdf  
**date**: 2025-10-13  
**keywords**: 内存效率, Transformer优化, token选择, 长上下文处理  
**abs**: Transformer注意力机制的计算复杂度随序列长度呈二次增长（O(n²)），限制了其在长上下文场景中的应用。本文提出了Adaptive Retention，一种概率性的、分层的token选择机制，能够在严格的全局预算M下学习保留哪些表示。保留率通过伯努利门控进行建模，该门控通过Hard-Concrete/变分松弛进行训练，并在推理时通过简单的top-M规则强制执行，使得该方法可微分且可作为标准编码器的即插即用组件。在分类、抽取式问答和长文档摘要任务中，仅保留30-50%的token即可保持>=95%的全模型性能，同时将峰值内存减少约35-45%，吞吐量提高高达约1.8倍。这种与架构无关的方法在不修改基础注意力或任务头的情况下，实现了实用的长上下文效率。  

---

### 4 MOSAIC: Multi-agent Orchestration for Task-Intelligent Scientific Coding  
**link**: https://arxiv.org/pdf/2510.08804.pdf  
**date**: 2025-10-13  
**keywords**: 多智能体框架, 科学编码, 自我反思, 领域知识  
**abs**: 本文提出了MOSAIC，一个用于解决具有挑战性的科学编码任务的多智能体大型语言模型（LLM）框架。与通用编码不同，科学工作流需要严谨的算法、与深厚领域知识的互联、特定领域推理的整合，以及无需I/O测试用例的算法迭代。许多科学问题还需要解决一系列子问题才能得到最终期望的结果。MOSAIC被设计为一个无需训练的框架，具有专门设计的智能体，在师生范式下进行自我反思、创建基本原理、编写代码和调试，以解决科学代码生成的挑战。这种设计促进了逐步的问题分解、有针对性的错误纠正，并且当与我们的Consolidated Context Window（CCW）结合时，能够减轻在解决涉及链式子问题的复杂科学任务时LLM的幻觉。我们在科学编码基准上评估了MOSAIC，并证明我们的专用智能体框架在准确性、鲁棒性和可解释性方面优于现有方法。  

---

### 5 Systematic Diagnosis of Brittle Reasoning in Large Language Models  
**link**: https://arxiv.org/pdf/2510.08595.pdf  
**date**: 2025-10-13  
**keywords**: 数学推理, 失败点诊断, 聚类分析, LLM脆弱性  
**abs**: 人工智能中的一个核心问题是机器学习模型对数学的理解程度。为解决这一问题，我们提出了一种新颖的数学推理测量框架，该框架超越标准基准，以诊断特定的失败点。我们的方法首先在GSM8K数据集上通过gpt-3.5-turbo生成结构化的逐步推理。然后，我们使用更强大的分析模型gpt-4o-mini对错误进行分类，关键是对每个推理句子进行无监督聚类，以识别涌现的“推理模式”。该分析揭示了一种明显的、非人类般的脆弱认知特征：尽管模型在如顺序计算等程序性模式上达到近乎完美的准确率，但其在需要带约束的组合推理模式上的性能却急剧下降。通过识别和量化这些不同推理技能的可靠性，我们的工作提供了一种更精细的数学理解评估方法，并为开发新能力和更可靠的未来应用提供了精确的路线图。  

---

### 6 Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs  
**link**: https://arxiv.org/pdf/2510.08601.pdf  
**date**: 2025-10-13  
**keywords**: 长期记忆, 边缘计算, 图结构存储, 医疗对话  
**abs**: 长期记忆对于自然、真实的对话至关重要。然而，当前大型语言模型（LLM）的记忆系统要么依赖蛮力上下文扩展，要么依赖静态检索管道，在边缘受限设备上表现不佳。我们提出了Mnemosyne，一种无监督、类人启发的长期记忆架构，专为边缘端LLM设计。该方法采用图结构存储、模块化实质与冗余过滤器、记忆提交和修剪机制，以及模仿人类记忆的带时间衰减和刷新过程的概率回忆。Mnemosyne还引入了一个浓缩的“核心摘要”，从记忆图的固定长度子集中高效提取，以捕捉用户的个性和其他领域特定的长期细节，例如在医疗应用中，患者的康复后志向和对护理的态度。与现有的检索增强方法不同，Mnemosyne设计用于纵向医疗助手，在这类应用中，重复且语义相似但时间不同的对话受到朴素检索的限制。在纵向医疗对话实验中，Mnemosyne在真实性和长期记忆能力的盲法人类评估中获得了65.8%的最高胜率，而基线RAG的胜率为31.1%。与其他相同骨干技术相比，Mnemosyne在LoCoMo基准的时间推理和单跳检索任务中也取得了当前最高分数。此外，其54.6%的平均总分在所有方法中排名第二，优于常用的Mem0和OpenAI基线等。这表明，通过边缘兼容且易于迁移的无监督记忆架构，可以实现改进的事实回忆、增强的时间推理以及更自然的用户响应。  

---

### 7 Autoencoding-Free Context Compression for LLMs via Contextual Semantic Anchors  
**link**: https://arxiv.org/pdf/2510.08907.pdf  
**date**: 2025-10-13  
**keywords**: 上下文压缩, 语义锚点, KV表示, 推理加速  
**abs**: 上下文压缩是一种通过将长上下文压缩为紧凑表示来加速大型语言模型（LLM）推理的有前景方法。当前的上下文压缩方法主要依赖自编码任务来训练与上下文无关的压缩令牌以压缩上下文语义。尽管自编码任务能使压缩令牌获得压缩能力，但基于自编码任务的压缩存在一个根本不匹配问题：模型针对重构进行优化，这与实际下游任务脱节，从而削弱了对实际应用更有益的特征。我们提出语义锚点压缩（SAC），这是一种新颖方法，将基于自编码任务的压缩转变为一种先天具备压缩能力的架构。SAC不通过自编码任务训练模型压缩上下文，而是直接从原始上下文中选择所谓的锚点令牌，并将上下文信息聚合到它们的键值（KV）表示中。通过直接从上下文令牌中获取表示，SAC消除了对自编码训练的需求。为在直接利用锚点令牌的同时确保压缩性能，SAC包含两个关键设计：（1）锚点嵌入，使压缩器能够识别关键令牌；（2）双向注意力修改，允许锚点令牌捕获整个上下文的信息。实验结果表明，SAC在各种压缩比下均一致优于现有上下文压缩方法。在使用MRQA的分布外评估中，SAC在5倍压缩下比强基线提高了1个EM值，且在更高压缩比下优势更大。  

---

### 8 SOP-Maze: Evaluating Large Language Models on Complicated Business Standard Operating Procedures  
**link**: https://arxiv.org/pdf/2510.08942.pdf  
**date**: 2025-10-13  
**keywords**: 标准操作程序, 业务场景评估, LLM失败分析, 多选项任务  
**abs**: 随着大型语言模型（LLMs）被广泛部署为特定领域的智能体，已提出许多基准来评估其在现实场景中遵循指令和做出决策的能力。然而，业务场景通常涉及复杂的标准操作程序（SOPs），而LLM在此类情境下的能力评估尚未得到充分探索。为填补这一空白，我们提出SOP-Maze，一个基于真实业务数据构建的基准，改编自23个复杂SOP场景中的397个任务。我们进一步将SOP任务分为两大类：横向根系系统（LRS），代表需要精确选择的多选项任务；以及核心根系系统（HRS），强调具有复杂分支的深度逻辑推理。大量实验表明，几乎所有最先进的模型在SOP-Maze上都表现不佳。我们进行了全面分析，确定了三个关键错误类别：（i）路径盲目性：难以遵循程序；（ii）对话脆弱性：无法处理真实对话的细微差别；（iii）计算错误：在复杂上下文中的时间或算术推理错误。这项系统性研究探索了LLM在挑战广度和深度的SOP任务中的表现，为改进模型能力提供了新见解。我们已开源相关工作于  

---

### 9 When Retrieval Succeeds and Fails: Rethinking Retrieval-Augmented Generation for LLMs  
**link**: https://arxiv.org/pdf/2510.09106.pdf  
**date**: 2025-10-13  
**keywords**: 检索增强生成, LLM局限性, 知识更新, 综述  
**abs**: 大型语言模型（LLMs）凭借其强大的语言理解和生成能力实现了广泛应用。然而，由于LLMs基于静态语料库训练，在处理快速变化的信息或特定领域查询时存在困难。检索增强生成（RAG）通过将LLMs与外部检索机制集成，使其能够访问最新且上下文相关的知识，从而克服这一限制。但随着LLMs规模和能力的提升，传统RAG框架的相对优势已不那么显著。本文全面综述了RAG，包括其总体目标、核心组件，分析了RAG中的关键挑战及限制其有效性的关键弱点，并展示了LLMs单独表现不佳但与RAG结合后能显著增强效果的应用场景，旨在鼓励重新思考RAG的作用并启发下一代RAG系统的开发。  

---

### 10 Augmenting Dialog with Think-Aloud Utterances for Modeling Individual Personality Traits by LLM  
**link**: https://arxiv.org/pdf/2510.09158.pdf  
**date**: 2025-10-13  
**keywords**: 人格建模, 思维外显话语, 大五人格, 数据增强  
**abs**: 本研究提出通过思维外显话语（TAUs）增强对话数据，以利用LLM在文本聊天中建模个体人格特质。TAU是说话者在表达话语前的思想 verbalization。研究期望用TAU增强数据训练的“人格LLMs”能更好地模仿说话者的人格特质，并基于大五人格模型（从五个方面描述人类人格特质）测试训练后的模型是否具备人类人格特质。结果显示，用TAU增强数据训练的LLMs在大五人格的宜人性和神经质方面比用原始对话数据训练的模型更接近说话者，同时发现TAU增强的质量会影响人格LLM的性能。  

---

### 11 DSPO: Stable and Efficient Policy Optimization for Agentic Search and Reasoning  
**link**: https://arxiv.org/pdf/2510.09255.pdf  
**date**: 2025-10-13  
**keywords**: 强化学习, 策略优化, 多轮搜索, 问答系统  
**abs**: 增强LLMs主动搜索外部知识的能力对复杂现实任务至关重要。当前方法或依赖提示激发模型固有智能体能力，或在将RL应用于复杂交互任务时面临性能上限和崩溃问题，未充分发挥其智能体潜力。为此，本文引入动态过滤序列级策略优化（DSPO），这是一种改进的RL算法，通过序列级优化和动态样本过滤实现稳健的智能体训练。模型纯粹通过RL训练以交错多轮搜索和推理，无需监督演示数据。在多个问答基准测试中，DSPO训练的7B模型比可比先前工作提升34.1%，在复杂多跳问答（如HotpotQA）中甚至优于先前14B模型近9%（相对值），同时保持出色的训练稳定性。  

---

### 12 Exploring Cross-Client Memorization of Training Data in Large Language Models for Federated Learning  
**link**: https://arxiv.org/pdf/2510.08750.pdf  
**date**: 2025-10-13  
**keywords**: 联邦学习, 数据记忆, 隐私风险, 跨客户端分析  
**abs**: 联邦学习（FL）允许在不共享原始数据的情况下进行协作训练，但仍存在训练数据记忆的风险。现有的FL记忆检测技术一次只关注一个样本，低估了跨样本记忆的更微妙风险。相比之下，最近在集中式学习（CL）中的研究引入了细粒度方法来评估训练数据中所有样本的记忆，但这些方法假设可以集中访问数据，无法直接应用于FL。我们通过提出一个框架来弥合这一差距，该框架使用跨所有客户端的细粒度跨样本记忆测量来量化FL中的客户端内和客户端间记忆。基于此框架，我们进行了两项研究：（1）测量跨客户端的微妙记忆；（2）检查影响记忆的关键因素，包括解码策略、前缀长度和FL算法。我们的研究结果表明，FL模型确实会记忆客户端数据，特别是客户端内数据比客户端间数据更多，记忆受训练和推理因素的影响。  

---

### 13 NL2GenSym: Natural Language to Generative Symbolic Rules for SOAR Cognitive Architecture via Large Language Models  
**link**: https://arxiv.org/pdf/2510.09355.pdf  
**date**: 2025-10-13  
**keywords**: SOAR架构, 符号规则生成, LLM集成, 水壶问题  
**abs**: SOAR是经典的符号主义认知架构，一直致力于推动类人通用智能体的发展，但其实际应用因繁琐的手动规则编码而受阻。新兴的大型语言模型（LLMs）为高效生成规则提供了巨大潜力，然而当前研究多集中于概念框架，缺乏有力的实验验证。为此，本文提出NL2GenSym框架，将LLMs与SOAR集成，实现从自然语言自主生成生成式符号规则。该框架引入了新颖的执行接地生成器 - 评论家机制：基于检索增强生成的自进化领域知识库，LLM生成器从自然语言中提出规则；随后这些规则在SOAR环境中立即执行以严格验证其正确性；基于此执行接地反馈，反思型LLM评论家驱动规则的迭代优化。在水壶问题（WJP）数据集上，使用Gemini和Qwen系列模型的实验验证了该框架的有效性，其从自然语言生成规则的成功率超过86%。关键的是，该框架还能生成新的启发式规则，将解决WJP的平均决策周期缩短至最优解的1.98倍，仅为基线方法的1/1000。此外，初步实验表明NL2GenSym能使小参数模型性能优于大参数模型。  

---

### 14 The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach  
**link**: https://arxiv.org/pdf/2510.09424.pdf  
**date**: 2025-10-13  
**keywords**: 口语对话状态跟踪, 端到端系统, 上下文管理, 注意力池化  
**abs**: 本文对使用Speech - LLM进行端到端口语对话状态跟踪的上下文管理策略展开了比较研究。系统评估了传统多模态上下文（结合文本历史和当前口语轮次）、完整口语历史以及压缩口语历史这几种方法。在SpokenWOZ语料库上的实验表明，提供完整的口语对话作为输入时，在相似大小的模型中能获得最高性能，显著超越了现有方法。此外，研究还发现基于注意力池化的口语历史压缩方法展现出良好的权衡效果，在减少上下文大小的同时仍能保持具有竞争力的准确率。详细分析证实，性能提升源于对上下文更有效的利用。  

---

### 15 Dyna-Mind: Learning to Simulate from Experience for Better AI Agents  
**link**: https://arxiv.org/pdf/2510.09577.pdf  
**date**: 2025-10-13  
**keywords**: 心理模拟, 强化学习, 交互任务, 决策优化  
**abs**: 推理模型在数学和编码等领域取得了显著进展，但在网络导航、计算机/手机使用等长时程交互任务中表现不佳。受人类认知研究启发，本文认为当前AI智能体需要“替代性试错”——即在行动前进行心理模拟未来可能性的能力——以增强其在复杂交互环境中的理解和表现。为此，提出Dyna-Mind两阶段训练框架，明确教导(V)LM智能体将模拟整合到推理中。第一阶段引入ReSim（Reasoning with Simulations），通过环境交互收集的真实经验构建扩展搜索树，训练智能体生成结构化推理轨迹，从而将智能体的推理建立在真实世界动态的基础上，并赋予其在推理中预测未来状态的能力。第二阶段提出Dyna-GRPO，一种在线强化学习方法，利用真实滚动中的结果奖励和中间状态作为反馈，进一步强化智能体的模拟和决策能力。在Sokoban、ALFWorld和AndroidWorld等基准测试上的实验表明，ReSim有效赋予AI智能体模拟能力，Dyna-GRPO利用结果和交互级信号学习更好的长时程规划密集型任务策略。这些结果凸显了模拟在使AI智能体更有效地推理、规划和行动中的核心作用。  

---

### 16 Multimodal Policy Internalization for Conversational Agents  
**link**: https://arxiv.org/pdf/2510.09474.pdf  
**date**: 2025-10-13  
**keywords**: 多模态策略, 策略内化, 对话代理, 强化学习  
**abs**: 现代对话代理（如ChatGPT和Alexa+）依赖预定义策略来指定元数据、响应风格和工具使用规则。随着这些基于LLM的系统扩展以支持多样化业务和用户查询，这些常以上下文提示形式实现的策略变得日益复杂冗长，导致遵循困难且产生高额计算成本。多模态代理兴起后，管理视觉和多模态行为的策略至关重要但研究不足。现有提示压缩工作主要缩短任务模板和演示，策略对齐研究仅关注文本安全规则。本文提出多模态策略内化（MPI）任务，将推理密集型多模态策略内化到模型参数中，实现推理时无需包含策略即可增强策略遵循能力。MPI面临独特数据和算法挑战，为此构建了涵盖合成与现实世界决策及工具使用任务的两个数据集，并提出TriMPI三阶段训练框架：通过持续预训练注入策略知识、进行有监督微调、应用PolicyRollout（GRPO风格强化学习扩展，通过策略感知响应增强轨迹探索）。实验表明TriMPI在端到端准确性、泛化能力和抗遗忘鲁棒性上显著提升。作为多模态策略内化的首次研究，本文提供数据集、训练方法和综合评估以促进未来研究。  

---

### 17 Auto-scaling Continuous Memory for GUI Agent  
**link**: https://arxiv.org/pdf/2510.09038.pdf  
**date**: 2025-10-13  
**keywords**: GUI代理, 连续内存, 视觉嵌入, 数据飞轮  
**abs**: 本文研究如何为GUI代理赋予可扩展内存，以帮助其在不熟悉的界面和长期任务中实现泛化。现有GUI代理将过去的轨迹压缩为文本标记，这会导致上下文长度膨胀并丢失关键视觉线索（如精确的控件大小和位置）。本文提出一种连续内存，使用VLM自身作为编码器，将每个GUI轨迹编码为固定长度的连续嵌入序列；这些嵌入直接插入主干网络的输入层，大幅降低上下文成本同时保留细粒度视觉信息。随着内存大小和检索深度的增加，性能单调提升，而不像文本内存那样随长提示而退化。为了以低成本扩展内存，本文引入自动扩展数据飞轮，该飞轮通过（i）搜索发现新环境，（ii）使用开源VLM合成任务，（iii）通过代理生成轨迹，（iv）使用同一VLM验证成功。利用该管道，以约4000美元收集了10万+轨迹，并仅用1500个样本微调内存编码器（Q-Former上的LoRA，1.2%参数）。在现实世界GUI基准测试中，该内存增强代理在长期任务和分布偏移下持续提高成功率。值得注意的是，Qwen-2.5-VL-7B+连续内存的性能可与最先进的闭源模型（如GPT-4o、Claude-4）相媲美。  

---

### 18 Humanoid Artificial Consciousness Designed with Large Language Model Based on Psychoanalysis and Personality Theory  
**link**: https://arxiv.org/pdf/2510.09043.pdf  
**date**: 2025-10-13  
**keywords**: 人工意识, 精神分析, MBTI人格, 类人AI  
**abs**: 人类意识仍是当前科学难以准确定义的概念。尽管大型语言模型（LLMs）最近在翻译、总结等多个领域取得了显著进展，但由于所谓的“幻觉”问题，当前技术尚无法模拟人类意识。因此，本研究提出了一种新颖方法，通过整合精神分析学和迈尔斯-布里格斯类型指标（MBTI）来构建意识和人格模块。基于精神分析原理，我们开发了三种人工意识（自我意识、无意识和前意识）。此外，我们设计了代表16种MBTI类型的不同人格角色，并赋予其需求、状态和记忆等多种属性。为验证模型的人工意识是否表现出类人认知，我们创建了考虑情感理解、逻辑思维等七种属性的十种不同情境。通过调查评估、ChatGPT三级分类和定性审查三种方式，对人工意识的决策过程和最终行为进行了评估。定量和定性分析均表明，该模型很可能模拟出了良好的意识，尽管不同角色和意识之间的反应差异并不显著。这意味着结合精神分析学和人格理论的模型有助于构建更具直觉性和适应性的类人意识AI系统，为改善复杂认知情境中的AI交互开辟了新途径。  

---

### 19 What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment  
**link**: https://arxiv.org/pdf/2510.08847.pdf  
**date**: 2025-10-13  
**keywords**: 智能体评估, 目标-计划-行动对齐, 逻辑一致性, 记忆能力  
**abs**: 本文介绍了Agent GPA（目标-计划-行动）框架，这是一种基于智能体设定目标、制定计划和执行行动的操作循环的评估范式。该框架包含五个评估指标：目标实现度、逻辑一致性、执行效率、计划质量和计划遵循度。其中逻辑一致性检查智能体的行动与其先前行动是否一致，这涉及智能体对过往行动的记忆能力，属于Agent Memory相关研究范畴。实验结果表明，该框架能系统覆盖智能体的多种失败情况，并支持与人类标注高度一致的LLM评判器。  

---

### 20 EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory  
**link**: https://arxiv.org/pdf/2510.08958.pdf  
**date**: 2025-10-13  
**keywords**: 知识图谱RAG, 联想记忆, 实体中心检索, 多跳推理  
**abs**: 受人类联想记忆机制启发，本文提出EcphoryRAG，一种以实体为中心的知识图谱RAG框架。人类通过线索激活实体中心记忆痕迹（engrams）进行多跳回忆，EcphoryRAG模仿此过程：索引阶段仅存储核心实体及元数据以减少94%令牌消耗；检索阶段从查询提取线索实体，进行多跳关联搜索，并动态推断实体间隐含关系。该研究将人类联想记忆（Personal Memory的一种形式）应用于智能体知识检索，在2WikiMultiHop等基准上实现EM分数从0.392提升至0.474的新SOTA。  

---

### 21 Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation  
**link**: https://arxiv.org/pdf/2510.08713.pdf  
**date**: 2025-10-13  
**keywords**: 具身导航, 世界模型, 视觉预见, 记忆增强  
**abs**: 为使具身智能体有效想象未来状态以实现稳健可泛化的视觉导航，本文提出UniWM——一种统一的记忆增强世界模型，将以自我为中心的视觉预见与规划整合到单一多模态自回归框架中。该模型通过将动作决策明确基于视觉想象结果，确保预测与控制的紧密对齐。其分层记忆机制整合短期感知线索与长期轨迹上下文，实现扩展视野下的稳定连贯推理。在Go Stanford、ReCon、SCAND、HuRoN四个基准测试中，UniWM将导航成功率提升高达30%，显著减少轨迹误差，并在未见过的TartanDrive数据集上展现出优异的零样本泛化能力，为基于想象的具身导航提供了重要进展。  

---

### 22 COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context  
**link**: https://arxiv.org/pdf/2510.08790.pdf  
**date**: 2025-10-13  
**keywords**: 长程推理, 上下文管理, 多智能体协作, 进度简报  
**abs**: 针对LLM智能体在长程任务中面临的推理连贯性差和错误累积问题，本文提出COMPASS框架，将上下文管理确定为核心瓶颈。该框架通过分层结构分离战术执行、战略监督和上下文组织：主智能体负责推理与工具使用，元思考者监控进度并发出战略干预，上下文管理器为不同推理阶段维护简洁相关的进度简报。在GAIA、BrowseComp和Humanity's Last Exam基准测试中，COMPASS相比单/多智能体基线准确率提升达20%，其测试时扩展机制可匹配DeepResearch智能体性能，后训练管道通过委托上下文管理给小模型提升效率，有效增强了智能体的长程推理能力。  

---

### 23 Fundamentals of Building Autonomous LLM Agents  
**link**: https://arxiv.org/pdf/2510.09244.pdf  
**date**: 2025-10-13  
**keywords**: 自主智能体, LLM架构, 感知系统, 记忆机制  
**abs**: 本文综述了由大型语言模型（LLMs）驱动的智能体的架构和实现方法。受传统LLMs在现实世界任务中局限性的启发，该研究旨在探索开发“智能体化”LLMs的模式，以实现复杂任务的自动化并缩小与人类能力的性能差距。关键组件包括：感知系统，将环境感知转换为有意义的表示；推理系统，通过思维链（Chain-of-Thought）和思维树（Tree-of-Thought）等技术制定计划、适应反馈并评估行动；记忆系统，通过短期和长期机制保留知识；执行系统，将内部决策转化为具体行动。本文展示了整合这些系统如何产生更具能力和泛化性的软件机器人，它们模仿人类认知过程以实现自主和智能行为。  

---

### 24 Titans Revisited: A Lightweight Reimplementation and Critical Analysis of a Test-Time Memory Model  
**link**: https://arxiv.org/pdf/2510.09551.pdf  
**date**: 2025-10-13  
**keywords**: 测试时学习, 神经记忆模型, 可复现性, 性能评估  
**abs**: 2024年底，谷歌研究人员提出了Titans：测试时学习（Learning at Test Time），这是一种神经记忆模型，在多个任务上取得了强大的实证结果。然而，缺乏公开可用的代码以及原始描述中的模糊性阻碍了其可复现性。在这项工作中，作者提出了Titans的轻量级重新实现，并在掩码语言建模、时间序列预测和推荐任务上进行了全面评估。结果表明，由于分块问题，Titans并不总是优于已建立的基线。然而，其神经记忆组件与仅基于注意力的模型相比，始终能提高性能。这些发现证实了该模型的创新潜力，同时也突出了其实际局限性，并为未来研究提出了问题。  

---

### 25 Guiding Exploration in Reinforcement Learning Through LLM-Augmented Observations  
**link**: https://arxiv.org/pdf/2510.08779.pdf  
**date**: 2025-10-13  
**keywords**: 强化学习, LLM指导, 探索策略, 稀疏奖励  
**abs**: 强化学习（RL）智能体在稀疏奖励环境中常常面临困难，传统的探索策略难以发现有效的动作序列。大型语言模型（LLMs）从文本预训练中获得了过程性知识和推理能力，这些能力可以指导RL的探索，但现有方法存在刚性依赖，即RL策略必须遵循LLM的建议或将其直接纳入奖励函数。我们提出了一个框架，通过增强的观察空间提供LLM生成的动作建议，允许RL智能体学习何时遵循或忽略这种指导。我们的方法利用LLMs的世界知识和推理能力，同时通过软约束保持灵活性。我们在三个复杂度递增的BabyAI环境中评估了我们的方法，结果表明LLM指导的好处随着任务难度的增加而扩大。在最具挑战性的环境中，我们的最终成功率比基线提高了71%。该方法显著提高了样本效率，智能体达到性能阈值的速度最高快9倍，并且不需要修改现有的RL算法。我们的结果证明了一种利用LLM规划能力加速挑战性环境中RL训练的有效方法。  

---

### 26 Transmuting prompts into weights  
**link**: https://arxiv.org/pdf/2510.08734.pdf  
**date**: 2025-10-13  
**keywords**: 模型干预, 权重更新, Transformer理论, 思维向量  
**abs**: 大量研究表明，大型语言模型（LLM）的行为可以通过直接修改其内部状态（如对激活进行向量加法或更新权重矩阵）在推理时得到有效控制。这些技术虽然强大，但通常依赖于经验性启发式方法，例如从对比提示的平均激活中导出引导向量。本文为这些干预提供了理论基础，解释了它们如何从Transformer架构的基本计算中产生。基于最近的研究发现（提示的影响可以通过数学方式映射到隐式权重更新，Dherin等人，2025），我们将该理论推广到深度多块Transformer。我们展示了用户提示中任何片段包含的信息如何通过权重向量和权重矩阵在内部表示和组合。然后，我们推导出一种原则性方法，将这些信息浓缩为与令牌无关的思维向量和思维矩阵。这些结构为现有的基于向量和矩阵的模型编辑技术提供了理论解释，并提供了一种直接的、基于计算的方法，将文本输入转化为可重用的权重更新。  

---

### 27 Task-Level Insights from Eigenvalues across Sequence Models  
**link**: https://arxiv.org/pdf/2510.09379.pdf  
**date**: 2025-10-13  
**keywords**: 序列模型, 特征值分析, 动态系统, 信息处理  
**abs**: 尽管softmax注意力驱动了序列模型的最先进性能，但其二次复杂度限制了可扩展性，促使人们研究线性替代方案（如状态空间模型SSMs）。虽然这些替代方案提高了效率，但它们在信息处理方面的根本差异仍未被充分理解。本文利用最近提出的动态系统框架，将softmax、归一化和线性注意力表示为动态系统，通过分析其特征值谱实现与SSMs的结构化比较。由于特征值捕获了动态系统行为的基本方面，我们在不同序列模型和基准上进行了广泛的实证分析。研究首先表明，特征值影响记忆和长程依赖建模的关键方面，揭示了与任务需求对齐的谱特征。基于这些见解，我们进一步研究了序列模型中的架构修改如何同时影响特征值谱和任务性能。这种对应关系进一步巩固了特征值分析作为解释、理解和改进序列模型能力的原则性指标的地位。  

---

### 28 Design Principles for Sequence Models via Coefficient Dynamics  
**link**: https://arxiv.org/pdf/2510.09389.pdf  
**date**: 2025-10-13  
**keywords**: 序列模型设计, 线性动态系统, 表达性权衡, 稳定性条件  
**abs**: 深度序列模型（从Transformer和状态空间模型SSMs到最近的门控线性RNN等方法）本质上通过过去值向量的线性组合来计算输出。为了获取见解并系统比较这些架构，我们开发了一个统一框架，通过将线性组合系数视为由脉冲输入驱动的自治线性动态系统的输出来明确这种输出操作。这种观点与专注于将线性RNN与线性注意力连接的方法在本质上不同，它揭示了不同架构之间的共同数学主题，并关键地涵盖了softmax注意力，以及RNN、SSMs和相关模型。与通常在基准上评估的新模型提案不同，我们推导了将架构选择与模型属性联系起来的设计原则。由此确定了表达性与高效实现之间的权衡、输入选择性的几何约束，以及数值稳定训练和信息保留的稳定性条件。通过连接最近文献中的若干见解和观察，该框架既解释了近期设计的实证成功，也为系统设计新的序列模型架构提供了指导原则。  

---

### 29 Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting  
**link**: https://arxiv.org/pdf/2510.09152.pdf  
**date**: 2025-10-13  
**keywords**: 后期训练, 遗忘最小化, logits重放, 模型适应  
**abs**: 大型语言模型（LLMs）在后期训练中常面临权衡：特定领域性能提升往往以牺牲通用能力为代价。现有解决方案通过正则化、选择性参数更新或数据重放来缓解此问题，但均存在计算成本高、数据访问受限或适应性不足等缺陷。近期研究表明，训练信号可压缩为logits子集而不显著损失精度，为高效适应提供了可能。然而，简单截断会破坏优化稳定性并加剧遗忘问题。本文提出Logits Replay + MoClip方法，旨在实现稳定、低成本且遗忘最小化的后训练。  

---

### 30 Agentic-KGR: Co-evolutionary Knowledge Graph Construction through Multi-Agent Reinforcement Learning  
**link**: https://arxiv.org/pdf/2510.09156.pdf  
**date**: 2025-10-13  
**keywords**: 知识图谱构建, 多智能体强化学习, 动态模式扩展, 检索增强  
**abs**: 当前知识增强型大型语言模型（LLMs）依赖静态预构建知识库，存在覆盖缺口和时效性问题，限制了其在动态信息环境中的有效性。本文提出Agentic-KGR框架，通过多轮强化学习实现LLMs与知识图谱（KGs）的协同进化。该方法包含三项关键创新：（1）动态模式扩展机制，在训练期间系统性扩展预定义边界外的图本体；（2）检索增强记忆系统，通过持续优化实现模型参数与知识结构的协同进化；（3）可学习的多尺度提示压缩方法，通过自适应序列优化保留关键信息并降低计算复杂度。实验结果表明，该方法在知识提取任务上显著优于有监督基线和单轮强化学习方法，与GraphRAG集成后在下游问答任务中实现了更高的准确率和知识覆盖率。  

---

### 31 Variability Aware Recursive Neural Network (VARNN): A Residual-Memory Model for Capturing Temporal Deviation in Sequence Regression Modeling  
**link**: https://arxiv.org/pdf/2510.08944.pdf  
**date**: 2025-10-13  
**keywords**: 时间序列回归, 残差记忆, 异方差性, 鲁棒预测  
**abs**: 现实世界的时间序列数据表现出非平稳行为、状态转换和随时间变化的噪声（异方差性），这些都会降低标准回归模型的鲁棒性。本文提出了变异性感知递归神经网络（VARNN），这是一种新型的残差感知架构，用于有监督时间序列回归。该模型从最近的预测残差中学习显式的误差记忆，并利用它来重新校准后续预测。VARNN 通过一个学习到的误差记忆状态增强前馈预测器，该状态通过短上下文步骤的残差更新，作为变异性和漂移的信号，然后调节当前时间步的最终预测。在电器能源、医疗保健和环境监测等多个数据集领域的实验结果表明，VARNN 相比静态、动态和递归基线模型，在实现更低测试 MSE 的同时具有最小的计算开销，性能更优。研究结果表明，VARNN 模型在漂移和波动环境下提供了稳健的预测，突显了其作为时间序列学习有前景框架的潜力。  

---

### 32 LLM Unlearning on Noisy Forget Sets: A Study of Incomplete, Rewritten, and Watermarked Data  
**link**: https://arxiv.org/pdf/2510.09007.pdf  
**date**: 2025-10-13  
**keywords**: LLM遗忘, 噪声遗忘集, 鲁棒性分析, 语义线索  
**abs**: 大型语言模型（LLMs）具备强大的生成能力，但因记忆敏感数据、强化偏见及生成有害内容而引发伦理与安全担忧。这些风险推动了LLM遗忘（unlearning）研究，其旨在从预训练模型中移除与不良数据相关的知识。然而，现有方法多假设可获取干净、明确的遗忘数据样本，而现实中的遗忘数据常存在质量低、经人工重写或带水印等问题，这使遗忘的可靠性受到质疑。本研究首次针对扰动或低保真遗忘数据（称为噪声遗忘集）下的遗忘展开探讨。通过在噪声遗忘集上对最先进的LLM遗忘方法（RMU和NPO）进行系统基准测试，发现只要核心语义信号得以保留，遗忘对扰动具有显著的鲁棒性。为解释此鲁棒性，提出基于显著性的解释：尽管表面形式存在较大差异，但驱动遗忘的关键语义组件始终保持影响力。这表明遗忘算法主要受深层语义线索引导，而非浅层词汇模式。  

---  
**处理完成**：共处理32篇唯一论文，所有摘要已总结并输出为中文，关键词基于标题和摘要生成。
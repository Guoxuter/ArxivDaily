### 1 Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search  
**link**: https://arxiv.org/pdf/2510.18939  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文针对长程智能体搜索中上下文限制问题，提出SLIM框架。该框架通过分离搜索和浏览工具，并定期总结轨迹，保持上下文简洁，支持更长、更聚焦的搜索。实验表明，SLIM在长程任务上以更低成本和更少工具调用实现与开源基线相当的性能，有效缓解智能体在长轨迹任务中的记忆限制，为Agent Memory领域提供实用解决方案。  

### 2 LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts  
**link**: https://arxiv.org/pdf/2510.19363  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文提出LoongRL框架，用于高级长上下文推理。核心是KeyChain方法，将短多跳问答转换为高难度长上下文任务，通过插入UUID链隐藏真实问题于干扰文档中。训练后模型形成“计划-检索-推理-复查”模式，泛化能力强，在16K长度训练下可处理128K任务。在Qwen2.5模型上，长上下文多跳问答准确率提升23.5%（7B）和21.1%（14B），性能媲美更大模型，并改进长上下文检索能力。  

### 3 Hubble: a Model Suite to Advance the Study of LLM Memorization  
**link**: https://arxiv.org/pdf/2510.19811  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文介绍Hubble开源模型套件，用于研究LLM记忆问题。Hubble包含标准模型和扰动模型（在训练中插入敏感文本），核心版本有8个模型（1B/8B参数，100B/500B tokens预训练）。研究发现记忆风险取决于敏感数据频率与训练语料大小的比例，敏感数据在较小语料中更易被记住。扰动模型显示，未持续暴露的数据可能被遗忘。Hubble支持记忆分析、成员推理和机器遗忘研究，并提出通过增大训练语料和早期安排敏感数据来降低风险。  

### 4 MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models  
**link**: https://arxiv.org/pdf/2510.19457  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文提出MINED基准，评估大型多模态模型（LMMs）对时间敏感知识的理解能力。MINED从6个维度（认知、感知等）和11个任务评估，包含2104个样本，基于维基百科构建。评估15个LMMs显示，Gemini-2.5-Pro得分最高（63.07），开源模型表现较差。LMMs在组织知识上最佳，体育知识上最弱。研究还探讨知识编辑方法更新LMMs时间敏感知识的可行性，证明单一编辑场景下有效。  

### 5 VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos  
**link**: https://arxiv.org/pdf/2510.19488  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文提出VideoAgentTrek流水线，从无标签视频自动挖掘训练数据，避免手动标注。核心是Video2Action模块，包含视频接地模型（检测GUI动作）和动作内容识别器（提取参数）。应用于39000个YouTube视频，生成152万个交互步骤。通过预训练和微调，在OSWorld-Verified任务成功率从9.3%提升至15.8%（相对70%），AgentNetBench步骤准确率从64.1%提升至69.3%，证明互联网视频可转化为高质量监督数据。  

### 6 CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation  
**link**: https://arxiv.org/pdf/2510.19670  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文提出CoSense-LLM边缘优先框架，处理多模态传感器流。包含四个组件：SenseFusion（轻量编码器对齐传感器和语言）、Edge-RAG（本地检索层）、PromptRouter（成本和不确定性感知策略选择边缘或云生成）、Secure Execution（数据最小化执行）。系统在家庭、办公室等部署中实现亚秒级延迟，通过本地检索减少带宽和保护隐私。实验显示Edge-RAG提高事实一致性，不确定性校准支持选择性弃权。  

### 7 Re:Member: Emotional Question Generation from Personal Memories  
**link**: https://arxiv.org/pdf/2510.19030  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文提出Re:Member系统，支持第二语言学习。系统利用用户个人视频生成目标语言的风格化口语问题，结合情感基调和视觉语境（如耳语或深夜语调），以WhisperX转录对齐和Style-BERT-VITS2情感合成实现。作为风格化交互探针，强调情感和个人媒体在以学习者为中心教育中的作用。  

### 8 When Facts Change: Probing LLMs on Evolving Knowledge with evolveQA  
**link**: https://arxiv.org/pdf/2510.19172  
**date**: 2025-10-23  
**keywords**: cs.CL  
**abs**: 本文引入evolveQA基准，评估LLMs处理时间演变知识的能力。基准基于AWS、Azure和WHO时间戳语料库构建，识别自然知识演变并生成问题。评估12个开源和闭源LLMs显示，与静态知识相比，evolveQA上性能下降高达31%，突显LLMs在动态知识上的不足。  

### 9 Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties  
**link**: https://arxiv.org/pdf/2510.19299  
**date**: 2025-10-23  
**keywords**: cs.AI  
**abs**: 本文探讨LLM智能体再现人类社会动态。提出多智能体模拟框架，智能体通过上下文学习和教练信号交互，行为奖励函数对齐用户动机（社会互动、协作等）。实验显示，训练后智能体发展稳定交互模式和涌现社会联系，网络结构反映真实在线社区特性，为研究LLM集体动态提供测试平台。  

### 10 Continual Knowledge Adaptation for Reinforcement Learning  
**link**: https://arxiv.org/pdf/2510.19314  
**date**: 2025-10-23  
**keywords**: cs.AI  
**abs**: 本文提出持续知识适应强化学习（CKA-RL），解决非平稳环境中灾难性遗忘和知识利用问题。方法维护任务知识向量池，动态利用历史知识适应新任务，通过保留关键参数减轻遗忘。自适应知识合并机制合并相似向量，减少内存需求。在三个基准上，CKA-RL总体性能提升4.20%，前向迁移提升8.02%。  

### 11 LLM Unlearning with LLM Beliefs  
**link**: https://arxiv.org/pdf/2510.19422  
**date**: 2025-10-23  
**keywords**: cs.LG  
**abs**: 本文针对LLMs遗忘敏感内容问题，提出自举（BS）框架。主流遗忘方法引发挤压效应（概率质量转移到高可能性区域），导致虚假遗忘。BS联合抑制目标响应和模型信念：BS-T减弱高概率token，BS-S移除高置信度生成。实验证实，该方法在不同模型家族上实现更彻底遗忘，同时保留模型效用。  

### 12 Blackbox Model Provenance via Palimpsestic Membership Inference  
**link**: https://arxiv.org/pdf/2510.19796  
**date**: 2025-10-23  
**keywords**: cs.LG  
**abs**: 本文研究黑盒模型来源问题，通过重写记忆视角。提出检验方法：如果Alice随机打乱训练数据，Bob模型或文本与顺序的显著相关性可证明来源。查询设置中，直接估计Bob模型对Alice训练顺序的可能性；观察设置中，通过跨度重叠或不同版本模型估计文本可能性。实验在Pythia和OLMo模型上验证，p值低至1e-8，观察方法从少量标记可靠区分来源。  

### 13 NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning  
**link**: https://arxiv.org/pdf/2510.19429  
**date**: 2025-10-23  
**keywords**: cs.AI  
**abs**: 本文提出NeSyPr框架，解决动态环境中具身任务挑战。通过神经符号过程化编译知识，将符号工具生成计划转化为可组合程序表示，编码隐含规则。该方法将多步推理抽象为单步语言模型推理，支持资源受限环境高效执行。在PDDLGym、VirtualHome等基准上，使用紧凑模型优于大规模推理和符号规划器。  

### 14 Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning  
**link**: https://arxiv.org/pdf/2510.19732  
**date**: 2025-10-23  
**keywords**: cs.AI  
**abs**: 本文提出Memo架构，基于Transformer强化学习训练具身代理，专注于记忆密集型长任务。方法在训练期间交错总结令牌与输入，解决视觉输入超出上下文限制问题。在网格世界元强化学习和多目标导航任务中，Memo优于全上下文Transformer基线，计算和存储效率更高，泛化能力更强，属于Agent Memory研究范畴。